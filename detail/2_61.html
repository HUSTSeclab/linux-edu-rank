<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patches contributed by Harvard University</title>
    <style>
    .pagination {
        border-top: 1px solid #ddd;
        border-bottom: 1px solid #ddd;
        overflow-wrap: break-word;
    }
    .pagination a, .pagination span {
        margin: 0 4px;
    }

    </style>
</head>
<body>
    <h1>Patches contributed by Harvard University</h1>
    <div class="pagination">
        <a href='2_60.html'>&lt;&lt;Prev</a><a href='2.html'>1</a><a href='2_2.html'>2</a><a href='2_3.html'>3</a><a href='2_4.html'>4</a><a href='2_5.html'>5</a><a href='2_6.html'>6</a><a href='2_7.html'>7</a><a href='2_8.html'>8</a><a href='2_9.html'>9</a><a href='2_10.html'>10</a><a href='2_11.html'>11</a><a href='2_12.html'>12</a><a href='2_13.html'>13</a><a href='2_14.html'>14</a><a href='2_15.html'>15</a><a href='2_16.html'>16</a><a href='2_17.html'>17</a><a href='2_18.html'>18</a><a href='2_19.html'>19</a><a href='2_20.html'>20</a><a href='2_21.html'>21</a><a href='2_22.html'>22</a><a href='2_23.html'>23</a><a href='2_24.html'>24</a><a href='2_25.html'>25</a><a href='2_26.html'>26</a><a href='2_27.html'>27</a><a href='2_28.html'>28</a><a href='2_29.html'>29</a><a href='2_30.html'>30</a><a href='2_31.html'>31</a><a href='2_32.html'>32</a><a href='2_33.html'>33</a><a href='2_34.html'>34</a><a href='2_35.html'>35</a><a href='2_36.html'>36</a><a href='2_37.html'>37</a><a href='2_38.html'>38</a><a href='2_39.html'>39</a><a href='2_40.html'>40</a><a href='2_41.html'>41</a><a href='2_42.html'>42</a><a href='2_43.html'>43</a><a href='2_44.html'>44</a><a href='2_45.html'>45</a><a href='2_46.html'>46</a><a href='2_47.html'>47</a><a href='2_48.html'>48</a><a href='2_49.html'>49</a><a href='2_50.html'>50</a><a href='2_51.html'>51</a><a href='2_52.html'>52</a><a href='2_53.html'>53</a><a href='2_54.html'>54</a><a href='2_55.html'>55</a><a href='2_56.html'>56</a><a href='2_57.html'>57</a><a href='2_58.html'>58</a><a href='2_59.html'>59</a><a href='2_60.html'>60</a><span>[61]</span><a href='2_62.html'>62</a><a href='2_63.html'>63</a><a href='2_64.html'>64</a><a href='2_65.html'>65</a><a href='2_66.html'>66</a><a href='2_67.html'>67</a><a href='2_68.html'>68</a><a href='2_69.html'>69</a><a href='2_70.html'>70</a><a href='2_71.html'>71</a><a href='2_72.html'>72</a><a href='2_73.html'>73</a><a href='2_74.html'>74</a><a href='2_75.html'>75</a><a href='2_76.html'>76</a><a href='2_77.html'>77</a><a href='2_78.html'>78</a><a href='2_79.html'>79</a><a href='2_80.html'>80</a><a href='2_81.html'>81</a><a href='2_82.html'>82</a><a href='2_83.html'>83</a><a href='2_84.html'>84</a><a href='2_85.html'>85</a><a href='2_86.html'>86</a><a href='2_87.html'>87</a><a href='2_88.html'>88</a><a href='2_89.html'>89</a><a href='2_90.html'>90</a><a href='2_91.html'>91</a><a href='2_92.html'>92</a><a href='2_93.html'>93</a><a href='2_94.html'>94</a><a href='2_95.html'>95</a><a href='2_96.html'>96</a><a href='2_97.html'>97</a><a href='2_98.html'>98</a><a href='2_99.html'>99</a><a href='2_100.html'>100</a><a href='2_101.html'>101</a><a href='2_102.html'>102</a><a href='2_103.html'>103</a><a href='2_104.html'>104</a><a href='2_105.html'>105</a><a href='2_106.html'>106</a><a href='2_107.html'>107</a><a href='2_108.html'>108</a><a href='2_109.html'>109</a><a href='2_110.html'>110</a><a href='2_111.html'>111</a><a href='2_112.html'>112</a><a href='2_113.html'>113</a><a href='2_114.html'>114</a><a href='2_115.html'>115</a><a href='2_116.html'>116</a><a href='2_117.html'>117</a><a href='2_118.html'>118</a><a href='2_119.html'>119</a><a href='2_120.html'>120</a><a href='2_121.html'>121</a><a href='2_122.html'>122</a><a href='2_123.html'>123</a><a href='2_124.html'>124</a><a href='2_125.html'>125</a><a href='2_126.html'>126</a><a href='2_127.html'>127</a><a href='2_128.html'>128</a><a href='2_129.html'>129</a><a href='2_130.html'>130</a><a href='2_131.html'>131</a><a href='2_132.html'>132</a><a href='2_133.html'>133</a><a href='2_134.html'>134</a><a href='2_135.html'>135</a><a href='2_136.html'>136</a><a href='2_137.html'>137</a><a href='2_138.html'>138</a><a href='2_139.html'>139</a><a href='2_140.html'>140</a><a href='2_62.html'>Next&gt;&gt;</a>
    </div>
    <hr>
    <pre>commit 56626a72a47bf3e50875d960d6b5f17b9bee0ab2
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Thu Oct 14 15:25:21 2010 -0400

    USB: accept some invalid ep0-maxpacket values
    
    A few devices (such as the RCA VR5220 voice recorder) are so
    non-compliant with the USB spec that they have invalid maxpacket sizes
    for endpoint 0.  Nevertheless, as long as we can safely use them, we
    may as well do so.
    
    This patch (as1432) softens our acceptance criterion by allowing
    high-speed devices to have ep0-maxpacket sizes other than 64.  A
    warning is printed in the system log when this happens, and the
    existing error message is clarified.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Reported-by: James &lt;bjlockie@lockie.ca&gt;
    Cc: stable &lt;stable@kernel.org&gt;
    Signed-off-by: Greg Kroah-Hartman &lt;gregkh@suse.de&gt;

diff --git a/drivers/usb/core/hub.c b/drivers/usb/core/hub.c
index 7f82c48a0bae..27115b45edc5 100644
--- a/drivers/usb/core/hub.c
+++ b/drivers/usb/core/hub.c
@@ -2861,13 +2861,16 @@ hub_port_init (struct usb_hub *hub, struct usb_device *udev, int port1,
 	else
 		i = udev-&gt;descriptor.bMaxPacketSize0;
 	if (le16_to_cpu(udev-&gt;ep0.desc.wMaxPacketSize) != i) {
-		if (udev-&gt;speed != USB_SPEED_FULL ||
+		if (udev-&gt;speed == USB_SPEED_LOW ||
 				!(i == 8 || i == 16 || i == 32 || i == 64)) {
-			dev_err(&amp;udev-&gt;dev, "ep0 maxpacket = %d\n", i);
+			dev_err(&amp;udev-&gt;dev, "Invalid ep0 maxpacket: %d\n", i);
 			retval = -EMSGSIZE;
 			goto fail;
 		}
-		dev_dbg(&amp;udev-&gt;dev, "ep0 maxpacket = %d\n", i);
+		if (udev-&gt;speed == USB_SPEED_FULL)
+			dev_dbg(&amp;udev-&gt;dev, "ep0 maxpacket = %d\n", i);
+		else
+			dev_warn(&amp;udev-&gt;dev, "Using ep0 maxpacket: %d\n", i);
 		udev-&gt;ep0.desc.wMaxPacketSize = cpu_to_le16(i);
 		usb_ep0_reinit(udev);
 	}</pre><hr><pre>commit 80f0cf3947889014d3a3dc0ad60fb87cfda4b12a
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Thu Sep 30 15:16:23 2010 -0400

    USB: disable endpoints after unbinding interfaces, not before
    
    This patch (as1430) fixes a bug in usbcore.  When a device
    configuration change occurs or a device is removed, the endpoints for
    the old config should be completely disabled.  However it turns out
    they aren't; this is because usb_unbind_interface() calls
    usb_enable_interface() or usb_set_interface() to put interfaces back
    in altsetting 0, which re-enables the interfaces' endpoints.
    
    As a result, when a device goes through a config change or is
    unconfigured, the ep_in[] and ep_out[] arrays may be left holding old
    pointers to usb_host_endpoint structures.  If the device is
    deauthorized these structures get freed, and the stale pointers cause
    errors when the the device is eventually unplugged.
    
    The solution is to disable the endpoints after unbinding the
    interfaces instead of before.  This isn't as large a change as it
    sounds, since usb_unbind_interface() disables all the interface's
    endpoints anyway before calling the driver's disconnect routine,
    unless the driver claims to support "soft" unbind.
    
    This fixes Bugzilla #19192.  Thanks to "Tom" Lei Ming for diagnosing
    the underlying cause of the problem.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Tested-by: Carsten Sommer &lt;carsten_sommer@ymail.com&gt;
    CC: stable &lt;stable@kernel.org&gt;
    Signed-off-by: Greg Kroah-Hartman &lt;gregkh@suse.de&gt;

diff --git a/drivers/usb/core/message.c b/drivers/usb/core/message.c
index 9f0ce7de0e36..d6e3e410477e 100644
--- a/drivers/usb/core/message.c
+++ b/drivers/usb/core/message.c
@@ -1140,13 +1140,6 @@ void usb_disable_device(struct usb_device *dev, int skip_ep0)
 {
 	int i;
 
-	dev_dbg(&amp;dev-&gt;dev, "%s nuking %s URBs\n", __func__,
-		skip_ep0 ? "non-ep0" : "all");
-	for (i = skip_ep0; i &lt; 16; ++i) {
-		usb_disable_endpoint(dev, i, true);
-		usb_disable_endpoint(dev, i + USB_DIR_IN, true);
-	}
-
 	/* getting rid of interfaces will disconnect
 	 * any drivers bound to them (a key side effect)
 	 */
@@ -1176,6 +1169,13 @@ void usb_disable_device(struct usb_device *dev, int skip_ep0)
 		if (dev-&gt;state == USB_STATE_CONFIGURED)
 			usb_set_device_state(dev, USB_STATE_ADDRESS);
 	}
+
+	dev_dbg(&amp;dev-&gt;dev, "%s nuking %s URBs\n", __func__,
+		skip_ep0 ? "non-ep0" : "all");
+	for (i = skip_ep0; i &lt; 16; ++i) {
+		usb_disable_endpoint(dev, i, true);
+		usb_disable_endpoint(dev, i + USB_DIR_IN, true);
+	}
 }
 
 /**</pre><hr><pre>commit 834e2312e7a384877a876b0d34dffc3046c96bcb
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Mon Sep 13 10:43:25 2010 -0400

    USB: teach "devices" file about Wireless and SuperSpeed USB
    
    The /sys/kernel/debug/usb/devices file doesn't know about Wireless or
    SuperSpeed USB.  This patch (as1416b) teaches it, and updates the
    Documentation/usb/proc_sub_info.txt file accordingly.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    CC: David Vrabel &lt;david.vrabel@csr.com&gt;
    CC: Sarah Sharp &lt;sarah.a.sharp@linux.intel.com&gt;
    Signed-off-by: Greg Kroah-Hartman &lt;gregkh@suse.de&gt;

diff --git a/Documentation/usb/proc_usb_info.txt b/Documentation/usb/proc_usb_info.txt
index fafcd4723260..afe596d5f201 100644
--- a/Documentation/usb/proc_usb_info.txt
+++ b/Documentation/usb/proc_usb_info.txt
@@ -1,12 +1,17 @@
 /proc/bus/usb filesystem output
 ===============================
-(version 2003.05.30)
+(version 2010.09.13)
 
 
 The usbfs filesystem for USB devices is traditionally mounted at
 /proc/bus/usb.  It provides the /proc/bus/usb/devices file, as well as
 the /proc/bus/usb/BBB/DDD files.
 
+In many modern systems the usbfs filsystem isn't used at all.  Instead
+USB device nodes are created under /dev/usb/ or someplace similar.  The
+"devices" file is available in debugfs, typically as
+/sys/kernel/debug/usb/devices.
+
 
 **NOTE**: If /proc/bus/usb appears empty, and a host controller
 	  driver has been linked, then you need to mount the
@@ -106,8 +111,8 @@ Legend:
 
 Topology info:
 
-T:  Bus=dd Lev=dd Prnt=dd Port=dd Cnt=dd Dev#=ddd Spd=ddd MxCh=dd
-|   |      |      |       |       |      |        |       |__MaxChildren
+T:  Bus=dd Lev=dd Prnt=dd Port=dd Cnt=dd Dev#=ddd Spd=dddd MxCh=dd
+|   |      |      |       |       |      |        |        |__MaxChildren
 |   |      |      |       |       |      |        |__Device Speed in Mbps
 |   |      |      |       |       |      |__DeviceNumber
 |   |      |      |       |       |__Count of devices at this level
@@ -120,8 +125,13 @@ T:  Bus=dd Lev=dd Prnt=dd Port=dd Cnt=dd Dev#=ddd Spd=ddd MxCh=dd
     Speed may be:
     	1.5	Mbit/s for low speed USB
 	12	Mbit/s for full speed USB
-	480	Mbit/s for high speed USB (added for USB 2.0)
+	480	Mbit/s for high speed USB (added for USB 2.0);
+		  also used for Wireless USB, which has no fixed speed
+	5000	Mbit/s for SuperSpeed USB (added for USB 3.0)
 
+    For reasons lost in the mists of time, the Port number is always
+    too low by 1.  For example, a device plugged into port 4 will
+    show up with "Port=03".
 
 Bandwidth info:
 B:  Alloc=ddd/ddd us (xx%), #Int=ddd, #Iso=ddd
@@ -291,7 +301,7 @@ Here's an example, from a system which has a UHCI root hub,
 an external hub connected to the root hub, and a mouse and
 a serial converter connected to the external hub.
 
-T:  Bus=00 Lev=00 Prnt=00 Port=00 Cnt=00 Dev#=  1 Spd=12  MxCh= 2
+T:  Bus=00 Lev=00 Prnt=00 Port=00 Cnt=00 Dev#=  1 Spd=12   MxCh= 2
 B:  Alloc= 28/900 us ( 3%), #Int=  2, #Iso=  0
 D:  Ver= 1.00 Cls=09(hub  ) Sub=00 Prot=00 MxPS= 8 #Cfgs=  1
 P:  Vendor=0000 ProdID=0000 Rev= 0.00
@@ -301,21 +311,21 @@ C:* #Ifs= 1 Cfg#= 1 Atr=40 MxPwr=  0mA
 I:  If#= 0 Alt= 0 #EPs= 1 Cls=09(hub  ) Sub=00 Prot=00 Driver=hub
 E:  Ad=81(I) Atr=03(Int.) MxPS=   8 Ivl=255ms
 
-T:  Bus=00 Lev=01 Prnt=01 Port=00 Cnt=01 Dev#=  2 Spd=12  MxCh= 4
+T:  Bus=00 Lev=01 Prnt=01 Port=00 Cnt=01 Dev#=  2 Spd=12   MxCh= 4
 D:  Ver= 1.00 Cls=09(hub  ) Sub=00 Prot=00 MxPS= 8 #Cfgs=  1
 P:  Vendor=0451 ProdID=1446 Rev= 1.00
 C:* #Ifs= 1 Cfg#= 1 Atr=e0 MxPwr=100mA
 I:  If#= 0 Alt= 0 #EPs= 1 Cls=09(hub  ) Sub=00 Prot=00 Driver=hub
 E:  Ad=81(I) Atr=03(Int.) MxPS=   1 Ivl=255ms
 
-T:  Bus=00 Lev=02 Prnt=02 Port=00 Cnt=01 Dev#=  3 Spd=1.5 MxCh= 0
+T:  Bus=00 Lev=02 Prnt=02 Port=00 Cnt=01 Dev#=  3 Spd=1.5  MxCh= 0
 D:  Ver= 1.00 Cls=00(&gt;ifc ) Sub=00 Prot=00 MxPS= 8 #Cfgs=  1
 P:  Vendor=04b4 ProdID=0001 Rev= 0.00
 C:* #Ifs= 1 Cfg#= 1 Atr=80 MxPwr=100mA
 I:  If#= 0 Alt= 0 #EPs= 1 Cls=03(HID  ) Sub=01 Prot=02 Driver=mouse
 E:  Ad=81(I) Atr=03(Int.) MxPS=   3 Ivl= 10ms
 
-T:  Bus=00 Lev=02 Prnt=02 Port=02 Cnt=02 Dev#=  4 Spd=12  MxCh= 0
+T:  Bus=00 Lev=02 Prnt=02 Port=02 Cnt=02 Dev#=  4 Spd=12   MxCh= 0
 D:  Ver= 1.00 Cls=00(&gt;ifc ) Sub=00 Prot=00 MxPS= 8 #Cfgs=  1
 P:  Vendor=0565 ProdID=0001 Rev= 1.08
 S:  Manufacturer=Peracom Networks, Inc.
@@ -330,12 +340,12 @@ E:  Ad=82(I) Atr=03(Int.) MxPS=   8 Ivl=  8ms
 Selecting only the "T:" and "I:" lines from this (for example, by using
 "procusb ti"), we have:
 
-T:  Bus=00 Lev=00 Prnt=00 Port=00 Cnt=00 Dev#=  1 Spd=12  MxCh= 2
-T:  Bus=00 Lev=01 Prnt=01 Port=00 Cnt=01 Dev#=  2 Spd=12  MxCh= 4
+T:  Bus=00 Lev=00 Prnt=00 Port=00 Cnt=00 Dev#=  1 Spd=12   MxCh= 2
+T:  Bus=00 Lev=01 Prnt=01 Port=00 Cnt=01 Dev#=  2 Spd=12   MxCh= 4
 I:  If#= 0 Alt= 0 #EPs= 1 Cls=09(hub  ) Sub=00 Prot=00 Driver=hub
-T:  Bus=00 Lev=02 Prnt=02 Port=00 Cnt=01 Dev#=  3 Spd=1.5 MxCh= 0
+T:  Bus=00 Lev=02 Prnt=02 Port=00 Cnt=01 Dev#=  3 Spd=1.5  MxCh= 0
 I:  If#= 0 Alt= 0 #EPs= 1 Cls=03(HID  ) Sub=01 Prot=02 Driver=mouse
-T:  Bus=00 Lev=02 Prnt=02 Port=02 Cnt=02 Dev#=  4 Spd=12  MxCh= 0
+T:  Bus=00 Lev=02 Prnt=02 Port=02 Cnt=02 Dev#=  4 Spd=12   MxCh= 0
 I:  If#= 0 Alt= 0 #EPs= 3 Cls=00(&gt;ifc ) Sub=00 Prot=00 Driver=serial
 
 
diff --git a/drivers/usb/core/devices.c b/drivers/usb/core/devices.c
index 3449742c00e1..ddb4dc980923 100644
--- a/drivers/usb/core/devices.c
+++ b/drivers/usb/core/devices.c
@@ -66,8 +66,8 @@
 #define ALLOW_SERIAL_NUMBER
 
 static const char *format_topo =
-/* T:  Bus=dd Lev=dd Prnt=dd Port=dd Cnt=dd Dev#=ddd Spd=ddd MxCh=dd */
-"\nT:  Bus=%2.2d Lev=%2.2d Prnt=%2.2d Port=%2.2d Cnt=%2.2d Dev#=%3d Spd=%3s MxCh=%2d\n";
+/* T:  Bus=dd Lev=dd Prnt=dd Port=dd Cnt=dd Dev#=ddd Spd=dddd MxCh=dd */
+"\nT:  Bus=%2.2d Lev=%2.2d Prnt=%2.2d Port=%2.2d Cnt=%2.2d Dev#=%3d Spd=%-4s MxCh=%2d\n";
 
 static const char *format_string_manufacturer =
 /* S:  Manufacturer=xxxx */
@@ -520,11 +520,14 @@ static ssize_t usb_device_dump(char __user **buffer, size_t *nbytes,
 		speed = "1.5"; break;
 	case USB_SPEED_UNKNOWN:		/* usb 1.1 root hub code */
 	case USB_SPEED_FULL:
-		speed = "12 "; break;
+		speed = "12"; break;
+	case USB_SPEED_WIRELESS:	/* Wireless has no real fixed speed */
 	case USB_SPEED_HIGH:
 		speed = "480"; break;
+	case USB_SPEED_SUPER:
+		speed = "5000"; break;
 	default:
-		speed = "?? ";
+		speed = "??";
 	}
 	data_end = pages_start + sprintf(pages_start, format_topo,
 			bus-&gt;busnum, level, parent_devnum,</pre><hr><pre>commit 3df7169e73fc1d71a39cffeacc969f6840cdf52b
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Fri Sep 10 16:37:05 2010 -0400

    OHCI: work around for nVidia shutdown problem
    
    This patch (as1417) fixes a problem affecting some (or all) nVidia
    chipsets.  When the computer is shut down, the OHCI controllers
    continue to power the USB buses and evidently they drive a Reset
    signal out all their ports.  This prevents attached devices from going
    to low power.  Mouse LEDs stay on, for example, which is disconcerting
    for users and a drain on laptop batteries.
    
    The fix involves leaving each OHCI controller in the OPERATIONAL state
    during system shutdown rather than putting it in the RESET state.
    Although this nominally means the controller is running, in fact it's
    not doing very much since all the schedules are all disabled.  However
    there is ongoing DMA to the Host Controller Communications Area, so
    the patch also disables the bus-master capability of all PCI USB
    controllers after the shutdown routine runs.
    
    The fix is applied only to nVidia-based PCI OHCI controllers, so it
    shouldn't cause problems on systems using other hardware.  As an added
    safety measure, in case the kernel encounters one of these running
    controllers during boot, the patch changes quirk_usb_handoff_ohci()
    (which runs early on during PCI discovery) to reset the controller
    before anything bad can happen.
    
    Reported-by: Pali Rohár &lt;pali.rohar@gmail.com&gt;
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    CC: David Brownell &lt;david-b@pacbell.net&gt;
    Tested-by: Pali Rohár &lt;pali.rohar@gmail.com&gt;
    CC: stable &lt;stable@kernel.org&gt;
    Signed-off-by: Greg Kroah-Hartman &lt;gregkh@suse.de&gt;

diff --git a/drivers/usb/core/hcd-pci.c b/drivers/usb/core/hcd-pci.c
index c3f98543caaf..3799573bd385 100644
--- a/drivers/usb/core/hcd-pci.c
+++ b/drivers/usb/core/hcd-pci.c
@@ -329,8 +329,10 @@ void usb_hcd_pci_shutdown(struct pci_dev *dev)
 		return;
 
 	if (test_bit(HCD_FLAG_HW_ACCESSIBLE, &amp;hcd-&gt;flags) &amp;&amp;
-			hcd-&gt;driver-&gt;shutdown)
+			hcd-&gt;driver-&gt;shutdown) {
 		hcd-&gt;driver-&gt;shutdown(hcd);
+		pci_disable_device(dev);
+	}
 }
 EXPORT_SYMBOL_GPL(usb_hcd_pci_shutdown);
 
diff --git a/drivers/usb/host/ohci-hcd.c b/drivers/usb/host/ohci-hcd.c
index c3b4ccc7337b..8ef3c1944364 100644
--- a/drivers/usb/host/ohci-hcd.c
+++ b/drivers/usb/host/ohci-hcd.c
@@ -398,7 +398,14 @@ ohci_shutdown (struct usb_hcd *hcd)
 
 	ohci = hcd_to_ohci (hcd);
 	ohci_writel (ohci, OHCI_INTR_MIE, &amp;ohci-&gt;regs-&gt;intrdisable);
-	ohci_usb_reset (ohci);
+	ohci-&gt;hc_control = ohci_readl(ohci, &amp;ohci-&gt;regs-&gt;control);
+
+	/* If the SHUTDOWN quirk is set, don't put the controller in RESET */
+	ohci-&gt;hc_control &amp;= (ohci-&gt;flags &amp; OHCI_QUIRK_SHUTDOWN ?
+			OHCI_CTRL_RWC | OHCI_CTRL_HCFS :
+			OHCI_CTRL_RWC);
+	ohci_writel(ohci, ohci-&gt;hc_control, &amp;ohci-&gt;regs-&gt;control);
+
 	/* flush the writes */
 	(void) ohci_readl (ohci, &amp;ohci-&gt;regs-&gt;control);
 }
diff --git a/drivers/usb/host/ohci-pci.c b/drivers/usb/host/ohci-pci.c
index 6bdc8b25a6a1..36ee9a666e93 100644
--- a/drivers/usb/host/ohci-pci.c
+++ b/drivers/usb/host/ohci-pci.c
@@ -201,6 +201,20 @@ static int ohci_quirk_amd700(struct usb_hcd *hcd)
 	return 0;
 }
 
+/* nVidia controllers continue to drive Reset signalling on the bus
+ * even after system shutdown, wasting power.  This flag tells the
+ * shutdown routine to leave the controller OPERATIONAL instead of RESET.
+ */
+static int ohci_quirk_nvidia_shutdown(struct usb_hcd *hcd)
+{
+	struct ohci_hcd	*ohci = hcd_to_ohci(hcd);
+
+	ohci-&gt;flags |= OHCI_QUIRK_SHUTDOWN;
+	ohci_dbg(ohci, "enabled nVidia shutdown quirk\n");
+
+	return 0;
+}
+
 /*
  * The hardware normally enables the A-link power management feature, which
  * lets the system lower the power consumption in idle states.
@@ -332,6 +346,10 @@ static const struct pci_device_id ohci_pci_quirks[] = {
 		PCI_DEVICE(PCI_VENDOR_ID_ATI, 0x4399),
 		.driver_data = (unsigned long)ohci_quirk_amd700,
 	},
+	{
+		PCI_DEVICE(PCI_VENDOR_ID_NVIDIA, PCI_ANY_ID),
+		.driver_data = (unsigned long) ohci_quirk_nvidia_shutdown,
+	},
 
 	/* FIXME for some of the early AMD 760 southbridges, OHCI
 	 * won't work at all.  blacklist them.
diff --git a/drivers/usb/host/ohci.h b/drivers/usb/host/ohci.h
index 5bf15fed0d9f..51facb985c84 100644
--- a/drivers/usb/host/ohci.h
+++ b/drivers/usb/host/ohci.h
@@ -403,6 +403,7 @@ struct ohci_hcd {
 #define	OHCI_QUIRK_HUB_POWER	0x100			/* distrust firmware power/oc setup */
 #define	OHCI_QUIRK_AMD_ISO	0x200			/* ISO transfers*/
 #define	OHCI_QUIRK_AMD_PREFETCH	0x400			/* pre-fetch for ISO transfer */
+#define	OHCI_QUIRK_SHUTDOWN	0x800			/* nVidia power bug */
 	// there are also chip quirks/bugs in init logic
 
 	struct work_struct	nec_work;	/* Worker for NEC quirk */
diff --git a/drivers/usb/host/pci-quirks.c b/drivers/usb/host/pci-quirks.c
index 83b5f9cea85a..464ed977b45d 100644
--- a/drivers/usb/host/pci-quirks.c
+++ b/drivers/usb/host/pci-quirks.c
@@ -169,6 +169,7 @@ static int __devinit mmio_resource_enabled(struct pci_dev *pdev, int idx)
 static void __devinit quirk_usb_handoff_ohci(struct pci_dev *pdev)
 {
 	void __iomem *base;
+	u32 control;
 
 	if (!mmio_resource_enabled(pdev, 0))
 		return;
@@ -177,10 +178,14 @@ static void __devinit quirk_usb_handoff_ohci(struct pci_dev *pdev)
 	if (base == NULL)
 		return;
 
+	control = readl(base + OHCI_CONTROL);
+
 /* On PA-RISC, PDC can leave IR set incorrectly; ignore it there. */
-#ifndef __hppa__
-{
-	u32 control = readl(base + OHCI_CONTROL);
+#ifdef __hppa__
+#define	OHCI_CTRL_MASK		(OHCI_CTRL_RWC | OHCI_CTRL_IR)
+#else
+#define	OHCI_CTRL_MASK		OHCI_CTRL_RWC
+
 	if (control &amp; OHCI_CTRL_IR) {
 		int wait_time = 500; /* arbitrary; 5 seconds */
 		writel(OHCI_INTR_OC, base + OHCI_INTRENABLE);
@@ -194,13 +199,12 @@ static void __devinit quirk_usb_handoff_ohci(struct pci_dev *pdev)
 			dev_warn(&amp;pdev-&gt;dev, "OHCI: BIOS handoff failed"
 					" (BIOS bug?) %08x\n",
 					readl(base + OHCI_CONTROL));
-
-		/* reset controller, preserving RWC */
-		writel(control &amp; OHCI_CTRL_RWC, base + OHCI_CONTROL);
 	}
-}
 #endif
 
+	/* reset controller, preserving RWC (and possibly IR) */
+	writel(control &amp; OHCI_CTRL_MASK, base + OHCI_CONTROL);
+
 	/*
 	 * disable interrupts
 	 */</pre><hr><pre>commit d8087427ccefc0b3364735b96274375246fd452c
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Fri Sep 3 11:15:41 2010 -0400

    USB: g_file_storage: don't generate automatic serial string
    
    This patch (as1413) changes g_file_storage to avoid generating a bogus
    automatic serial-number string descriptor.  If the user doesn't provide
    a valid serial number via a module parameter then a warning is logged
    and the gadget won't have any serial string descriptor at all.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Acked-by: David Brownell &lt;david-b@pacbell.net&gt;
    CC: Michal Nazarewicz &lt;m.nazarewicz@samsung.com&gt;
    Signed-off-by: Greg Kroah-Hartman &lt;gregkh@suse.de&gt;

diff --git a/drivers/usb/gadget/file_storage.c b/drivers/usb/gadget/file_storage.c
index 132a1c0877bd..ce437f5dd674 100644
--- a/drivers/usb/gadget/file_storage.c
+++ b/drivers/usb/gadget/file_storage.c
@@ -89,6 +89,7 @@
  *				Required if "removable" is not set, names of
  *					the files or block devices used for
  *					backing storage
+ *	serial=HHHH...		Required serial number (string of hex chars)
  *	ro=b[,b...]		Default false, booleans for read-only access
  *	removable		Default false, boolean for removable media
  *	luns=N			Default N = number of filenames, number of
@@ -108,12 +109,11 @@
  *	vendor=0xVVVV		Default 0x0525 (NetChip), USB Vendor ID
  *	product=0xPPPP		Default 0xa4a5 (FSG), USB Product ID
  *	release=0xRRRR		Override the USB release number (bcdDevice)
- *	serial=HHHH...		Override serial number (string of hex chars)
  *	buflen=N		Default N=16384, buffer size used (will be
  *					rounded down to a multiple of
  *					PAGE_CACHE_SIZE)
  *
- * If CONFIG_USB_FILE_STORAGE_TEST is not set, only the "file", "ro",
+ * If CONFIG_USB_FILE_STORAGE_TEST is not set, only the "file", "serial", "ro",
  * "removable", "luns", "nofua", "stall", and "cdrom" options are available;
  * default values are used for everything else.
  *
@@ -273,13 +273,10 @@
 
 #define DRIVER_DESC		"File-backed Storage Gadget"
 #define DRIVER_NAME		"g_file_storage"
-/* DRIVER_VERSION must be at least 6 characters long, as it is used
- * to generate a fallback serial number. */
-#define DRIVER_VERSION		"20 November 2008"
+#define DRIVER_VERSION		"1 September 2010"
 
 static       char fsg_string_manufacturer[64];
 static const char fsg_string_product[] = DRIVER_DESC;
-static       char fsg_string_serial[13];
 static const char fsg_string_config[] = "Self-powered";
 static const char fsg_string_interface[] = "Mass Storage";
 
@@ -305,6 +302,7 @@ MODULE_LICENSE("Dual BSD/GPL");
 
 static struct {
 	char		*file[FSG_MAX_LUNS];
+	char		*serial;
 	int		ro[FSG_MAX_LUNS];
 	int		nofua[FSG_MAX_LUNS];
 	unsigned int	num_filenames;
@@ -321,7 +319,6 @@ static struct {
 	unsigned short	vendor;
 	unsigned short	product;
 	unsigned short	release;
-	char		*serial;
 	unsigned int	buflen;
 
 	int		transport_type;
@@ -346,6 +343,9 @@ module_param_array_named(file, mod_data.file, charp, &amp;mod_data.num_filenames,
 		S_IRUGO);
 MODULE_PARM_DESC(file, "names of backing files or devices");
 
+module_param_named(serial, mod_data.serial, charp, S_IRUGO);
+MODULE_PARM_DESC(serial, "USB serial number");
+
 module_param_array_named(ro, mod_data.ro, bool, &amp;mod_data.num_ros, S_IRUGO);
 MODULE_PARM_DESC(ro, "true to force read-only");
 
@@ -365,9 +365,6 @@ MODULE_PARM_DESC(stall, "false to prevent bulk stalls");
 module_param_named(cdrom, mod_data.cdrom, bool, S_IRUGO);
 MODULE_PARM_DESC(cdrom, "true to emulate cdrom instead of disk");
 
-module_param_named(serial, mod_data.serial, charp, S_IRUGO);
-MODULE_PARM_DESC(serial, "USB serial number");
-
 /* In the non-TEST version, only the module parameters listed above
  * are available. */
 #ifdef CONFIG_USB_FILE_STORAGE_TEST
@@ -3214,7 +3211,6 @@ static int __init check_parameters(struct fsg_dev *fsg)
 {
 	int	prot;
 	int	gcnum;
-	int	i;
 
 	/* Store the default values */
 	mod_data.transport_type = USB_PR_BULK;
@@ -3310,38 +3306,22 @@ static int __init check_parameters(struct fsg_dev *fsg)
 			if ((*ch &lt; '0' || *ch &gt; '9') &amp;&amp;
 			    (*ch &lt; 'A' || *ch &gt; 'F')) { /* not uppercase hex */
 				WARNING(fsg,
-					"Invalid serial string character: %c; "
-					"Failing back to default\n",
+					"Invalid serial string character: %c\n",
 					*ch);
-				goto fill_serial;
+				goto no_serial;
 			}
 		}
 		if (len &gt; 126 ||
 		    (mod_data.transport_type == USB_PR_BULK &amp;&amp; len &lt; 12) ||
 		    (mod_data.transport_type != USB_PR_BULK &amp;&amp; len &gt; 12)) {
-			WARNING(fsg,
-				"Invalid serial string length; "
-				"Failing back to default\n");
-			goto fill_serial;
+			WARNING(fsg, "Invalid serial string length!\n");
+			goto no_serial;
 		}
 		fsg_strings[FSG_STRING_SERIAL - 1].s = mod_data.serial;
 	} else {
-		WARNING(fsg,
-			"Userspace failed to provide serial number; "
-			"Failing back to default\n");
-fill_serial:
-		/* Serial number not specified or invalid, make our own.
-		 * We just encode it from the driver version string,
-		 * 12 characters to comply with both CB[I] and BBB spec.
-		 * Warning : Two devices running the same kernel will have
-		 * the same fallback serial number. */
-		for (i = 0; i &lt; 12; i += 2) {
-			unsigned char	c = DRIVER_VERSION[i / 2];
-
-			if (!c)
-				break;
-			sprintf(&amp;fsg_string_serial[i], "%02X", c);
-		}
+		WARNING(fsg, "No serial-number string provided!\n");
+ no_serial:
+		device_desc.iSerialNumber = 0;
 	}
 
 	return 0;
diff --git a/drivers/usb/gadget/storage_common.c b/drivers/usb/gadget/storage_common.c
index 484acfb1a7c5..d7856c599d5a 100644
--- a/drivers/usb/gadget/storage_common.c
+++ b/drivers/usb/gadget/storage_common.c
@@ -26,7 +26,6 @@
  * be defined (each of type pointer to char):
  *  - fsg_string_manufacturer -- name of the manufacturer
  *  - fsg_string_product      -- name of the product
- *  - fsg_string_serial       -- product's serial
  *  - fsg_string_config       -- name of the configuration
  *  - fsg_string_interface    -- name of the interface
  * The first four are only needed when FSG_DESCRIPTORS_DEVICE_STRINGS
@@ -552,7 +551,7 @@ static struct usb_string		fsg_strings[] = {
 #ifndef FSG_NO_DEVICE_STRINGS
 	{FSG_STRING_MANUFACTURER,	fsg_string_manufacturer},
 	{FSG_STRING_PRODUCT,		fsg_string_product},
-	{FSG_STRING_SERIAL,		fsg_string_serial},
+	{FSG_STRING_SERIAL,		""},
 	{FSG_STRING_CONFIG,		fsg_string_config},
 #endif
 	{FSG_STRING_INTERFACE,		fsg_string_interface},</pre><hr><pre>commit 15bcb91d7e607d8a2e060f01f7784a7454668da4
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Sat Sep 25 23:35:21 2010 +0200

    PM / Runtime: Implement autosuspend support
    
    This patch (as1427) implements the "autosuspend" facility for runtime
    PM.  A few new fields are added to the dev_pm_info structure and
    several new PM helper functions are defined, for telling the PM core
    whether or not a device uses autosuspend, for setting the autosuspend
    delay, and for marking periods of device activity.
    
    Drivers that do not want to use autosuspend can continue using the
    same helper functions as before; their behavior will not change.  In
    addition, drivers supporting autosuspend can also call the old helper
    functions to get the old behavior.
    
    The details are all explained in Documentation/power/runtime_pm.txt
    and Documentation/ABI/testing/sysfs-devices-power.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Rafael J. Wysocki &lt;rjw@sisk.pl&gt;

diff --git a/Documentation/ABI/testing/sysfs-devices-power b/Documentation/ABI/testing/sysfs-devices-power
index 6bb2dd3c3a71..7628cd1bc36a 100644
--- a/Documentation/ABI/testing/sysfs-devices-power
+++ b/Documentation/ABI/testing/sysfs-devices-power
@@ -147,3 +147,21 @@ Description:
 		milliseconds.  This attribute is read-only.  If the device is
 		not enabled to wake up the system from sleep states, this
 		attribute is empty.
+
+What:		/sys/devices/.../power/autosuspend_delay_ms
+Date:		September 2010
+Contact:	Alan Stern &lt;stern@rowland.harvard.edu&gt;
+Description:
+		The /sys/devices/.../power/autosuspend_delay_ms attribute
+		contains the autosuspend delay value (in milliseconds).  Some
+		drivers do not want their device to suspend as soon as it
+		becomes idle at run time; they want the device to remain
+		inactive for a certain minimum period of time first.  That
+		period is called the autosuspend delay.  Negative values will
+		prevent the device from being suspended at run time (similar
+		to writing "on" to the power/control attribute).  Values &gt;=
+		1000 will cause the autosuspend timer expiration to be rounded
+		up to the nearest second.
+
+		Not all drivers support this attribute.  If it isn't supported,
+		attempts to read or write it will yield I/O errors.
diff --git a/Documentation/power/runtime_pm.txt b/Documentation/power/runtime_pm.txt
index 9ba49b21ac86..489e9bacd165 100644
--- a/Documentation/power/runtime_pm.txt
+++ b/Documentation/power/runtime_pm.txt
@@ -158,7 +158,8 @@ rules:
     to execute it, the other callbacks will not be executed for the same device.
 
   * A request to execute -&gt;runtime_resume() will cancel any pending or
-    scheduled requests to execute the other callbacks for the same device.
+    scheduled requests to execute the other callbacks for the same device,
+    except for scheduled autosuspends.
 
 3. Run-time PM Device Fields
 
@@ -166,7 +167,7 @@ The following device run-time PM fields are present in 'struct dev_pm_info', as
 defined in include/linux/pm.h:
 
   struct timer_list suspend_timer;
-    - timer used for scheduling (delayed) suspend request
+    - timer used for scheduling (delayed) suspend and autosuspend requests
 
   unsigned long timer_expires;
     - timer expiration time, in jiffies (if this is different from zero, the
@@ -236,6 +237,23 @@ defined in include/linux/pm.h:
       Section 8); it may be modified only by the pm_runtime_no_callbacks()
       helper function
 
+  unsigned int use_autosuspend;
+    - indicates that the device's driver supports delayed autosuspend (see
+      Section 9); it may be modified only by the
+      pm_runtime{_dont}_use_autosuspend() helper functions
+
+  unsigned int timer_autosuspends;
+    - indicates that the PM core should attempt to carry out an autosuspend
+      when the timer expires rather than a normal suspend
+
+  int autosuspend_delay;
+    - the delay time (in milliseconds) to be used for autosuspend
+
+  unsigned long last_busy;
+    - the time (in jiffies) when the pm_runtime_mark_last_busy() helper
+      function was last called for this device; used in calculating inactivity
+      periods for autosuspend
+
 All of the above fields are members of the 'power' member of 'struct device'.
 
 4. Run-time PM Device Helper Functions
@@ -261,6 +279,12 @@ drivers/base/power/runtime.c and include/linux/pm_runtime.h:
       error code on failure, where -EAGAIN or -EBUSY means it is safe to attempt
       to suspend the device again in future
 
+  int pm_runtime_autosuspend(struct device *dev);
+    - same as pm_runtime_suspend() except that the autosuspend delay is taken
+      into account; if pm_runtime_autosuspend_expiration() says the delay has
+      not yet expired then an autosuspend is scheduled for the appropriate time
+      and 0 is returned
+
   int pm_runtime_resume(struct device *dev);
     - execute the subsystem-level resume callback for the device; returns 0 on
       success, 1 if the device's run-time PM status was already 'active' or
@@ -273,6 +297,11 @@ drivers/base/power/runtime.c and include/linux/pm_runtime.h:
       device (the request is represented by a work item in pm_wq); returns 0 on
       success or error code if the request has not been queued up
 
+  int pm_request_autosuspend(struct device *dev);
+    - schedule the execution of the subsystem-level suspend callback for the
+      device when the autosuspend delay has expired; if the delay has already
+      expired then the work item is queued up immediately
+
   int pm_schedule_suspend(struct device *dev, unsigned int delay);
     - schedule the execution of the subsystem-level suspend callback for the
       device in future, where 'delay' is the time to wait before queuing up a
@@ -304,12 +333,20 @@ drivers/base/power/runtime.c and include/linux/pm_runtime.h:
     - decrement the device's usage counter
 
   int pm_runtime_put(struct device *dev);
-    - decrement the device's usage counter, run pm_request_idle(dev) and return
-      its result
+    - decrement the device's usage counter; if the result is 0 then run
+      pm_request_idle(dev) and return its result
+
+  int pm_runtime_put_autosuspend(struct device *dev);
+    - decrement the device's usage counter; if the result is 0 then run
+      pm_request_autosuspend(dev) and return its result
 
   int pm_runtime_put_sync(struct device *dev);
-    - decrement the device's usage counter, run pm_runtime_idle(dev) and return
-      its result
+    - decrement the device's usage counter; if the result is 0 then run
+      pm_runtime_idle(dev) and return its result
+
+  int pm_runtime_put_sync_autosuspend(struct device *dev);
+    - decrement the device's usage counter; if the result is 0 then run
+      pm_runtime_autosuspend(dev) and return its result
 
   void pm_runtime_enable(struct device *dev);
     - enable the run-time PM helper functions to run the device bus type's
@@ -360,19 +397,46 @@ drivers/base/power/runtime.c and include/linux/pm_runtime.h:
       PM attributes from /sys/devices/.../power (or prevent them from being
       added when the device is registered)
 
+  void pm_runtime_mark_last_busy(struct device *dev);
+    - set the power.last_busy field to the current time
+
+  void pm_runtime_use_autosuspend(struct device *dev);
+    - set the power.use_autosuspend flag, enabling autosuspend delays
+
+  void pm_runtime_dont_use_autosuspend(struct device *dev);
+    - clear the power.use_autosuspend flag, disabling autosuspend delays
+
+  void pm_runtime_set_autosuspend_delay(struct device *dev, int delay);
+    - set the power.autosuspend_delay value to 'delay' (expressed in
+      milliseconds); if 'delay' is negative then run-time suspends are
+      prevented
+
+  unsigned long pm_runtime_autosuspend_expiration(struct device *dev);
+    - calculate the time when the current autosuspend delay period will expire,
+      based on power.last_busy and power.autosuspend_delay; if the delay time
+      is 1000 ms or larger then the expiration time is rounded up to the
+      nearest second; returns 0 if the delay period has already expired or
+      power.use_autosuspend isn't set, otherwise returns the expiration time
+      in jiffies
+
 It is safe to execute the following helper functions from interrupt context:
 
 pm_request_idle()
+pm_request_autosuspend()
 pm_schedule_suspend()
 pm_request_resume()
 pm_runtime_get_noresume()
 pm_runtime_get()
 pm_runtime_put_noidle()
 pm_runtime_put()
+pm_runtime_put_autosuspend()
+pm_runtime_enable()
 pm_suspend_ignore_children()
 pm_runtime_set_active()
 pm_runtime_set_suspended()
-pm_runtime_enable()
+pm_runtime_suspended()
+pm_runtime_mark_last_busy()
+pm_runtime_autosuspend_expiration()
 
 5. Run-time PM Initialization, Device Probing and Removal
 
@@ -561,3 +625,115 @@ As a consequence, the PM core will never directly inform the device's subsystem
 or driver about run-time power changes.  Instead, the driver for the device's
 parent must take responsibility for telling the device's driver when the
 parent's power state changes.
+
+9. Autosuspend, or automatically-delayed suspends
+
+Changing a device's power state isn't free; it requires both time and energy.
+A device should be put in a low-power state only when there's some reason to
+think it will remain in that state for a substantial time.  A common heuristic
+says that a device which hasn't been used for a while is liable to remain
+unused; following this advice, drivers should not allow devices to be suspended
+at run-time until they have been inactive for some minimum period.  Even when
+the heuristic ends up being non-optimal, it will still prevent devices from
+"bouncing" too rapidly between low-power and full-power states.
+
+The term "autosuspend" is an historical remnant.  It doesn't mean that the
+device is automatically suspended (the subsystem or driver still has to call
+the appropriate PM routines); rather it means that run-time suspends will
+automatically be delayed until the desired period of inactivity has elapsed.
+
+Inactivity is determined based on the power.last_busy field.  Drivers should
+call pm_runtime_mark_last_busy() to update this field after carrying out I/O,
+typically just before calling pm_runtime_put_autosuspend().  The desired length
+of the inactivity period is a matter of policy.  Subsystems can set this length
+initially by calling pm_runtime_set_autosuspend_delay(), but after device
+registration the length should be controlled by user space, using the
+/sys/devices/.../power/autosuspend_delay_ms attribute.
+
+In order to use autosuspend, subsystems or drivers must call
+pm_runtime_use_autosuspend() (preferably before registering the device), and
+thereafter they should use the various *_autosuspend() helper functions instead
+of the non-autosuspend counterparts:
+
+	Instead of: pm_runtime_suspend    use: pm_runtime_autosuspend;
+	Instead of: pm_schedule_suspend   use: pm_request_autosuspend;
+	Instead of: pm_runtime_put        use: pm_runtime_put_autosuspend;
+	Instead of: pm_runtime_put_sync   use: pm_runtime_put_sync_autosuspend.
+
+Drivers may also continue to use the non-autosuspend helper functions; they
+will behave normally, not taking the autosuspend delay into account.
+Similarly, if the power.use_autosuspend field isn't set then the autosuspend
+helper functions will behave just like the non-autosuspend counterparts.
+
+The implementation is well suited for asynchronous use in interrupt contexts.
+However such use inevitably involves races, because the PM core can't
+synchronize -&gt;runtime_suspend() callbacks with the arrival of I/O requests.
+This synchronization must be handled by the driver, using its private lock.
+Here is a schematic pseudo-code example:
+
+	foo_read_or_write(struct foo_priv *foo, void *data)
+	{
+		lock(&amp;foo-&gt;private_lock);
+		add_request_to_io_queue(foo, data);
+		if (foo-&gt;num_pending_requests++ == 0)
+			pm_runtime_get(&amp;foo-&gt;dev);
+		if (!foo-&gt;is_suspended)
+			foo_process_next_request(foo);
+		unlock(&amp;foo-&gt;private_lock);
+	}
+
+	foo_io_completion(struct foo_priv *foo, void *req)
+	{
+		lock(&amp;foo-&gt;private_lock);
+		if (--foo-&gt;num_pending_requests == 0) {
+			pm_runtime_mark_last_busy(&amp;foo-&gt;dev);
+			pm_runtime_put_autosuspend(&amp;foo-&gt;dev);
+		} else {
+			foo_process_next_request(foo);
+		}
+		unlock(&amp;foo-&gt;private_lock);
+		/* Send req result back to the user ... */
+	}
+
+	int foo_runtime_suspend(struct device *dev)
+	{
+		struct foo_priv foo = container_of(dev, ...);
+		int ret = 0;
+
+		lock(&amp;foo-&gt;private_lock);
+		if (foo-&gt;num_pending_requests &gt; 0) {
+			ret = -EBUSY;
+		} else {
+			/* ... suspend the device ... */
+			foo-&gt;is_suspended = 1;
+		}
+		unlock(&amp;foo-&gt;private_lock);
+		return ret;
+	}
+
+	int foo_runtime_resume(struct device *dev)
+	{
+		struct foo_priv foo = container_of(dev, ...);
+
+		lock(&amp;foo-&gt;private_lock);
+		/* ... resume the device ... */
+		foo-&gt;is_suspended = 0;
+		pm_runtime_mark_last_busy(&amp;foo-&gt;dev);
+		if (foo-&gt;num_pending_requests &gt; 0)
+			foo_process_requests(foo);
+		unlock(&amp;foo-&gt;private_lock);
+		return 0;
+	}
+
+The important point is that after foo_io_completion() asks for an autosuspend,
+the foo_runtime_suspend() callback may race with foo_read_or_write().
+Therefore foo_runtime_suspend() has to check whether there are any pending I/O
+requests (while holding the private lock) before allowing the suspend to
+proceed.
+
+In addition, the power.autosuspend_delay field can be changed by user space at
+any time.  If a driver cares about this, it can call
+pm_runtime_autosuspend_expiration() from within the -&gt;runtime_suspend()
+callback while holding its private lock.  If the function returns a nonzero
+value then the delay has not yet expired and the callback should return
+-EAGAIN.
diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 5bd4daa93ef1..cd4e100a1362 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -9,7 +9,6 @@
 
 #include &lt;linux/sched.h&gt;
 #include &lt;linux/pm_runtime.h&gt;
-#include &lt;linux/jiffies.h&gt;
 #include "power.h"
 
 static int rpm_resume(struct device *dev, int rpmflags);
@@ -79,6 +78,53 @@ static void pm_runtime_cancel_pending(struct device *dev)
 	dev-&gt;power.request = RPM_REQ_NONE;
 }
 
+/*
+ * pm_runtime_autosuspend_expiration - Get a device's autosuspend-delay expiration time.
+ * @dev: Device to handle.
+ *
+ * Compute the autosuspend-delay expiration time based on the device's
+ * power.last_busy time.  If the delay has already expired or is disabled
+ * (negative) or the power.use_autosuspend flag isn't set, return 0.
+ * Otherwise return the expiration time in jiffies (adjusted to be nonzero).
+ *
+ * This function may be called either with or without dev-&gt;power.lock held.
+ * Either way it can be racy, since power.last_busy may be updated at any time.
+ */
+unsigned long pm_runtime_autosuspend_expiration(struct device *dev)
+{
+	int autosuspend_delay;
+	long elapsed;
+	unsigned long last_busy;
+	unsigned long expires = 0;
+
+	if (!dev-&gt;power.use_autosuspend)
+		goto out;
+
+	autosuspend_delay = ACCESS_ONCE(dev-&gt;power.autosuspend_delay);
+	if (autosuspend_delay &lt; 0)
+		goto out;
+
+	last_busy = ACCESS_ONCE(dev-&gt;power.last_busy);
+	elapsed = jiffies - last_busy;
+	if (elapsed &lt; 0)
+		goto out;	/* jiffies has wrapped around. */
+
+	/*
+	 * If the autosuspend_delay is &gt;= 1 second, align the timer by rounding
+	 * up to the nearest second.
+	 */
+	expires = last_busy + msecs_to_jiffies(autosuspend_delay);
+	if (autosuspend_delay &gt;= 1000)
+		expires = round_jiffies(expires);
+	expires += !expires;
+	if (elapsed &gt;= expires - last_busy)
+		expires = 0;	/* Already expired. */
+
+ out:
+	return expires;
+}
+EXPORT_SYMBOL_GPL(pm_runtime_autosuspend_expiration);
+
 /**
  * rpm_check_suspend_allowed - Test whether a device may be suspended.
  * @dev: Device to test.
@@ -234,6 +280,32 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	if (retval)
 		goto out;
 
+	/* If the autosuspend_delay time hasn't expired yet, reschedule. */
+	if ((rpmflags &amp; RPM_AUTO)
+	    &amp;&amp; dev-&gt;power.runtime_status != RPM_SUSPENDING) {
+		unsigned long expires = pm_runtime_autosuspend_expiration(dev);
+
+		if (expires != 0) {
+			/* Pending requests need to be canceled. */
+			dev-&gt;power.request = RPM_REQ_NONE;
+
+			/*
+			 * Optimization: If the timer is already running and is
+			 * set to expire at or before the autosuspend delay,
+			 * avoid the overhead of resetting it.  Just let it
+			 * expire; pm_suspend_timer_fn() will take care of the
+			 * rest.
+			 */
+			if (!(dev-&gt;power.timer_expires &amp;&amp; time_before_eq(
+			    dev-&gt;power.timer_expires, expires))) {
+				dev-&gt;power.timer_expires = expires;
+				mod_timer(&amp;dev-&gt;power.suspend_timer, expires);
+			}
+			dev-&gt;power.timer_autosuspends = 1;
+			goto out;
+		}
+	}
+
 	/* Other scheduled or pending requests need to be canceled. */
 	pm_runtime_cancel_pending(dev);
 
@@ -268,7 +340,8 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 
 	/* Carry out an asynchronous or a synchronous suspend. */
 	if (rpmflags &amp; RPM_ASYNC) {
-		dev-&gt;power.request = RPM_REQ_SUSPEND;
+		dev-&gt;power.request = (rpmflags &amp; RPM_AUTO) ?
+		    RPM_REQ_AUTOSUSPEND : RPM_REQ_SUSPEND;
 		if (!dev-&gt;power.request_pending) {
 			dev-&gt;power.request_pending = true;
 			queue_work(pm_wq, &amp;dev-&gt;power.work);
@@ -383,8 +456,15 @@ static int rpm_resume(struct device *dev, int rpmflags)
 	if (retval)
 		goto out;
 
-	/* Other scheduled or pending requests need to be canceled. */
-	pm_runtime_cancel_pending(dev);
+	/*
+	 * Other scheduled or pending requests need to be canceled.  Small
+	 * optimization: If an autosuspend timer is running, leave it running
+	 * rather than cancelling it now only to restart it again in the near
+	 * future.
+	 */
+	dev-&gt;power.request = RPM_REQ_NONE;
+	if (!dev-&gt;power.timer_autosuspends)
+		pm_runtime_deactivate_timer(dev);
 
 	if (dev-&gt;power.runtime_status == RPM_ACTIVE) {
 		retval = 1;
@@ -568,6 +648,9 @@ static void pm_runtime_work(struct work_struct *work)
 	case RPM_REQ_SUSPEND:
 		rpm_suspend(dev, RPM_NOWAIT);
 		break;
+	case RPM_REQ_AUTOSUSPEND:
+		rpm_suspend(dev, RPM_NOWAIT | RPM_AUTO);
+		break;
 	case RPM_REQ_RESUME:
 		rpm_resume(dev, RPM_NOWAIT);
 		break;
@@ -595,7 +678,8 @@ static void pm_suspend_timer_fn(unsigned long data)
 	/* If 'expire' is after 'jiffies' we've been called too early. */
 	if (expires &gt; 0 &amp;&amp; !time_after(expires, jiffies)) {
 		dev-&gt;power.timer_expires = 0;
-		rpm_suspend(dev, RPM_ASYNC);
+		rpm_suspend(dev, dev-&gt;power.timer_autosuspends ?
+		    (RPM_ASYNC | RPM_AUTO) : RPM_ASYNC);
 	}
 
 	spin_unlock_irqrestore(&amp;dev-&gt;power.lock, flags);
@@ -627,6 +711,7 @@ int pm_schedule_suspend(struct device *dev, unsigned int delay)
 
 	dev-&gt;power.timer_expires = jiffies + msecs_to_jiffies(delay);
 	dev-&gt;power.timer_expires += !dev-&gt;power.timer_expires;
+	dev-&gt;power.timer_autosuspends = 0;
 	mod_timer(&amp;dev-&gt;power.suspend_timer, dev-&gt;power.timer_expires);
 
  out:
@@ -670,7 +755,9 @@ EXPORT_SYMBOL_GPL(__pm_runtime_idle);
  * @dev: Device to suspend.
  * @rpmflags: Flag bits.
  *
- * Carry out a suspend, either synchronous or asynchronous.
+ * If the RPM_GET_PUT flag is set, decrement the device's usage count and
+ * return immediately if it is larger than zero.  Then carry out a suspend,
+ * either synchronous or asynchronous.
  *
  * This routine may be called in atomic context if the RPM_ASYNC flag is set.
  */
@@ -679,6 +766,11 @@ int __pm_runtime_suspend(struct device *dev, int rpmflags)
 	unsigned long flags;
 	int retval;
 
+	if (rpmflags &amp; RPM_GET_PUT) {
+		if (!atomic_dec_and_test(&amp;dev-&gt;power.usage_count))
+			return 0;
+	}
+
 	spin_lock_irqsave(&amp;dev-&gt;power.lock, flags);
 	retval = rpm_suspend(dev, rpmflags);
 	spin_unlock_irqrestore(&amp;dev-&gt;power.lock, flags);
@@ -980,7 +1072,7 @@ void pm_runtime_allow(struct device *dev)
 
 	dev-&gt;power.runtime_auto = true;
 	if (atomic_dec_and_test(&amp;dev-&gt;power.usage_count))
-		rpm_idle(dev, 0);
+		rpm_idle(dev, RPM_AUTO);
 
  out:
 	spin_unlock_irq(&amp;dev-&gt;power.lock);
@@ -1006,6 +1098,86 @@ void pm_runtime_no_callbacks(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(pm_runtime_no_callbacks);
 
+/**
+ * update_autosuspend - Handle a change to a device's autosuspend settings.
+ * @dev: Device to handle.
+ * @old_delay: The former autosuspend_delay value.
+ * @old_use: The former use_autosuspend value.
+ *
+ * Prevent runtime suspend if the new delay is negative and use_autosuspend is
+ * set; otherwise allow it.  Send an idle notification if suspends are allowed.
+ *
+ * This function must be called under dev-&gt;power.lock with interrupts disabled.
+ */
+static void update_autosuspend(struct device *dev, int old_delay, int old_use)
+{
+	int delay = dev-&gt;power.autosuspend_delay;
+
+	/* Should runtime suspend be prevented now? */
+	if (dev-&gt;power.use_autosuspend &amp;&amp; delay &lt; 0) {
+
+		/* If it used to be allowed then prevent it. */
+		if (!old_use || old_delay &gt;= 0) {
+			atomic_inc(&amp;dev-&gt;power.usage_count);
+			rpm_resume(dev, 0);
+		}
+	}
+
+	/* Runtime suspend should be allowed now. */
+	else {
+
+		/* If it used to be prevented then allow it. */
+		if (old_use &amp;&amp; old_delay &lt; 0)
+			atomic_dec(&amp;dev-&gt;power.usage_count);
+
+		/* Maybe we can autosuspend now. */
+		rpm_idle(dev, RPM_AUTO);
+	}
+}
+
+/**
+ * pm_runtime_set_autosuspend_delay - Set a device's autosuspend_delay value.
+ * @dev: Device to handle.
+ * @delay: Value of the new delay in milliseconds.
+ *
+ * Set the device's power.autosuspend_delay value.  If it changes to negative
+ * and the power.use_autosuspend flag is set, prevent run-time suspends.  If it
+ * changes the other way, allow run-time suspends.
+ */
+void pm_runtime_set_autosuspend_delay(struct device *dev, int delay)
+{
+	int old_delay, old_use;
+
+	spin_lock_irq(&amp;dev-&gt;power.lock);
+	old_delay = dev-&gt;power.autosuspend_delay;
+	old_use = dev-&gt;power.use_autosuspend;
+	dev-&gt;power.autosuspend_delay = delay;
+	update_autosuspend(dev, old_delay, old_use);
+	spin_unlock_irq(&amp;dev-&gt;power.lock);
+}
+EXPORT_SYMBOL_GPL(pm_runtime_set_autosuspend_delay);
+
+/**
+ * __pm_runtime_use_autosuspend - Set a device's use_autosuspend flag.
+ * @dev: Device to handle.
+ * @use: New value for use_autosuspend.
+ *
+ * Set the device's power.use_autosuspend flag, and allow or prevent run-time
+ * suspends as needed.
+ */
+void __pm_runtime_use_autosuspend(struct device *dev, bool use)
+{
+	int old_delay, old_use;
+
+	spin_lock_irq(&amp;dev-&gt;power.lock);
+	old_delay = dev-&gt;power.autosuspend_delay;
+	old_use = dev-&gt;power.use_autosuspend;
+	dev-&gt;power.use_autosuspend = use;
+	update_autosuspend(dev, old_delay, old_use);
+	spin_unlock_irq(&amp;dev-&gt;power.lock);
+}
+EXPORT_SYMBOL_GPL(__pm_runtime_use_autosuspend);
+
 /**
  * pm_runtime_init - Initialize run-time PM fields in given device object.
  * @dev: Device object to initialize.
diff --git a/drivers/base/power/sysfs.c b/drivers/base/power/sysfs.c
index b5708c47ce2d..0b1e46bf3e56 100644
--- a/drivers/base/power/sysfs.c
+++ b/drivers/base/power/sysfs.c
@@ -75,6 +75,18 @@
  *	attribute is set to "enabled" by bus type code or device drivers and in
  *	that cases it should be safe to leave the default value.
  *
+ *	autosuspend_delay_ms - Report/change a device's autosuspend_delay value
+ *
+ *	Some drivers don't want to carry out a runtime suspend as soon as a
+ *	device becomes idle; they want it always to remain idle for some period
+ *	of time before suspending it.  This period is the autosuspend_delay
+ *	value (expressed in milliseconds) and it can be controlled by the user.
+ *	If the value is negative then the device will never be runtime
+ *	suspended.
+ *
+ *	NOTE: The autosuspend_delay_ms attribute and the autosuspend_delay
+ *	value are used only if the driver calls pm_runtime_use_autosuspend().
+ *
  *	wakeup_count - Report the number of wakeup events related to the device
  */
 
@@ -173,6 +185,33 @@ static ssize_t rtpm_status_show(struct device *dev,
 }
 
 static DEVICE_ATTR(runtime_status, 0444, rtpm_status_show, NULL);
+
+static ssize_t autosuspend_delay_ms_show(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	if (!dev-&gt;power.use_autosuspend)
+		return -EIO;
+	return sprintf(buf, "%d\n", dev-&gt;power.autosuspend_delay);
+}
+
+static ssize_t autosuspend_delay_ms_store(struct device *dev,
+		struct device_attribute *attr, const char *buf, size_t n)
+{
+	long delay;
+
+	if (!dev-&gt;power.use_autosuspend)
+		return -EIO;
+
+	if (strict_strtol(buf, 10, &amp;delay) != 0 || delay != (int) delay)
+		return -EINVAL;
+
+	pm_runtime_set_autosuspend_delay(dev, delay);
+	return n;
+}
+
+static DEVICE_ATTR(autosuspend_delay_ms, 0644, autosuspend_delay_ms_show,
+		autosuspend_delay_ms_store);
+
 #endif
 
 static ssize_t
@@ -428,6 +467,7 @@ static struct attribute *runtime_attrs[] = {
 	&amp;dev_attr_control.attr,
 	&amp;dev_attr_runtime_suspended_time.attr,
 	&amp;dev_attr_runtime_active_time.attr,
+	&amp;dev_attr_autosuspend_delay_ms.attr,
 	NULL,
 };
 static struct attribute_group pm_runtime_attr_group = {
diff --git a/include/linux/pm.h b/include/linux/pm.h
index abd81ffaba3c..40f3f45702ba 100644
--- a/include/linux/pm.h
+++ b/include/linux/pm.h
@@ -444,6 +444,9 @@ enum rpm_status {
  *
  * RPM_REQ_SUSPEND	Run the device bus type's -&gt;runtime_suspend() callback
  *
+ * RPM_REQ_AUTOSUSPEND	Same as RPM_REQ_SUSPEND, but not until the device has
+ *			been inactive for as long as power.autosuspend_delay
+ *
  * RPM_REQ_RESUME	Run the device bus type's -&gt;runtime_resume() callback
  */
 
@@ -451,6 +454,7 @@ enum rpm_request {
 	RPM_REQ_NONE = 0,
 	RPM_REQ_IDLE,
 	RPM_REQ_SUSPEND,
+	RPM_REQ_AUTOSUSPEND,
 	RPM_REQ_RESUME,
 };
 
@@ -482,9 +486,13 @@ struct dev_pm_info {
 	unsigned int		run_wake:1;
 	unsigned int		runtime_auto:1;
 	unsigned int		no_callbacks:1;
+	unsigned int		use_autosuspend:1;
+	unsigned int		timer_autosuspends:1;
 	enum rpm_request	request;
 	enum rpm_status		runtime_status;
 	int			runtime_error;
+	int			autosuspend_delay;
+	unsigned long		last_busy;
 	unsigned long		active_jiffies;
 	unsigned long		suspended_jiffies;
 	unsigned long		accounting_timestamp;
diff --git a/include/linux/pm_runtime.h b/include/linux/pm_runtime.h
index 8ca52f7c357e..99ed1aa8f933 100644
--- a/include/linux/pm_runtime.h
+++ b/include/linux/pm_runtime.h
@@ -12,12 +12,15 @@
 #include &lt;linux/device.h&gt;
 #include &lt;linux/pm.h&gt;
 
+#include &lt;linux/jiffies.h&gt;
+
 /* Runtime PM flag argument bits */
 #define RPM_ASYNC		0x01	/* Request is asynchronous */
 #define RPM_NOWAIT		0x02	/* Don't wait for concurrent
 					    state change */
 #define RPM_GET_PUT		0x04	/* Increment/decrement the
 					    usage_count */
+#define RPM_AUTO		0x08	/* Use autosuspend_delay */
 
 #ifdef CONFIG_PM_RUNTIME
 
@@ -37,6 +40,9 @@ extern int pm_generic_runtime_idle(struct device *dev);
 extern int pm_generic_runtime_suspend(struct device *dev);
 extern int pm_generic_runtime_resume(struct device *dev);
 extern void pm_runtime_no_callbacks(struct device *dev);
+extern void __pm_runtime_use_autosuspend(struct device *dev, bool use);
+extern void pm_runtime_set_autosuspend_delay(struct device *dev, int delay);
+extern unsigned long pm_runtime_autosuspend_expiration(struct device *dev);
 
 static inline bool pm_children_suspended(struct device *dev)
 {
@@ -74,6 +80,11 @@ static inline bool pm_runtime_suspended(struct device *dev)
 	return dev-&gt;power.runtime_status == RPM_SUSPENDED;
 }
 
+static inline void pm_runtime_mark_last_busy(struct device *dev)
+{
+	ACCESS_ONCE(dev-&gt;power.last_busy) = jiffies;
+}
+
 #else /* !CONFIG_PM_RUNTIME */
 
 static inline int __pm_runtime_idle(struct device *dev, int rpmflags)
@@ -113,6 +124,14 @@ static inline int pm_generic_runtime_suspend(struct device *dev) { return 0; }
 static inline int pm_generic_runtime_resume(struct device *dev) { return 0; }
 static inline void pm_runtime_no_callbacks(struct device *dev) {}
 
+static inline void pm_runtime_mark_last_busy(struct device *dev) {}
+static inline void __pm_runtime_use_autosuspend(struct device *dev,
+						bool use) {}
+static inline void pm_runtime_set_autosuspend_delay(struct device *dev,
+						int delay) {}
+static inline unsigned long pm_runtime_autosuspend_expiration(
+				struct device *dev) { return 0; }
+
 #endif /* !CONFIG_PM_RUNTIME */
 
 static inline int pm_runtime_idle(struct device *dev)
@@ -125,6 +144,11 @@ static inline int pm_runtime_suspend(struct device *dev)
 	return __pm_runtime_suspend(dev, 0);
 }
 
+static inline int pm_runtime_autosuspend(struct device *dev)
+{
+	return __pm_runtime_suspend(dev, RPM_AUTO);
+}
+
 static inline int pm_runtime_resume(struct device *dev)
 {
 	return __pm_runtime_resume(dev, 0);
@@ -155,11 +179,22 @@ static inline int pm_runtime_put(struct device *dev)
 	return __pm_runtime_idle(dev, RPM_GET_PUT | RPM_ASYNC);
 }
 
+static inline int pm_runtime_put_autosuspend(struct device *dev)
+{
+	return __pm_runtime_suspend(dev,
+	    RPM_GET_PUT | RPM_ASYNC | RPM_AUTO);
+}
+
 static inline int pm_runtime_put_sync(struct device *dev)
 {
 	return __pm_runtime_idle(dev, RPM_GET_PUT);
 }
 
+static inline int pm_runtime_put_sync_autosuspend(struct device *dev)
+{
+	return __pm_runtime_suspend(dev, RPM_GET_PUT | RPM_AUTO);
+}
+
 static inline int pm_runtime_set_active(struct device *dev)
 {
 	return __pm_runtime_set_status(dev, RPM_ACTIVE);
@@ -175,4 +210,14 @@ static inline void pm_runtime_disable(struct device *dev)
 	__pm_runtime_disable(dev, true);
 }
 
+static inline void pm_runtime_use_autosuspend(struct device *dev)
+{
+	__pm_runtime_use_autosuspend(dev, true);
+}
+
+static inline void pm_runtime_dont_use_autosuspend(struct device *dev)
+{
+	__pm_runtime_use_autosuspend(dev, false);
+}
+
 #endif</pre><hr><pre>commit 7490e44239e60293bca0c2663229050c36c660c2
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Sat Sep 25 23:35:15 2010 +0200

    PM / Runtime: Add no_callbacks flag
    
    Some devices, such as USB interfaces, cannot be power-managed
    independently of their parents, i.e., they cannot be put in low power
    while the parent remains at full power.  This patch (as1425) creates a
    new "no_callbacks" flag, which tells the PM core not to invoke the
    runtime-PM callback routines for the such devices but instead to
    assume that the callbacks always succeed.  In addition, the
    non-debugging runtime-PM sysfs attributes for the devices are removed,
    since they are pretty much meaningless.
    
    The advantage of this scheme comes not so much from avoiding the
    callbacks themselves, but rather from the fact that without the need
    for a process context in which to run the callbacks, more work can be
    done in interrupt context.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Rafael J. Wysocki &lt;rjw@sisk.pl&gt;

diff --git a/Documentation/power/runtime_pm.txt b/Documentation/power/runtime_pm.txt
index 55b859b3bc72..9ba49b21ac86 100644
--- a/Documentation/power/runtime_pm.txt
+++ b/Documentation/power/runtime_pm.txt
@@ -1,6 +1,7 @@
 Run-time Power Management Framework for I/O Devices
 
 (C) 2009 Rafael J. Wysocki &lt;rjw@sisk.pl&gt;, Novell Inc.
+(C) 2010 Alan Stern &lt;stern@rowland.harvard.edu&gt;
 
 1. Introduction
 
@@ -230,6 +231,11 @@ defined in include/linux/pm.h:
       interface; it may only be modified with the help of the pm_runtime_allow()
       and pm_runtime_forbid() helper functions
 
+  unsigned int no_callbacks;
+    - indicates that the device does not use the run-time PM callbacks (see
+      Section 8); it may be modified only by the pm_runtime_no_callbacks()
+      helper function
+
 All of the above fields are members of the 'power' member of 'struct device'.
 
 4. Run-time PM Device Helper Functions
@@ -349,6 +355,11 @@ drivers/base/power/runtime.c and include/linux/pm_runtime.h:
       counter (used by the /sys/devices/.../power/control interface to
       effectively prevent the device from being power managed at run time)
 
+  void pm_runtime_no_callbacks(struct device *dev);
+    - set the power.no_callbacks flag for the device and remove the run-time
+      PM attributes from /sys/devices/.../power (or prevent them from being
+      added when the device is registered)
+
 It is safe to execute the following helper functions from interrupt context:
 
 pm_request_idle()
@@ -524,3 +535,29 @@ poweroff and run-time suspend callback, and similarly for system resume, thaw,
 restore, and run-time resume, can achieve this with the help of the
 UNIVERSAL_DEV_PM_OPS macro defined in include/linux/pm.h (possibly setting its
 last argument to NULL).
+
+8. "No-Callback" Devices
+
+Some "devices" are only logical sub-devices of their parent and cannot be
+power-managed on their own.  (The prototype example is a USB interface.  Entire
+USB devices can go into low-power mode or send wake-up requests, but neither is
+possible for individual interfaces.)  The drivers for these devices have no
+need of run-time PM callbacks; if the callbacks did exist, -&gt;runtime_suspend()
+and -&gt;runtime_resume() would always return 0 without doing anything else and
+-&gt;runtime_idle() would always call pm_runtime_suspend().
+
+Subsystems can tell the PM core about these devices by calling
+pm_runtime_no_callbacks().  This should be done after the device structure is
+initialized and before it is registered (although after device registration is
+also okay).  The routine will set the device's power.no_callbacks flag and
+prevent the non-debugging run-time PM sysfs attributes from being created.
+
+When power.no_callbacks is set, the PM core will not invoke the
+-&gt;runtime_idle(), -&gt;runtime_suspend(), or -&gt;runtime_resume() callbacks.
+Instead it will assume that suspends and resumes always succeed and that idle
+devices should be suspended.
+
+As a consequence, the PM core will never directly inform the device's subsystem
+or driver about run-time power changes.  Instead, the driver for the device's
+parent must take responsibility for telling the device's driver when the
+parent's power state changes.
diff --git a/drivers/base/power/power.h b/drivers/base/power/power.h
index 8b2745c69e2a..698dde742587 100644
--- a/drivers/base/power/power.h
+++ b/drivers/base/power/power.h
@@ -60,6 +60,7 @@ static inline void device_pm_move_last(struct device *dev) {}
 
 extern int dpm_sysfs_add(struct device *);
 extern void dpm_sysfs_remove(struct device *);
+extern void rpm_sysfs_remove(struct device *);
 
 #else /* CONFIG_PM */
 
diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index ed227b7c1bb5..5bd4daa93ef1 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -10,8 +10,10 @@
 #include &lt;linux/sched.h&gt;
 #include &lt;linux/pm_runtime.h&gt;
 #include &lt;linux/jiffies.h&gt;
+#include "power.h"
 
 static int rpm_resume(struct device *dev, int rpmflags);
+static int rpm_suspend(struct device *dev, int rpmflags);
 
 /**
  * update_pm_runtime_accounting - Update the time accounting of power states
@@ -148,6 +150,12 @@ static int rpm_idle(struct device *dev, int rpmflags)
 	/* Pending requests need to be canceled. */
 	dev-&gt;power.request = RPM_REQ_NONE;
 
+	if (dev-&gt;power.no_callbacks) {
+		/* Assume -&gt;runtime_idle() callback would have suspended. */
+		retval = rpm_suspend(dev, rpmflags);
+		goto out;
+	}
+
 	/* Carry out an asynchronous or a synchronous idle notification. */
 	if (rpmflags &amp; RPM_ASYNC) {
 		dev-&gt;power.request = RPM_REQ_IDLE;
@@ -254,6 +262,10 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 		goto repeat;
 	}
 
+	dev-&gt;power.deferred_resume = false;
+	if (dev-&gt;power.no_callbacks)
+		goto no_callback;	/* Assume success. */
+
 	/* Carry out an asynchronous or a synchronous suspend. */
 	if (rpmflags &amp; RPM_ASYNC) {
 		dev-&gt;power.request = RPM_REQ_SUSPEND;
@@ -265,7 +277,6 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 	}
 
 	__update_runtime_status(dev, RPM_SUSPENDING);
-	dev-&gt;power.deferred_resume = false;
 
 	if (dev-&gt;bus &amp;&amp; dev-&gt;bus-&gt;pm &amp;&amp; dev-&gt;bus-&gt;pm-&gt;runtime_suspend) {
 		spin_unlock_irq(&amp;dev-&gt;power.lock);
@@ -305,6 +316,7 @@ static int rpm_suspend(struct device *dev, int rpmflags)
 			pm_runtime_cancel_pending(dev);
 		}
 	} else {
+ no_callback:
 		__update_runtime_status(dev, RPM_SUSPENDED);
 		pm_runtime_deactivate_timer(dev);
 
@@ -409,6 +421,23 @@ static int rpm_resume(struct device *dev, int rpmflags)
 		goto repeat;
 	}
 
+	/*
+	 * See if we can skip waking up the parent.  This is safe only if
+	 * power.no_callbacks is set, because otherwise we don't know whether
+	 * the resume will actually succeed.
+	 */
+	if (dev-&gt;power.no_callbacks &amp;&amp; !parent &amp;&amp; dev-&gt;parent) {
+		spin_lock(&amp;dev-&gt;parent-&gt;power.lock);
+		if (dev-&gt;parent-&gt;power.disable_depth &gt; 0
+		    || dev-&gt;parent-&gt;power.ignore_children
+		    || dev-&gt;parent-&gt;power.runtime_status == RPM_ACTIVE) {
+			atomic_inc(&amp;dev-&gt;parent-&gt;power.child_count);
+			spin_unlock(&amp;dev-&gt;parent-&gt;power.lock);
+			goto no_callback;	/* Assume success. */
+		}
+		spin_unlock(&amp;dev-&gt;parent-&gt;power.lock);
+	}
+
 	/* Carry out an asynchronous or a synchronous resume. */
 	if (rpmflags &amp; RPM_ASYNC) {
 		dev-&gt;power.request = RPM_REQ_RESUME;
@@ -449,6 +478,9 @@ static int rpm_resume(struct device *dev, int rpmflags)
 		goto repeat;
 	}
 
+	if (dev-&gt;power.no_callbacks)
+		goto no_callback;	/* Assume success. */
+
 	__update_runtime_status(dev, RPM_RESUMING);
 
 	if (dev-&gt;bus &amp;&amp; dev-&gt;bus-&gt;pm &amp;&amp; dev-&gt;bus-&gt;pm-&gt;runtime_resume) {
@@ -482,6 +514,7 @@ static int rpm_resume(struct device *dev, int rpmflags)
 		__update_runtime_status(dev, RPM_SUSPENDED);
 		pm_runtime_cancel_pending(dev);
 	} else {
+ no_callback:
 		__update_runtime_status(dev, RPM_ACTIVE);
 		if (parent)
 			atomic_inc(&amp;parent-&gt;power.child_count);
@@ -954,6 +987,25 @@ void pm_runtime_allow(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(pm_runtime_allow);
 
+/**
+ * pm_runtime_no_callbacks - Ignore run-time PM callbacks for a device.
+ * @dev: Device to handle.
+ *
+ * Set the power.no_callbacks flag, which tells the PM core that this
+ * device is power-managed through its parent and has no run-time PM
+ * callbacks of its own.  The run-time sysfs attributes will be removed.
+ *
+ */
+void pm_runtime_no_callbacks(struct device *dev)
+{
+	spin_lock_irq(&amp;dev-&gt;power.lock);
+	dev-&gt;power.no_callbacks = 1;
+	spin_unlock_irq(&amp;dev-&gt;power.lock);
+	if (device_is_registered(dev))
+		rpm_sysfs_remove(dev);
+}
+EXPORT_SYMBOL_GPL(pm_runtime_no_callbacks);
+
 /**
  * pm_runtime_init - Initialize run-time PM fields in given device object.
  * @dev: Device object to initialize.
diff --git a/drivers/base/power/sysfs.c b/drivers/base/power/sysfs.c
index 8859780817e1..b5708c47ce2d 100644
--- a/drivers/base/power/sysfs.c
+++ b/drivers/base/power/sysfs.c
@@ -81,6 +81,9 @@
 static const char enabled[] = "enabled";
 static const char disabled[] = "disabled";
 
+const char power_group_name[] = "power";
+EXPORT_SYMBOL_GPL(power_group_name);
+
 #ifdef CONFIG_PM_RUNTIME
 static const char ctrl_auto[] = "auto";
 static const char ctrl_on[] = "on";
@@ -390,12 +393,6 @@ static DEVICE_ATTR(async, 0644, async_show, async_store);
 #endif /* CONFIG_PM_ADVANCED_DEBUG */
 
 static struct attribute * power_attrs[] = {
-#ifdef CONFIG_PM_RUNTIME
-	&amp;dev_attr_control.attr,
-	&amp;dev_attr_runtime_status.attr,
-	&amp;dev_attr_runtime_suspended_time.attr,
-	&amp;dev_attr_runtime_active_time.attr,
-#endif
 	&amp;dev_attr_wakeup.attr,
 #ifdef CONFIG_PM_SLEEP
 	&amp;dev_attr_wakeup_count.attr,
@@ -409,6 +406,7 @@ static struct attribute * power_attrs[] = {
 #ifdef CONFIG_PM_ADVANCED_DEBUG
 	&amp;dev_attr_async.attr,
 #ifdef CONFIG_PM_RUNTIME
+	&amp;dev_attr_runtime_status.attr,
 	&amp;dev_attr_runtime_usage.attr,
 	&amp;dev_attr_runtime_active_kids.attr,
 	&amp;dev_attr_runtime_enabled.attr,
@@ -417,10 +415,52 @@ static struct attribute * power_attrs[] = {
 	NULL,
 };
 static struct attribute_group pm_attr_group = {
-	.name	= "power",
+	.name	= power_group_name,
 	.attrs	= power_attrs,
 };
 
+#ifdef CONFIG_PM_RUNTIME
+
+static struct attribute *runtime_attrs[] = {
+#ifndef CONFIG_PM_ADVANCED_DEBUG
+	&amp;dev_attr_runtime_status.attr,
+#endif
+	&amp;dev_attr_control.attr,
+	&amp;dev_attr_runtime_suspended_time.attr,
+	&amp;dev_attr_runtime_active_time.attr,
+	NULL,
+};
+static struct attribute_group pm_runtime_attr_group = {
+	.name	= power_group_name,
+	.attrs	= runtime_attrs,
+};
+
+int dpm_sysfs_add(struct device *dev)
+{
+	int rc;
+
+	rc = sysfs_create_group(&amp;dev-&gt;kobj, &amp;pm_attr_group);
+	if (rc == 0 &amp;&amp; !dev-&gt;power.no_callbacks) {
+		rc = sysfs_merge_group(&amp;dev-&gt;kobj, &amp;pm_runtime_attr_group);
+		if (rc)
+			sysfs_remove_group(&amp;dev-&gt;kobj, &amp;pm_attr_group);
+	}
+	return rc;
+}
+
+void rpm_sysfs_remove(struct device *dev)
+{
+	sysfs_unmerge_group(&amp;dev-&gt;kobj, &amp;pm_runtime_attr_group);
+}
+
+void dpm_sysfs_remove(struct device *dev)
+{
+	rpm_sysfs_remove(dev);
+	sysfs_remove_group(&amp;dev-&gt;kobj, &amp;pm_attr_group);
+}
+
+#else /* CONFIG_PM_RUNTIME */
+
 int dpm_sysfs_add(struct device * dev)
 {
 	return sysfs_create_group(&amp;dev-&gt;kobj, &amp;pm_attr_group);
@@ -430,3 +470,5 @@ void dpm_sysfs_remove(struct device * dev)
 {
 	sysfs_remove_group(&amp;dev-&gt;kobj, &amp;pm_attr_group);
 }
+
+#endif
diff --git a/include/linux/pm.h b/include/linux/pm.h
index 1abfe84f447d..abd81ffaba3c 100644
--- a/include/linux/pm.h
+++ b/include/linux/pm.h
@@ -41,6 +41,12 @@ extern void (*pm_power_off_prepare)(void);
 
 struct device;
 
+#ifdef CONFIG_PM
+extern const char power_group_name[];		/* = "power" */
+#else
+#define power_group_name	NULL
+#endif
+
 typedef struct pm_message {
 	int event;
 } pm_message_t;
@@ -475,6 +481,7 @@ struct dev_pm_info {
 	unsigned int		deferred_resume:1;
 	unsigned int		run_wake:1;
 	unsigned int		runtime_auto:1;
+	unsigned int		no_callbacks:1;
 	enum rpm_request	request;
 	enum rpm_status		runtime_status;
 	int			runtime_error;
diff --git a/include/linux/pm_runtime.h b/include/linux/pm_runtime.h
index 5869d87fffac..8ca52f7c357e 100644
--- a/include/linux/pm_runtime.h
+++ b/include/linux/pm_runtime.h
@@ -36,6 +36,7 @@ extern void pm_runtime_forbid(struct device *dev);
 extern int pm_generic_runtime_idle(struct device *dev);
 extern int pm_generic_runtime_suspend(struct device *dev);
 extern int pm_generic_runtime_resume(struct device *dev);
+extern void pm_runtime_no_callbacks(struct device *dev);
 
 static inline bool pm_children_suspended(struct device *dev)
 {
@@ -110,6 +111,7 @@ static inline bool pm_runtime_suspended(struct device *dev) { return false; }
 static inline int pm_generic_runtime_idle(struct device *dev) { return 0; }
 static inline int pm_generic_runtime_suspend(struct device *dev) { return 0; }
 static inline int pm_generic_runtime_resume(struct device *dev) { return 0; }
+static inline void pm_runtime_no_callbacks(struct device *dev) {}
 
 #endif /* !CONFIG_PM_RUNTIME */
 </pre><hr><pre>commit 140a6c945211ee911dec776fafa52e03a7d7bb9a
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Sat Sep 25 23:35:07 2010 +0200

    PM / Runtime: Combine runtime PM entry points
    
    This patch (as1424) combines the various public entry points for the
    runtime PM routines into three simple functions: one for idle, one for
    suspend, and one for resume.  A new bitflag specifies whether or not
    to increment or decrement the usage_count field.
    
    The new entry points are named __pm_runtime_idle,
    __pm_runtime_suspend, and __pm_runtime_resume, to reflect that they
    are trampolines.  Simultaneously, the corresponding internal routines
    are renamed to rpm_idle, rpm_suspend, and rpm_resume.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Rafael J. Wysocki &lt;rjw@sisk.pl&gt;

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index d7b5d84c235c..ed227b7c1bb5 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -11,7 +11,7 @@
 #include &lt;linux/pm_runtime.h&gt;
 #include &lt;linux/jiffies.h&gt;
 
-static int __pm_runtime_resume(struct device *dev, int rpmflags);
+static int rpm_resume(struct device *dev, int rpmflags);
 
 /**
  * update_pm_runtime_accounting - Update the time accounting of power states
@@ -107,7 +107,7 @@ static int rpm_check_suspend_allowed(struct device *dev)
 
 
 /**
- * __pm_runtime_idle - Notify device bus type if the device can be suspended.
+ * rpm_idle - Notify device bus type if the device can be suspended.
  * @dev: Device to notify the bus type about.
  * @rpmflags: Flag bits.
  *
@@ -118,7 +118,7 @@ static int rpm_check_suspend_allowed(struct device *dev)
  *
  * This function must be called under dev-&gt;power.lock with interrupts disabled.
  */
-static int __pm_runtime_idle(struct device *dev, int rpmflags)
+static int rpm_idle(struct device *dev, int rpmflags)
 	__releases(&amp;dev-&gt;power.lock) __acquires(&amp;dev-&gt;power.lock)
 {
 	int retval;
@@ -189,23 +189,7 @@ static int __pm_runtime_idle(struct device *dev, int rpmflags)
 }
 
 /**
- * pm_runtime_idle - Notify device bus type if the device can be suspended.
- * @dev: Device to notify the bus type about.
- */
-int pm_runtime_idle(struct device *dev)
-{
-	int retval;
-
-	spin_lock_irq(&amp;dev-&gt;power.lock);
-	retval = __pm_runtime_idle(dev, 0);
-	spin_unlock_irq(&amp;dev-&gt;power.lock);
-
-	return retval;
-}
-EXPORT_SYMBOL_GPL(pm_runtime_idle);
-
-/**
- * __pm_runtime_suspend - Carry out run-time suspend of given device.
+ * rpm_suspend - Carry out run-time suspend of given device.
  * @dev: Device to suspend.
  * @rpmflags: Flag bits.
  *
@@ -220,7 +204,7 @@ EXPORT_SYMBOL_GPL(pm_runtime_idle);
  *
  * This function must be called under dev-&gt;power.lock with interrupts disabled.
  */
-static int __pm_runtime_suspend(struct device *dev, int rpmflags)
+static int rpm_suspend(struct device *dev, int rpmflags)
 	__releases(&amp;dev-&gt;power.lock) __acquires(&amp;dev-&gt;power.lock)
 {
 	struct device *parent = NULL;
@@ -332,13 +316,13 @@ static int __pm_runtime_suspend(struct device *dev, int rpmflags)
 	wake_up_all(&amp;dev-&gt;power.wait_queue);
 
 	if (dev-&gt;power.deferred_resume) {
-		__pm_runtime_resume(dev, 0);
+		rpm_resume(dev, 0);
 		retval = -EAGAIN;
 		goto out;
 	}
 
 	if (notify)
-		__pm_runtime_idle(dev, 0);
+		rpm_idle(dev, 0);
 
 	if (parent &amp;&amp; !parent-&gt;power.ignore_children) {
 		spin_unlock_irq(&amp;dev-&gt;power.lock);
@@ -355,23 +339,7 @@ static int __pm_runtime_suspend(struct device *dev, int rpmflags)
 }
 
 /**
- * pm_runtime_suspend - Carry out run-time suspend of given device.
- * @dev: Device to suspend.
- */
-int pm_runtime_suspend(struct device *dev)
-{
-	int retval;
-
-	spin_lock_irq(&amp;dev-&gt;power.lock);
-	retval = __pm_runtime_suspend(dev, 0);
-	spin_unlock_irq(&amp;dev-&gt;power.lock);
-
-	return retval;
-}
-EXPORT_SYMBOL_GPL(pm_runtime_suspend);
-
-/**
- * __pm_runtime_resume - Carry out run-time resume of given device.
+ * rpm_resume - Carry out run-time resume of given device.
  * @dev: Device to resume.
  * @rpmflags: Flag bits.
  *
@@ -387,7 +355,7 @@ EXPORT_SYMBOL_GPL(pm_runtime_suspend);
  *
  * This function must be called under dev-&gt;power.lock with interrupts disabled.
  */
-static int __pm_runtime_resume(struct device *dev, int rpmflags)
+static int rpm_resume(struct device *dev, int rpmflags)
 	__releases(&amp;dev-&gt;power.lock) __acquires(&amp;dev-&gt;power.lock)
 {
 	struct device *parent = NULL;
@@ -469,7 +437,7 @@ static int __pm_runtime_resume(struct device *dev, int rpmflags)
 		 */
 		if (!parent-&gt;power.disable_depth
 		    &amp;&amp; !parent-&gt;power.ignore_children) {
-			__pm_runtime_resume(parent, 0);
+			rpm_resume(parent, 0);
 			if (parent-&gt;power.runtime_status != RPM_ACTIVE)
 				retval = -EBUSY;
 		}
@@ -521,7 +489,7 @@ static int __pm_runtime_resume(struct device *dev, int rpmflags)
 	wake_up_all(&amp;dev-&gt;power.wait_queue);
 
 	if (!retval)
-		__pm_runtime_idle(dev, RPM_ASYNC);
+		rpm_idle(dev, RPM_ASYNC);
 
  out:
 	if (parent) {
@@ -537,22 +505,6 @@ static int __pm_runtime_resume(struct device *dev, int rpmflags)
 	return retval;
 }
 
-/**
- * pm_runtime_resume - Carry out run-time resume of given device.
- * @dev: Device to suspend.
- */
-int pm_runtime_resume(struct device *dev)
-{
-	int retval;
-
-	spin_lock_irq(&amp;dev-&gt;power.lock);
-	retval = __pm_runtime_resume(dev, 0);
-	spin_unlock_irq(&amp;dev-&gt;power.lock);
-
-	return retval;
-}
-EXPORT_SYMBOL_GPL(pm_runtime_resume);
-
 /**
  * pm_runtime_work - Universal run-time PM work function.
  * @work: Work structure used for scheduling the execution of this function.
@@ -578,13 +530,13 @@ static void pm_runtime_work(struct work_struct *work)
 	case RPM_REQ_NONE:
 		break;
 	case RPM_REQ_IDLE:
-		__pm_runtime_idle(dev, RPM_NOWAIT);
+		rpm_idle(dev, RPM_NOWAIT);
 		break;
 	case RPM_REQ_SUSPEND:
-		__pm_runtime_suspend(dev, RPM_NOWAIT);
+		rpm_suspend(dev, RPM_NOWAIT);
 		break;
 	case RPM_REQ_RESUME:
-		__pm_runtime_resume(dev, RPM_NOWAIT);
+		rpm_resume(dev, RPM_NOWAIT);
 		break;
 	}
 
@@ -592,23 +544,6 @@ static void pm_runtime_work(struct work_struct *work)
 	spin_unlock_irq(&amp;dev-&gt;power.lock);
 }
 
-/**
- * pm_request_idle - Submit an idle notification request for given device.
- * @dev: Device to handle.
- */
-int pm_request_idle(struct device *dev)
-{
-	unsigned long flags;
-	int retval;
-
-	spin_lock_irqsave(&amp;dev-&gt;power.lock, flags);
-	retval = __pm_runtime_idle(dev, RPM_ASYNC);
-	spin_unlock_irqrestore(&amp;dev-&gt;power.lock, flags);
-
-	return retval;
-}
-EXPORT_SYMBOL_GPL(pm_request_idle);
-
 /**
  * pm_suspend_timer_fn - Timer function for pm_schedule_suspend().
  * @data: Device pointer passed by pm_schedule_suspend().
@@ -627,7 +562,7 @@ static void pm_suspend_timer_fn(unsigned long data)
 	/* If 'expire' is after 'jiffies' we've been called too early. */
 	if (expires &gt; 0 &amp;&amp; !time_after(expires, jiffies)) {
 		dev-&gt;power.timer_expires = 0;
-		__pm_runtime_suspend(dev, RPM_ASYNC);
+		rpm_suspend(dev, RPM_ASYNC);
 	}
 
 	spin_unlock_irqrestore(&amp;dev-&gt;power.lock, flags);
@@ -646,7 +581,7 @@ int pm_schedule_suspend(struct device *dev, unsigned int delay)
 	spin_lock_irqsave(&amp;dev-&gt;power.lock, flags);
 
 	if (!delay) {
-		retval = __pm_runtime_suspend(dev, RPM_ASYNC);
+		retval = rpm_suspend(dev, RPM_ASYNC);
 		goto out;
 	}
 
@@ -669,62 +604,81 @@ int pm_schedule_suspend(struct device *dev, unsigned int delay)
 EXPORT_SYMBOL_GPL(pm_schedule_suspend);
 
 /**
- * pm_request_resume - Submit a resume request for given device.
- * @dev: Device to resume.
+ * __pm_runtime_idle - Entry point for run-time idle operations.
+ * @dev: Device to send idle notification for.
+ * @rpmflags: Flag bits.
+ *
+ * If the RPM_GET_PUT flag is set, decrement the device's usage count and
+ * return immediately if it is larger than zero.  Then carry out an idle
+ * notification, either synchronous or asynchronous.
+ *
+ * This routine may be called in atomic context if the RPM_ASYNC flag is set.
  */
-int pm_request_resume(struct device *dev)
+int __pm_runtime_idle(struct device *dev, int rpmflags)
 {
 	unsigned long flags;
 	int retval;
 
+	if (rpmflags &amp; RPM_GET_PUT) {
+		if (!atomic_dec_and_test(&amp;dev-&gt;power.usage_count))
+			return 0;
+	}
+
 	spin_lock_irqsave(&amp;dev-&gt;power.lock, flags);
-	retval = __pm_runtime_resume(dev, RPM_ASYNC);
+	retval = rpm_idle(dev, rpmflags);
 	spin_unlock_irqrestore(&amp;dev-&gt;power.lock, flags);
 
 	return retval;
 }
-EXPORT_SYMBOL_GPL(pm_request_resume);
+EXPORT_SYMBOL_GPL(__pm_runtime_idle);
 
 /**
- * __pm_runtime_get - Reference count a device and wake it up, if necessary.
- * @dev: Device to handle.
+ * __pm_runtime_suspend - Entry point for run-time put/suspend operations.
+ * @dev: Device to suspend.
  * @rpmflags: Flag bits.
  *
- * Increment the usage count of the device and resume it or submit a resume
- * request for it, depending on the RPM_ASYNC flag bit.
+ * Carry out a suspend, either synchronous or asynchronous.
+ *
+ * This routine may be called in atomic context if the RPM_ASYNC flag is set.
  */
-int __pm_runtime_get(struct device *dev, int rpmflags)
+int __pm_runtime_suspend(struct device *dev, int rpmflags)
 {
+	unsigned long flags;
 	int retval;
 
-	atomic_inc(&amp;dev-&gt;power.usage_count);
-	retval = (rpmflags &amp; RPM_ASYNC) ?
-	    pm_request_resume(dev) : pm_runtime_resume(dev);
+	spin_lock_irqsave(&amp;dev-&gt;power.lock, flags);
+	retval = rpm_suspend(dev, rpmflags);
+	spin_unlock_irqrestore(&amp;dev-&gt;power.lock, flags);
 
 	return retval;
 }
-EXPORT_SYMBOL_GPL(__pm_runtime_get);
+EXPORT_SYMBOL_GPL(__pm_runtime_suspend);
 
 /**
- * __pm_runtime_put - Decrement the device's usage counter and notify its bus.
- * @dev: Device to handle.
+ * __pm_runtime_resume - Entry point for run-time resume operations.
+ * @dev: Device to resume.
  * @rpmflags: Flag bits.
  *
- * Decrement the usage count of the device and if it reaches zero, carry out a
- * synchronous idle notification or submit an idle notification request for it,
- * depending on the RPM_ASYNC flag bit.
+ * If the RPM_GET_PUT flag is set, increment the device's usage count.  Then
+ * carry out a resume, either synchronous or asynchronous.
+ *
+ * This routine may be called in atomic context if the RPM_ASYNC flag is set.
  */
-int __pm_runtime_put(struct device *dev, int rpmflags)
+int __pm_runtime_resume(struct device *dev, int rpmflags)
 {
-	int retval = 0;
+	unsigned long flags;
+	int retval;
 
-	if (atomic_dec_and_test(&amp;dev-&gt;power.usage_count))
-		retval = (rpmflags &amp; RPM_ASYNC) ?
-		    pm_request_idle(dev) : pm_runtime_idle(dev);
+	if (rpmflags &amp; RPM_GET_PUT)
+		atomic_inc(&amp;dev-&gt;power.usage_count);
+
+	spin_lock_irqsave(&amp;dev-&gt;power.lock, flags);
+	retval = rpm_resume(dev, rpmflags);
+	spin_unlock_irqrestore(&amp;dev-&gt;power.lock, flags);
 
 	return retval;
 }
-EXPORT_SYMBOL_GPL(__pm_runtime_put);
+EXPORT_SYMBOL_GPL(__pm_runtime_resume);
 
 /**
  * __pm_runtime_set_status - Set run-time PM status of a device.
@@ -875,7 +829,7 @@ int pm_runtime_barrier(struct device *dev)
 
 	if (dev-&gt;power.request_pending
 	    &amp;&amp; dev-&gt;power.request == RPM_REQ_RESUME) {
-		__pm_runtime_resume(dev, 0);
+		rpm_resume(dev, 0);
 		retval = 1;
 	}
 
@@ -924,7 +878,7 @@ void __pm_runtime_disable(struct device *dev, bool check_resume)
 		 */
 		pm_runtime_get_noresume(dev);
 
-		__pm_runtime_resume(dev, 0);
+		rpm_resume(dev, 0);
 
 		pm_runtime_put_noidle(dev);
 	}
@@ -972,7 +926,7 @@ void pm_runtime_forbid(struct device *dev)
 
 	dev-&gt;power.runtime_auto = false;
 	atomic_inc(&amp;dev-&gt;power.usage_count);
-	__pm_runtime_resume(dev, 0);
+	rpm_resume(dev, 0);
 
  out:
 	spin_unlock_irq(&amp;dev-&gt;power.lock);
@@ -993,7 +947,7 @@ void pm_runtime_allow(struct device *dev)
 
 	dev-&gt;power.runtime_auto = true;
 	if (atomic_dec_and_test(&amp;dev-&gt;power.usage_count))
-		__pm_runtime_idle(dev, 0);
+		rpm_idle(dev, 0);
 
  out:
 	spin_unlock_irq(&amp;dev-&gt;power.lock);
diff --git a/include/linux/pm_runtime.h b/include/linux/pm_runtime.h
index c030cac59aac..5869d87fffac 100644
--- a/include/linux/pm_runtime.h
+++ b/include/linux/pm_runtime.h
@@ -16,19 +16,17 @@
 #define RPM_ASYNC		0x01	/* Request is asynchronous */
 #define RPM_NOWAIT		0x02	/* Don't wait for concurrent
 					    state change */
+#define RPM_GET_PUT		0x04	/* Increment/decrement the
+					    usage_count */
 
 #ifdef CONFIG_PM_RUNTIME
 
 extern struct workqueue_struct *pm_wq;
 
-extern int pm_runtime_idle(struct device *dev);
-extern int pm_runtime_suspend(struct device *dev);
-extern int pm_runtime_resume(struct device *dev);
-extern int pm_request_idle(struct device *dev);
+extern int __pm_runtime_idle(struct device *dev, int rpmflags);
+extern int __pm_runtime_suspend(struct device *dev, int rpmflags);
+extern int __pm_runtime_resume(struct device *dev, int rpmflags);
 extern int pm_schedule_suspend(struct device *dev, unsigned int delay);
-extern int pm_request_resume(struct device *dev);
-extern int __pm_runtime_get(struct device *dev, int rpmflags);
-extern int __pm_runtime_put(struct device *dev, int rpmflags);
 extern int __pm_runtime_set_status(struct device *dev, unsigned int status);
 extern int pm_runtime_barrier(struct device *dev);
 extern void pm_runtime_enable(struct device *dev);
@@ -77,19 +75,22 @@ static inline bool pm_runtime_suspended(struct device *dev)
 
 #else /* !CONFIG_PM_RUNTIME */
 
-static inline int pm_runtime_idle(struct device *dev) { return -ENOSYS; }
-static inline int pm_runtime_suspend(struct device *dev) { return -ENOSYS; }
-static inline int pm_runtime_resume(struct device *dev) { return 0; }
-static inline int pm_request_idle(struct device *dev) { return -ENOSYS; }
+static inline int __pm_runtime_idle(struct device *dev, int rpmflags)
+{
+	return -ENOSYS;
+}
+static inline int __pm_runtime_suspend(struct device *dev, int rpmflags)
+{
+	return -ENOSYS;
+}
+static inline int __pm_runtime_resume(struct device *dev, int rpmflags)
+{
+	return 1;
+}
 static inline int pm_schedule_suspend(struct device *dev, unsigned int delay)
 {
 	return -ENOSYS;
 }
-static inline int pm_request_resume(struct device *dev) { return 0; }
-static inline int __pm_runtime_get(struct device *dev, int rpmflags)
-					{ return 1; }
-static inline int __pm_runtime_put(struct device *dev, int rpmflags)
-					{ return 0; }
 static inline int __pm_runtime_set_status(struct device *dev,
 					    unsigned int status) { return 0; }
 static inline int pm_runtime_barrier(struct device *dev) { return 0; }
@@ -112,24 +113,49 @@ static inline int pm_generic_runtime_resume(struct device *dev) { return 0; }
 
 #endif /* !CONFIG_PM_RUNTIME */
 
+static inline int pm_runtime_idle(struct device *dev)
+{
+	return __pm_runtime_idle(dev, 0);
+}
+
+static inline int pm_runtime_suspend(struct device *dev)
+{
+	return __pm_runtime_suspend(dev, 0);
+}
+
+static inline int pm_runtime_resume(struct device *dev)
+{
+	return __pm_runtime_resume(dev, 0);
+}
+
+static inline int pm_request_idle(struct device *dev)
+{
+	return __pm_runtime_idle(dev, RPM_ASYNC);
+}
+
+static inline int pm_request_resume(struct device *dev)
+{
+	return __pm_runtime_resume(dev, RPM_ASYNC);
+}
+
 static inline int pm_runtime_get(struct device *dev)
 {
-	return __pm_runtime_get(dev, RPM_ASYNC);
+	return __pm_runtime_resume(dev, RPM_GET_PUT | RPM_ASYNC);
 }
 
 static inline int pm_runtime_get_sync(struct device *dev)
 {
-	return __pm_runtime_get(dev, 0);
+	return __pm_runtime_resume(dev, RPM_GET_PUT);
 }
 
 static inline int pm_runtime_put(struct device *dev)
 {
-	return __pm_runtime_put(dev, RPM_ASYNC);
+	return __pm_runtime_idle(dev, RPM_GET_PUT | RPM_ASYNC);
 }
 
 static inline int pm_runtime_put_sync(struct device *dev)
 {
-	return __pm_runtime_put(dev, 0);
+	return __pm_runtime_idle(dev, RPM_GET_PUT);
 }
 
 static inline int pm_runtime_set_active(struct device *dev)</pre><hr><pre>commit 1bfee5bc86fdaecc912e06080583eddab7263df2
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Sat Sep 25 23:35:00 2010 +0200

    PM / Runtime: Merge synchronous and async runtime routines
    
    This patch (as1423) merges the asynchronous routines
    __pm_request_idle(), __pm_request_suspend(), and __pm_request_resume()
    with their synchronous counterparts.  The RPM_ASYNC bitflag argument
    serves to indicate what sort of operation to perform.
    
    In the course of performing this merger, it became apparent that the
    various functions don't all behave consistenly with regard to error
    reporting and cancellation of outstanding requests.  A new routine,
    rpm_check_suspend_allowed(), was written to centralize much of the
    testing, and the other functions were revised to follow a simple
    algorithm:
    
            If the operation is disallowed because of the device's
            settings or current state, return an error.
    
            Cancel pending or scheduled requests of lower priority.
    
            Schedule, queue, or perform the desired operation.
    
    A few special cases and exceptions are noted in comments.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Rafael J. Wysocki &lt;rjw@sisk.pl&gt;

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index 0c1db879544b..d7b5d84c235c 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -2,6 +2,7 @@
  * drivers/base/power/runtime.c - Helper functions for device run-time PM
  *
  * Copyright (c) 2009 Rafael J. Wysocki &lt;rjw@sisk.pl&gt;, Novell Inc.
+ * Copyright (C) 2010 Alan Stern &lt;stern@rowland.harvard.edu&gt;
  *
  * This file is released under the GPLv2.
  */
@@ -11,8 +12,6 @@
 #include &lt;linux/jiffies.h&gt;
 
 static int __pm_runtime_resume(struct device *dev, int rpmflags);
-static int __pm_request_idle(struct device *dev);
-static int __pm_request_resume(struct device *dev);
 
 /**
  * update_pm_runtime_accounting - Update the time accounting of power states
@@ -79,40 +78,84 @@ static void pm_runtime_cancel_pending(struct device *dev)
 }
 
 /**
- * __pm_runtime_idle - Notify device bus type if the device can be suspended.
- * @dev: Device to notify the bus type about.
- *
- * This function must be called under dev-&gt;power.lock with interrupts disabled.
+ * rpm_check_suspend_allowed - Test whether a device may be suspended.
+ * @dev: Device to test.
  */
-static int __pm_runtime_idle(struct device *dev)
-	__releases(&amp;dev-&gt;power.lock) __acquires(&amp;dev-&gt;power.lock)
+static int rpm_check_suspend_allowed(struct device *dev)
 {
 	int retval = 0;
 
 	if (dev-&gt;power.runtime_error)
 		retval = -EINVAL;
-	else if (dev-&gt;power.idle_notification)
-		retval = -EINPROGRESS;
 	else if (atomic_read(&amp;dev-&gt;power.usage_count) &gt; 0
-	    || dev-&gt;power.disable_depth &gt; 0
-	    || dev-&gt;power.runtime_status != RPM_ACTIVE)
+	    || dev-&gt;power.disable_depth &gt; 0)
 		retval = -EAGAIN;
 	else if (!pm_children_suspended(dev))
 		retval = -EBUSY;
+
+	/* Pending resume requests take precedence over suspends. */
+	else if ((dev-&gt;power.deferred_resume
+			&amp;&amp; dev-&gt;power.status == RPM_SUSPENDING)
+	    || (dev-&gt;power.request_pending
+			&amp;&amp; dev-&gt;power.request == RPM_REQ_RESUME))
+		retval = -EAGAIN;
+	else if (dev-&gt;power.runtime_status == RPM_SUSPENDED)
+		retval = 1;
+
+	return retval;
+}
+
+
+/**
+ * __pm_runtime_idle - Notify device bus type if the device can be suspended.
+ * @dev: Device to notify the bus type about.
+ * @rpmflags: Flag bits.
+ *
+ * Check if the device's run-time PM status allows it to be suspended.  If
+ * another idle notification has been started earlier, return immediately.  If
+ * the RPM_ASYNC flag is set then queue an idle-notification request; otherwise
+ * run the -&gt;runtime_idle() callback directly.
+ *
+ * This function must be called under dev-&gt;power.lock with interrupts disabled.
+ */
+static int __pm_runtime_idle(struct device *dev, int rpmflags)
+	__releases(&amp;dev-&gt;power.lock) __acquires(&amp;dev-&gt;power.lock)
+{
+	int retval;
+
+	retval = rpm_check_suspend_allowed(dev);
+	if (retval &lt; 0)
+		;	/* Conditions are wrong. */
+
+	/* Idle notifications are allowed only in the RPM_ACTIVE state. */
+	else if (dev-&gt;power.runtime_status != RPM_ACTIVE)
+		retval = -EAGAIN;
+
+	/*
+	 * Any pending request other than an idle notification takes
+	 * precedence over us, except that the timer may be running.
+	 */
+	else if (dev-&gt;power.request_pending &amp;&amp;
+	    dev-&gt;power.request &gt; RPM_REQ_IDLE)
+		retval = -EAGAIN;
+
+	/* Act as though RPM_NOWAIT is always set. */
+	else if (dev-&gt;power.idle_notification)
+		retval = -EINPROGRESS;
 	if (retval)
 		goto out;
 
-	if (dev-&gt;power.request_pending) {
-		/*
-		 * If an idle notification request is pending, cancel it.  Any
-		 * other pending request takes precedence over us.
-		 */
-		if (dev-&gt;power.request == RPM_REQ_IDLE) {
-			dev-&gt;power.request = RPM_REQ_NONE;
-		} else if (dev-&gt;power.request != RPM_REQ_NONE) {
-			retval = -EAGAIN;
-			goto out;
+	/* Pending requests need to be canceled. */
+	dev-&gt;power.request = RPM_REQ_NONE;
+
+	/* Carry out an asynchronous or a synchronous idle notification. */
+	if (rpmflags &amp; RPM_ASYNC) {
+		dev-&gt;power.request = RPM_REQ_IDLE;
+		if (!dev-&gt;power.request_pending) {
+			dev-&gt;power.request_pending = true;
+			queue_work(pm_wq, &amp;dev-&gt;power.work);
 		}
+		goto out;
 	}
 
 	dev-&gt;power.idle_notification = true;
@@ -154,7 +197,7 @@ int pm_runtime_idle(struct device *dev)
 	int retval;
 
 	spin_lock_irq(&amp;dev-&gt;power.lock);
-	retval = __pm_runtime_idle(dev);
+	retval = __pm_runtime_idle(dev, 0);
 	spin_unlock_irq(&amp;dev-&gt;power.lock);
 
 	return retval;
@@ -166,11 +209,14 @@ EXPORT_SYMBOL_GPL(pm_runtime_idle);
  * @dev: Device to suspend.
  * @rpmflags: Flag bits.
  *
- * Check if the device can be suspended and run the -&gt;runtime_suspend() callback
- * provided by its bus type.  If another suspend has been started earlier,
- * either return immediately or wait for it to finish, depending on the
- * RPM_NOWAIT flag.  If an idle notification or suspend request is pending or
- * scheduled, cancel it.
+ * Check if the device's run-time PM status allows it to be suspended.  If
+ * another suspend has been started earlier, either return immediately or wait
+ * for it to finish, depending on the RPM_NOWAIT and RPM_ASYNC flags.  Cancel a
+ * pending idle notification.  If the RPM_ASYNC flag is set then queue a
+ * suspend request; otherwise run the -&gt;runtime_suspend() callback directly.
+ * If a deferred resume was requested while the callback was running then carry
+ * it out; otherwise send an idle notification for the device (if the suspend
+ * failed) or for its parent (if the suspend succeeded).
  *
  * This function must be called under dev-&gt;power.lock with interrupts disabled.
  */
@@ -179,41 +225,30 @@ static int __pm_runtime_suspend(struct device *dev, int rpmflags)
 {
 	struct device *parent = NULL;
 	bool notify = false;
-	int retval = 0;
+	int retval;
 
 	dev_dbg(dev, "%s flags 0x%x\n", __func__, rpmflags);
 
  repeat:
-	if (dev-&gt;power.runtime_error) {
-		retval = -EINVAL;
-		goto out;
-	}
+	retval = rpm_check_suspend_allowed(dev);
 
-	/* Pending resume requests take precedence over us. */
-	if (dev-&gt;power.request_pending
-	    &amp;&amp; dev-&gt;power.request == RPM_REQ_RESUME) {
+	if (retval &lt; 0)
+		;	/* Conditions are wrong. */
+
+	/* Synchronous suspends are not allowed in the RPM_RESUMING state. */
+	else if (dev-&gt;power.runtime_status == RPM_RESUMING &amp;&amp;
+	    !(rpmflags &amp; RPM_ASYNC))
 		retval = -EAGAIN;
+	if (retval)
 		goto out;
-	}
 
 	/* Other scheduled or pending requests need to be canceled. */
 	pm_runtime_cancel_pending(dev);
 
-	if (dev-&gt;power.runtime_status == RPM_SUSPENDED)
-		retval = 1;
-	else if (dev-&gt;power.runtime_status == RPM_RESUMING
-	    || dev-&gt;power.disable_depth &gt; 0
-	    || atomic_read(&amp;dev-&gt;power.usage_count) &gt; 0)
-		retval = -EAGAIN;
-	else if (!pm_children_suspended(dev))
-		retval = -EBUSY;
-	if (retval)
-		goto out;
-
 	if (dev-&gt;power.runtime_status == RPM_SUSPENDING) {
 		DEFINE_WAIT(wait);
 
-		if (rpmflags &amp; RPM_NOWAIT) {
+		if (rpmflags &amp; (RPM_ASYNC | RPM_NOWAIT)) {
 			retval = -EINPROGRESS;
 			goto out;
 		}
@@ -235,6 +270,16 @@ static int __pm_runtime_suspend(struct device *dev, int rpmflags)
 		goto repeat;
 	}
 
+	/* Carry out an asynchronous or a synchronous suspend. */
+	if (rpmflags &amp; RPM_ASYNC) {
+		dev-&gt;power.request = RPM_REQ_SUSPEND;
+		if (!dev-&gt;power.request_pending) {
+			dev-&gt;power.request_pending = true;
+			queue_work(pm_wq, &amp;dev-&gt;power.work);
+		}
+		goto out;
+	}
+
 	__update_runtime_status(dev, RPM_SUSPENDING);
 	dev-&gt;power.deferred_resume = false;
 
@@ -267,6 +312,7 @@ static int __pm_runtime_suspend(struct device *dev, int rpmflags)
 
 	if (retval) {
 		__update_runtime_status(dev, RPM_ACTIVE);
+		dev-&gt;power.deferred_resume = 0;
 		if (retval == -EAGAIN || retval == -EBUSY) {
 			if (dev-&gt;power.timer_expires == 0)
 				notify = true;
@@ -292,7 +338,7 @@ static int __pm_runtime_suspend(struct device *dev, int rpmflags)
 	}
 
 	if (notify)
-		__pm_runtime_idle(dev);
+		__pm_runtime_idle(dev, 0);
 
 	if (parent &amp;&amp; !parent-&gt;power.ignore_children) {
 		spin_unlock_irq(&amp;dev-&gt;power.lock);
@@ -329,13 +375,15 @@ EXPORT_SYMBOL_GPL(pm_runtime_suspend);
  * @dev: Device to resume.
  * @rpmflags: Flag bits.
  *
- * Check if the device can be woken up and run the -&gt;runtime_resume() callback
- * provided by its bus type.  If another resume has been started earlier,
- * either return imediately or wait for it to finish, depending on the
- * RPM_NOWAIT flag.  If there's a suspend running in parallel with this
- * function, either tell the other process to resume after suspending
- * (deferred_resume) or wait for it to finish, depending on the RPM_NOWAIT
- * flag.  Cancel any scheduled or pending requests.
+ * Check if the device's run-time PM status allows it to be resumed.  Cancel
+ * any scheduled or pending requests.  If another resume has been started
+ * earlier, either return imediately or wait for it to finish, depending on the
+ * RPM_NOWAIT and RPM_ASYNC flags.  Similarly, if there's a suspend running in
+ * parallel with this function, either tell the other process to resume after
+ * suspending (deferred_resume) or wait for it to finish.  If the RPM_ASYNC
+ * flag is set then queue a resume request; otherwise run the
+ * -&gt;runtime_resume() callback directly.  Queue an idle notification for the
+ * device if the resume succeeded.
  *
  * This function must be called under dev-&gt;power.lock with interrupts disabled.
  */
@@ -348,28 +396,30 @@ static int __pm_runtime_resume(struct device *dev, int rpmflags)
 	dev_dbg(dev, "%s flags 0x%x\n", __func__, rpmflags);
 
  repeat:
-	if (dev-&gt;power.runtime_error) {
+	if (dev-&gt;power.runtime_error)
 		retval = -EINVAL;
+	else if (dev-&gt;power.disable_depth &gt; 0)
+		retval = -EAGAIN;
+	if (retval)
 		goto out;
-	}
 
+	/* Other scheduled or pending requests need to be canceled. */
 	pm_runtime_cancel_pending(dev);
 
-	if (dev-&gt;power.runtime_status == RPM_ACTIVE)
+	if (dev-&gt;power.runtime_status == RPM_ACTIVE) {
 		retval = 1;
-	else if (dev-&gt;power.disable_depth &gt; 0)
-		retval = -EAGAIN;
-	if (retval)
 		goto out;
+	}
 
 	if (dev-&gt;power.runtime_status == RPM_RESUMING
 	    || dev-&gt;power.runtime_status == RPM_SUSPENDING) {
 		DEFINE_WAIT(wait);
 
-		if (rpmflags &amp; RPM_NOWAIT) {
+		if (rpmflags &amp; (RPM_ASYNC | RPM_NOWAIT)) {
 			if (dev-&gt;power.runtime_status == RPM_SUSPENDING)
 				dev-&gt;power.deferred_resume = true;
-			retval = -EINPROGRESS;
+			else
+				retval = -EINPROGRESS;
 			goto out;
 		}
 
@@ -391,6 +441,17 @@ static int __pm_runtime_resume(struct device *dev, int rpmflags)
 		goto repeat;
 	}
 
+	/* Carry out an asynchronous or a synchronous resume. */
+	if (rpmflags &amp; RPM_ASYNC) {
+		dev-&gt;power.request = RPM_REQ_RESUME;
+		if (!dev-&gt;power.request_pending) {
+			dev-&gt;power.request_pending = true;
+			queue_work(pm_wq, &amp;dev-&gt;power.work);
+		}
+		retval = 0;
+		goto out;
+	}
+
 	if (!parent &amp;&amp; dev-&gt;parent) {
 		/*
 		 * Increment the parent's resume counter and resume it if
@@ -460,7 +521,7 @@ static int __pm_runtime_resume(struct device *dev, int rpmflags)
 	wake_up_all(&amp;dev-&gt;power.wait_queue);
 
 	if (!retval)
-		__pm_request_idle(dev);
+		__pm_runtime_idle(dev, RPM_ASYNC);
 
  out:
 	if (parent) {
@@ -517,7 +578,7 @@ static void pm_runtime_work(struct work_struct *work)
 	case RPM_REQ_NONE:
 		break;
 	case RPM_REQ_IDLE:
-		__pm_runtime_idle(dev);
+		__pm_runtime_idle(dev, RPM_NOWAIT);
 		break;
 	case RPM_REQ_SUSPEND:
 		__pm_runtime_suspend(dev, RPM_NOWAIT);
@@ -531,47 +592,6 @@ static void pm_runtime_work(struct work_struct *work)
 	spin_unlock_irq(&amp;dev-&gt;power.lock);
 }
 
-/**
- * __pm_request_idle - Submit an idle notification request for given device.
- * @dev: Device to handle.
- *
- * Check if the device's run-time PM status is correct for suspending the device
- * and queue up a request to run __pm_runtime_idle() for it.
- *
- * This function must be called under dev-&gt;power.lock with interrupts disabled.
- */
-static int __pm_request_idle(struct device *dev)
-{
-	int retval = 0;
-
-	if (dev-&gt;power.runtime_error)
-		retval = -EINVAL;
-	else if (atomic_read(&amp;dev-&gt;power.usage_count) &gt; 0
-	    || dev-&gt;power.disable_depth &gt; 0
-	    || dev-&gt;power.runtime_status == RPM_SUSPENDED
-	    || dev-&gt;power.runtime_status == RPM_SUSPENDING)
-		retval = -EAGAIN;
-	else if (!pm_children_suspended(dev))
-		retval = -EBUSY;
-	if (retval)
-		return retval;
-
-	if (dev-&gt;power.request_pending) {
-		/* Any requests other then RPM_REQ_IDLE take precedence. */
-		if (dev-&gt;power.request == RPM_REQ_NONE)
-			dev-&gt;power.request = RPM_REQ_IDLE;
-		else if (dev-&gt;power.request != RPM_REQ_IDLE)
-			retval = -EAGAIN;
-		return retval;
-	}
-
-	dev-&gt;power.request = RPM_REQ_IDLE;
-	dev-&gt;power.request_pending = true;
-	queue_work(pm_wq, &amp;dev-&gt;power.work);
-
-	return retval;
-}
-
 /**
  * pm_request_idle - Submit an idle notification request for given device.
  * @dev: Device to handle.
@@ -582,67 +602,18 @@ int pm_request_idle(struct device *dev)
 	int retval;
 
 	spin_lock_irqsave(&amp;dev-&gt;power.lock, flags);
-	retval = __pm_request_idle(dev);
+	retval = __pm_runtime_idle(dev, RPM_ASYNC);
 	spin_unlock_irqrestore(&amp;dev-&gt;power.lock, flags);
 
 	return retval;
 }
 EXPORT_SYMBOL_GPL(pm_request_idle);
 
-/**
- * __pm_request_suspend - Submit a suspend request for given device.
- * @dev: Device to suspend.
- *
- * This function must be called under dev-&gt;power.lock with interrupts disabled.
- */
-static int __pm_request_suspend(struct device *dev)
-{
-	int retval = 0;
-
-	if (dev-&gt;power.runtime_error)
-		return -EINVAL;
-
-	if (dev-&gt;power.runtime_status == RPM_SUSPENDED)
-		retval = 1;
-	else if (atomic_read(&amp;dev-&gt;power.usage_count) &gt; 0
-	    || dev-&gt;power.disable_depth &gt; 0)
-		retval = -EAGAIN;
-	else if (dev-&gt;power.runtime_status == RPM_SUSPENDING)
-		retval = -EINPROGRESS;
-	else if (!pm_children_suspended(dev))
-		retval = -EBUSY;
-	if (retval &lt; 0)
-		return retval;
-
-	pm_runtime_deactivate_timer(dev);
-
-	if (dev-&gt;power.request_pending) {
-		/*
-		 * Pending resume requests take precedence over us, but we can
-		 * overtake any other pending request.
-		 */
-		if (dev-&gt;power.request == RPM_REQ_RESUME)
-			retval = -EAGAIN;
-		else if (dev-&gt;power.request != RPM_REQ_SUSPEND)
-			dev-&gt;power.request = retval ?
-						RPM_REQ_NONE : RPM_REQ_SUSPEND;
-		return retval;
-	} else if (retval) {
-		return retval;
-	}
-
-	dev-&gt;power.request = RPM_REQ_SUSPEND;
-	dev-&gt;power.request_pending = true;
-	queue_work(pm_wq, &amp;dev-&gt;power.work);
-
-	return 0;
-}
-
 /**
  * pm_suspend_timer_fn - Timer function for pm_schedule_suspend().
  * @data: Device pointer passed by pm_schedule_suspend().
  *
- * Check if the time is right and execute __pm_request_suspend() in that case.
+ * Check if the time is right and queue a suspend request.
  */
 static void pm_suspend_timer_fn(unsigned long data)
 {
@@ -656,7 +627,7 @@ static void pm_suspend_timer_fn(unsigned long data)
 	/* If 'expire' is after 'jiffies' we've been called too early. */
 	if (expires &gt; 0 &amp;&amp; !time_after(expires, jiffies)) {
 		dev-&gt;power.timer_expires = 0;
-		__pm_request_suspend(dev);
+		__pm_runtime_suspend(dev, RPM_ASYNC);
 	}
 
 	spin_unlock_irqrestore(&amp;dev-&gt;power.lock, flags);
@@ -670,47 +641,24 @@ static void pm_suspend_timer_fn(unsigned long data)
 int pm_schedule_suspend(struct device *dev, unsigned int delay)
 {
 	unsigned long flags;
-	int retval = 0;
+	int retval;
 
 	spin_lock_irqsave(&amp;dev-&gt;power.lock, flags);
 
-	if (dev-&gt;power.runtime_error) {
-		retval = -EINVAL;
-		goto out;
-	}
-
 	if (!delay) {
-		retval = __pm_request_suspend(dev);
+		retval = __pm_runtime_suspend(dev, RPM_ASYNC);
 		goto out;
 	}
 
-	pm_runtime_deactivate_timer(dev);
-
-	if (dev-&gt;power.request_pending) {
-		/*
-		 * Pending resume requests take precedence over us, but any
-		 * other pending requests have to be canceled.
-		 */
-		if (dev-&gt;power.request == RPM_REQ_RESUME) {
-			retval = -EAGAIN;
-			goto out;
-		}
-		dev-&gt;power.request = RPM_REQ_NONE;
-	}
-
-	if (dev-&gt;power.runtime_status == RPM_SUSPENDED)
-		retval = 1;
-	else if (atomic_read(&amp;dev-&gt;power.usage_count) &gt; 0
-	    || dev-&gt;power.disable_depth &gt; 0)
-		retval = -EAGAIN;
-	else if (!pm_children_suspended(dev))
-		retval = -EBUSY;
+	retval = rpm_check_suspend_allowed(dev);
 	if (retval)
 		goto out;
 
+	/* Other scheduled or pending requests need to be canceled. */
+	pm_runtime_cancel_pending(dev);
+
 	dev-&gt;power.timer_expires = jiffies + msecs_to_jiffies(delay);
-	if (!dev-&gt;power.timer_expires)
-		dev-&gt;power.timer_expires = 1;
+	dev-&gt;power.timer_expires += !dev-&gt;power.timer_expires;
 	mod_timer(&amp;dev-&gt;power.suspend_timer, dev-&gt;power.timer_expires);
 
  out:
@@ -720,49 +668,6 @@ int pm_schedule_suspend(struct device *dev, unsigned int delay)
 }
 EXPORT_SYMBOL_GPL(pm_schedule_suspend);
 
-/**
- * pm_request_resume - Submit a resume request for given device.
- * @dev: Device to resume.
- *
- * This function must be called under dev-&gt;power.lock with interrupts disabled.
- */
-static int __pm_request_resume(struct device *dev)
-{
-	int retval = 0;
-
-	if (dev-&gt;power.runtime_error)
-		return -EINVAL;
-
-	if (dev-&gt;power.runtime_status == RPM_ACTIVE)
-		retval = 1;
-	else if (dev-&gt;power.runtime_status == RPM_RESUMING)
-		retval = -EINPROGRESS;
-	else if (dev-&gt;power.disable_depth &gt; 0)
-		retval = -EAGAIN;
-	if (retval &lt; 0)
-		return retval;
-
-	pm_runtime_deactivate_timer(dev);
-
-	if (dev-&gt;power.runtime_status == RPM_SUSPENDING) {
-		dev-&gt;power.deferred_resume = true;
-		return retval;
-	}
-	if (dev-&gt;power.request_pending) {
-		/* If non-resume request is pending, we can overtake it. */
-		dev-&gt;power.request = retval ? RPM_REQ_NONE : RPM_REQ_RESUME;
-		return retval;
-	}
-	if (retval)
-		return retval;
-
-	dev-&gt;power.request = RPM_REQ_RESUME;
-	dev-&gt;power.request_pending = true;
-	queue_work(pm_wq, &amp;dev-&gt;power.work);
-
-	return retval;
-}
-
 /**
  * pm_request_resume - Submit a resume request for given device.
  * @dev: Device to resume.
@@ -773,7 +678,7 @@ int pm_request_resume(struct device *dev)
 	int retval;
 
 	spin_lock_irqsave(&amp;dev-&gt;power.lock, flags);
-	retval = __pm_request_resume(dev);
+	retval = __pm_runtime_resume(dev, RPM_ASYNC);
 	spin_unlock_irqrestore(&amp;dev-&gt;power.lock, flags);
 
 	return retval;
@@ -1088,7 +993,7 @@ void pm_runtime_allow(struct device *dev)
 
 	dev-&gt;power.runtime_auto = true;
 	if (atomic_dec_and_test(&amp;dev-&gt;power.usage_count))
-		__pm_runtime_idle(dev);
+		__pm_runtime_idle(dev, 0);
 
  out:
 	spin_unlock_irq(&amp;dev-&gt;power.lock);</pre><hr><pre>commit 3f9af0513ae5b1f185302c2d0ba656640926d970
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Sat Sep 25 23:34:54 2010 +0200

    PM / Runtime: Replace boolean arguments with bitflags
    
    The "from_wq" argument in __pm_runtime_suspend() and
    __pm_runtime_resume() supposedly indicates whether or not the function
    was called by the PM workqueue thread, but in fact it isn't always
    used this way.  It really indicates whether or not the function should
    return early if the requested operation is already in progress.
    
    Along with this badly-named boolean argument, later patches in this
    series will add several other boolean arguments to these functions and
    others.  Therefore this patch (as1422) begins the conversion process
    by replacing from_wq with a bitflag argument.  The same bitflags are
    also used in __pm_runtime_get() and __pm_runtime_put(), where they
    indicate whether or not the operation should be asynchronous.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Rafael J. Wysocki &lt;rjw@sisk.pl&gt;

diff --git a/drivers/base/power/runtime.c b/drivers/base/power/runtime.c
index ec08f1ae63f1..0c1db879544b 100644
--- a/drivers/base/power/runtime.c
+++ b/drivers/base/power/runtime.c
@@ -10,7 +10,7 @@
 #include &lt;linux/pm_runtime.h&gt;
 #include &lt;linux/jiffies.h&gt;
 
-static int __pm_runtime_resume(struct device *dev, bool from_wq);
+static int __pm_runtime_resume(struct device *dev, int rpmflags);
 static int __pm_request_idle(struct device *dev);
 static int __pm_request_resume(struct device *dev);
 
@@ -164,24 +164,24 @@ EXPORT_SYMBOL_GPL(pm_runtime_idle);
 /**
  * __pm_runtime_suspend - Carry out run-time suspend of given device.
  * @dev: Device to suspend.
- * @from_wq: If set, the function has been called via pm_wq.
+ * @rpmflags: Flag bits.
  *
  * Check if the device can be suspended and run the -&gt;runtime_suspend() callback
- * provided by its bus type.  If another suspend has been started earlier, wait
- * for it to finish.  If an idle notification or suspend request is pending or
+ * provided by its bus type.  If another suspend has been started earlier,
+ * either return immediately or wait for it to finish, depending on the
+ * RPM_NOWAIT flag.  If an idle notification or suspend request is pending or
  * scheduled, cancel it.
  *
  * This function must be called under dev-&gt;power.lock with interrupts disabled.
  */
-int __pm_runtime_suspend(struct device *dev, bool from_wq)
+static int __pm_runtime_suspend(struct device *dev, int rpmflags)
 	__releases(&amp;dev-&gt;power.lock) __acquires(&amp;dev-&gt;power.lock)
 {
 	struct device *parent = NULL;
 	bool notify = false;
 	int retval = 0;
 
-	dev_dbg(dev, "__pm_runtime_suspend()%s!\n",
-		from_wq ? " from workqueue" : "");
+	dev_dbg(dev, "%s flags 0x%x\n", __func__, rpmflags);
 
  repeat:
 	if (dev-&gt;power.runtime_error) {
@@ -213,7 +213,7 @@ int __pm_runtime_suspend(struct device *dev, bool from_wq)
 	if (dev-&gt;power.runtime_status == RPM_SUSPENDING) {
 		DEFINE_WAIT(wait);
 
-		if (from_wq) {
+		if (rpmflags &amp; RPM_NOWAIT) {
 			retval = -EINPROGRESS;
 			goto out;
 		}
@@ -286,7 +286,7 @@ int __pm_runtime_suspend(struct device *dev, bool from_wq)
 	wake_up_all(&amp;dev-&gt;power.wait_queue);
 
 	if (dev-&gt;power.deferred_resume) {
-		__pm_runtime_resume(dev, false);
+		__pm_runtime_resume(dev, 0);
 		retval = -EAGAIN;
 		goto out;
 	}
@@ -303,7 +303,7 @@ int __pm_runtime_suspend(struct device *dev, bool from_wq)
 	}
 
  out:
-	dev_dbg(dev, "__pm_runtime_suspend() returns %d!\n", retval);
+	dev_dbg(dev, "%s returns %d\n", __func__, retval);
 
 	return retval;
 }
@@ -317,7 +317,7 @@ int pm_runtime_suspend(struct device *dev)
 	int retval;
 
 	spin_lock_irq(&amp;dev-&gt;power.lock);
-	retval = __pm_runtime_suspend(dev, false);
+	retval = __pm_runtime_suspend(dev, 0);
 	spin_unlock_irq(&amp;dev-&gt;power.lock);
 
 	return retval;
@@ -327,24 +327,25 @@ EXPORT_SYMBOL_GPL(pm_runtime_suspend);
 /**
  * __pm_runtime_resume - Carry out run-time resume of given device.
  * @dev: Device to resume.
- * @from_wq: If set, the function has been called via pm_wq.
+ * @rpmflags: Flag bits.
  *
  * Check if the device can be woken up and run the -&gt;runtime_resume() callback
- * provided by its bus type.  If another resume has been started earlier, wait
- * for it to finish.  If there's a suspend running in parallel with this
- * function, wait for it to finish and resume the device.  Cancel any scheduled
- * or pending requests.
+ * provided by its bus type.  If another resume has been started earlier,
+ * either return imediately or wait for it to finish, depending on the
+ * RPM_NOWAIT flag.  If there's a suspend running in parallel with this
+ * function, either tell the other process to resume after suspending
+ * (deferred_resume) or wait for it to finish, depending on the RPM_NOWAIT
+ * flag.  Cancel any scheduled or pending requests.
  *
  * This function must be called under dev-&gt;power.lock with interrupts disabled.
  */
-int __pm_runtime_resume(struct device *dev, bool from_wq)
+static int __pm_runtime_resume(struct device *dev, int rpmflags)
 	__releases(&amp;dev-&gt;power.lock) __acquires(&amp;dev-&gt;power.lock)
 {
 	struct device *parent = NULL;
 	int retval = 0;
 
-	dev_dbg(dev, "__pm_runtime_resume()%s!\n",
-		from_wq ? " from workqueue" : "");
+	dev_dbg(dev, "%s flags 0x%x\n", __func__, rpmflags);
 
  repeat:
 	if (dev-&gt;power.runtime_error) {
@@ -365,7 +366,7 @@ int __pm_runtime_resume(struct device *dev, bool from_wq)
 	    || dev-&gt;power.runtime_status == RPM_SUSPENDING) {
 		DEFINE_WAIT(wait);
 
-		if (from_wq) {
+		if (rpmflags &amp; RPM_NOWAIT) {
 			if (dev-&gt;power.runtime_status == RPM_SUSPENDING)
 				dev-&gt;power.deferred_resume = true;
 			retval = -EINPROGRESS;
@@ -407,7 +408,7 @@ int __pm_runtime_resume(struct device *dev, bool from_wq)
 		 */
 		if (!parent-&gt;power.disable_depth
 		    &amp;&amp; !parent-&gt;power.ignore_children) {
-			__pm_runtime_resume(parent, false);
+			__pm_runtime_resume(parent, 0);
 			if (parent-&gt;power.runtime_status != RPM_ACTIVE)
 				retval = -EBUSY;
 		}
@@ -470,7 +471,7 @@ int __pm_runtime_resume(struct device *dev, bool from_wq)
 		spin_lock_irq(&amp;dev-&gt;power.lock);
 	}
 
-	dev_dbg(dev, "__pm_runtime_resume() returns %d!\n", retval);
+	dev_dbg(dev, "%s returns %d\n", __func__, retval);
 
 	return retval;
 }
@@ -484,7 +485,7 @@ int pm_runtime_resume(struct device *dev)
 	int retval;
 
 	spin_lock_irq(&amp;dev-&gt;power.lock);
-	retval = __pm_runtime_resume(dev, false);
+	retval = __pm_runtime_resume(dev, 0);
 	spin_unlock_irq(&amp;dev-&gt;power.lock);
 
 	return retval;
@@ -519,10 +520,10 @@ static void pm_runtime_work(struct work_struct *work)
 		__pm_runtime_idle(dev);
 		break;
 	case RPM_REQ_SUSPEND:
-		__pm_runtime_suspend(dev, true);
+		__pm_runtime_suspend(dev, RPM_NOWAIT);
 		break;
 	case RPM_REQ_RESUME:
-		__pm_runtime_resume(dev, true);
+		__pm_runtime_resume(dev, RPM_NOWAIT);
 		break;
 	}
 
@@ -782,17 +783,18 @@ EXPORT_SYMBOL_GPL(pm_request_resume);
 /**
  * __pm_runtime_get - Reference count a device and wake it up, if necessary.
  * @dev: Device to handle.
- * @sync: If set and the device is suspended, resume it synchronously.
+ * @rpmflags: Flag bits.
  *
  * Increment the usage count of the device and resume it or submit a resume
- * request for it, depending on the value of @sync.
+ * request for it, depending on the RPM_ASYNC flag bit.
  */
-int __pm_runtime_get(struct device *dev, bool sync)
+int __pm_runtime_get(struct device *dev, int rpmflags)
 {
 	int retval;
 
 	atomic_inc(&amp;dev-&gt;power.usage_count);
-	retval = sync ? pm_runtime_resume(dev) : pm_request_resume(dev);
+	retval = (rpmflags &amp; RPM_ASYNC) ?
+	    pm_request_resume(dev) : pm_runtime_resume(dev);
 
 	return retval;
 }
@@ -801,18 +803,19 @@ EXPORT_SYMBOL_GPL(__pm_runtime_get);
 /**
  * __pm_runtime_put - Decrement the device's usage counter and notify its bus.
  * @dev: Device to handle.
- * @sync: If the device's bus type is to be notified, do that synchronously.
+ * @rpmflags: Flag bits.
  *
  * Decrement the usage count of the device and if it reaches zero, carry out a
  * synchronous idle notification or submit an idle notification request for it,
- * depending on the value of @sync.
+ * depending on the RPM_ASYNC flag bit.
  */
-int __pm_runtime_put(struct device *dev, bool sync)
+int __pm_runtime_put(struct device *dev, int rpmflags)
 {
 	int retval = 0;
 
 	if (atomic_dec_and_test(&amp;dev-&gt;power.usage_count))
-		retval = sync ? pm_runtime_idle(dev) : pm_request_idle(dev);
+		retval = (rpmflags &amp; RPM_ASYNC) ?
+		    pm_request_idle(dev) : pm_runtime_idle(dev);
 
 	return retval;
 }
@@ -967,7 +970,7 @@ int pm_runtime_barrier(struct device *dev)
 
 	if (dev-&gt;power.request_pending
 	    &amp;&amp; dev-&gt;power.request == RPM_REQ_RESUME) {
-		__pm_runtime_resume(dev, false);
+		__pm_runtime_resume(dev, 0);
 		retval = 1;
 	}
 
@@ -1016,7 +1019,7 @@ void __pm_runtime_disable(struct device *dev, bool check_resume)
 		 */
 		pm_runtime_get_noresume(dev);
 
-		__pm_runtime_resume(dev, false);
+		__pm_runtime_resume(dev, 0);
 
 		pm_runtime_put_noidle(dev);
 	}
@@ -1064,7 +1067,7 @@ void pm_runtime_forbid(struct device *dev)
 
 	dev-&gt;power.runtime_auto = false;
 	atomic_inc(&amp;dev-&gt;power.usage_count);
-	__pm_runtime_resume(dev, false);
+	__pm_runtime_resume(dev, 0);
 
  out:
 	spin_unlock_irq(&amp;dev-&gt;power.lock);
diff --git a/include/linux/pm_runtime.h b/include/linux/pm_runtime.h
index 6e81888c6222..c030cac59aac 100644
--- a/include/linux/pm_runtime.h
+++ b/include/linux/pm_runtime.h
@@ -12,6 +12,11 @@
 #include &lt;linux/device.h&gt;
 #include &lt;linux/pm.h&gt;
 
+/* Runtime PM flag argument bits */
+#define RPM_ASYNC		0x01	/* Request is asynchronous */
+#define RPM_NOWAIT		0x02	/* Don't wait for concurrent
+					    state change */
+
 #ifdef CONFIG_PM_RUNTIME
 
 extern struct workqueue_struct *pm_wq;
@@ -22,8 +27,8 @@ extern int pm_runtime_resume(struct device *dev);
 extern int pm_request_idle(struct device *dev);
 extern int pm_schedule_suspend(struct device *dev, unsigned int delay);
 extern int pm_request_resume(struct device *dev);
-extern int __pm_runtime_get(struct device *dev, bool sync);
-extern int __pm_runtime_put(struct device *dev, bool sync);
+extern int __pm_runtime_get(struct device *dev, int rpmflags);
+extern int __pm_runtime_put(struct device *dev, int rpmflags);
 extern int __pm_runtime_set_status(struct device *dev, unsigned int status);
 extern int pm_runtime_barrier(struct device *dev);
 extern void pm_runtime_enable(struct device *dev);
@@ -81,8 +86,10 @@ static inline int pm_schedule_suspend(struct device *dev, unsigned int delay)
 	return -ENOSYS;
 }
 static inline int pm_request_resume(struct device *dev) { return 0; }
-static inline int __pm_runtime_get(struct device *dev, bool sync) { return 1; }
-static inline int __pm_runtime_put(struct device *dev, bool sync) { return 0; }
+static inline int __pm_runtime_get(struct device *dev, int rpmflags)
+					{ return 1; }
+static inline int __pm_runtime_put(struct device *dev, int rpmflags)
+					{ return 0; }
 static inline int __pm_runtime_set_status(struct device *dev,
 					    unsigned int status) { return 0; }
 static inline int pm_runtime_barrier(struct device *dev) { return 0; }
@@ -107,22 +114,22 @@ static inline int pm_generic_runtime_resume(struct device *dev) { return 0; }
 
 static inline int pm_runtime_get(struct device *dev)
 {
-	return __pm_runtime_get(dev, false);
+	return __pm_runtime_get(dev, RPM_ASYNC);
 }
 
 static inline int pm_runtime_get_sync(struct device *dev)
 {
-	return __pm_runtime_get(dev, true);
+	return __pm_runtime_get(dev, 0);
 }
 
 static inline int pm_runtime_put(struct device *dev)
 {
-	return __pm_runtime_put(dev, false);
+	return __pm_runtime_put(dev, RPM_ASYNC);
 }
 
 static inline int pm_runtime_put_sync(struct device *dev)
 {
-	return __pm_runtime_put(dev, true);
+	return __pm_runtime_put(dev, 0);
 }
 
 static inline int pm_runtime_set_active(struct device *dev)</pre>
    <div class="pagination">
        <a href='2_60.html'>&lt;&lt;Prev</a><a href='2.html'>1</a><a href='2_2.html'>2</a><a href='2_3.html'>3</a><a href='2_4.html'>4</a><a href='2_5.html'>5</a><a href='2_6.html'>6</a><a href='2_7.html'>7</a><a href='2_8.html'>8</a><a href='2_9.html'>9</a><a href='2_10.html'>10</a><a href='2_11.html'>11</a><a href='2_12.html'>12</a><a href='2_13.html'>13</a><a href='2_14.html'>14</a><a href='2_15.html'>15</a><a href='2_16.html'>16</a><a href='2_17.html'>17</a><a href='2_18.html'>18</a><a href='2_19.html'>19</a><a href='2_20.html'>20</a><a href='2_21.html'>21</a><a href='2_22.html'>22</a><a href='2_23.html'>23</a><a href='2_24.html'>24</a><a href='2_25.html'>25</a><a href='2_26.html'>26</a><a href='2_27.html'>27</a><a href='2_28.html'>28</a><a href='2_29.html'>29</a><a href='2_30.html'>30</a><a href='2_31.html'>31</a><a href='2_32.html'>32</a><a href='2_33.html'>33</a><a href='2_34.html'>34</a><a href='2_35.html'>35</a><a href='2_36.html'>36</a><a href='2_37.html'>37</a><a href='2_38.html'>38</a><a href='2_39.html'>39</a><a href='2_40.html'>40</a><a href='2_41.html'>41</a><a href='2_42.html'>42</a><a href='2_43.html'>43</a><a href='2_44.html'>44</a><a href='2_45.html'>45</a><a href='2_46.html'>46</a><a href='2_47.html'>47</a><a href='2_48.html'>48</a><a href='2_49.html'>49</a><a href='2_50.html'>50</a><a href='2_51.html'>51</a><a href='2_52.html'>52</a><a href='2_53.html'>53</a><a href='2_54.html'>54</a><a href='2_55.html'>55</a><a href='2_56.html'>56</a><a href='2_57.html'>57</a><a href='2_58.html'>58</a><a href='2_59.html'>59</a><a href='2_60.html'>60</a><span>[61]</span><a href='2_62.html'>62</a><a href='2_63.html'>63</a><a href='2_64.html'>64</a><a href='2_65.html'>65</a><a href='2_66.html'>66</a><a href='2_67.html'>67</a><a href='2_68.html'>68</a><a href='2_69.html'>69</a><a href='2_70.html'>70</a><a href='2_71.html'>71</a><a href='2_72.html'>72</a><a href='2_73.html'>73</a><a href='2_74.html'>74</a><a href='2_75.html'>75</a><a href='2_76.html'>76</a><a href='2_77.html'>77</a><a href='2_78.html'>78</a><a href='2_79.html'>79</a><a href='2_80.html'>80</a><a href='2_81.html'>81</a><a href='2_82.html'>82</a><a href='2_83.html'>83</a><a href='2_84.html'>84</a><a href='2_85.html'>85</a><a href='2_86.html'>86</a><a href='2_87.html'>87</a><a href='2_88.html'>88</a><a href='2_89.html'>89</a><a href='2_90.html'>90</a><a href='2_91.html'>91</a><a href='2_92.html'>92</a><a href='2_93.html'>93</a><a href='2_94.html'>94</a><a href='2_95.html'>95</a><a href='2_96.html'>96</a><a href='2_97.html'>97</a><a href='2_98.html'>98</a><a href='2_99.html'>99</a><a href='2_100.html'>100</a><a href='2_101.html'>101</a><a href='2_102.html'>102</a><a href='2_103.html'>103</a><a href='2_104.html'>104</a><a href='2_105.html'>105</a><a href='2_106.html'>106</a><a href='2_107.html'>107</a><a href='2_108.html'>108</a><a href='2_109.html'>109</a><a href='2_110.html'>110</a><a href='2_111.html'>111</a><a href='2_112.html'>112</a><a href='2_113.html'>113</a><a href='2_114.html'>114</a><a href='2_115.html'>115</a><a href='2_116.html'>116</a><a href='2_117.html'>117</a><a href='2_118.html'>118</a><a href='2_119.html'>119</a><a href='2_120.html'>120</a><a href='2_121.html'>121</a><a href='2_122.html'>122</a><a href='2_123.html'>123</a><a href='2_124.html'>124</a><a href='2_125.html'>125</a><a href='2_126.html'>126</a><a href='2_127.html'>127</a><a href='2_128.html'>128</a><a href='2_129.html'>129</a><a href='2_130.html'>130</a><a href='2_131.html'>131</a><a href='2_132.html'>132</a><a href='2_133.html'>133</a><a href='2_134.html'>134</a><a href='2_135.html'>135</a><a href='2_136.html'>136</a><a href='2_137.html'>137</a><a href='2_138.html'>138</a><a href='2_139.html'>139</a><a href='2_140.html'>140</a><a href='2_62.html'>Next&gt;&gt;</a>
    <div>
</body>
