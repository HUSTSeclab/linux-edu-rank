<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patches contributed by Harvard University</title>
    <style>
    .pagination {
        border-top: 1px solid #ddd;
        border-bottom: 1px solid #ddd;
        overflow-wrap: break-word;
    }
    .pagination a, .pagination span {
        margin: 0 4px;
    }

    </style>
</head>
<body>
    <h1>Patches contributed by Harvard University</h1>
    <div class="pagination">
        <a href='2_16.html'>&lt;&lt;Prev</a><a href='2.html'>1</a><a href='2_2.html'>2</a><a href='2_3.html'>3</a><a href='2_4.html'>4</a><a href='2_5.html'>5</a><a href='2_6.html'>6</a><a href='2_7.html'>7</a><a href='2_8.html'>8</a><a href='2_9.html'>9</a><a href='2_10.html'>10</a><a href='2_11.html'>11</a><a href='2_12.html'>12</a><a href='2_13.html'>13</a><a href='2_14.html'>14</a><a href='2_15.html'>15</a><a href='2_16.html'>16</a><span>[17]</span><a href='2_18.html'>18</a><a href='2_19.html'>19</a><a href='2_20.html'>20</a><a href='2_21.html'>21</a><a href='2_22.html'>22</a><a href='2_23.html'>23</a><a href='2_24.html'>24</a><a href='2_25.html'>25</a><a href='2_26.html'>26</a><a href='2_27.html'>27</a><a href='2_28.html'>28</a><a href='2_29.html'>29</a><a href='2_30.html'>30</a><a href='2_31.html'>31</a><a href='2_32.html'>32</a><a href='2_33.html'>33</a><a href='2_34.html'>34</a><a href='2_35.html'>35</a><a href='2_36.html'>36</a><a href='2_37.html'>37</a><a href='2_38.html'>38</a><a href='2_39.html'>39</a><a href='2_40.html'>40</a><a href='2_41.html'>41</a><a href='2_42.html'>42</a><a href='2_43.html'>43</a><a href='2_44.html'>44</a><a href='2_45.html'>45</a><a href='2_46.html'>46</a><a href='2_47.html'>47</a><a href='2_48.html'>48</a><a href='2_49.html'>49</a><a href='2_50.html'>50</a><a href='2_51.html'>51</a><a href='2_52.html'>52</a><a href='2_53.html'>53</a><a href='2_54.html'>54</a><a href='2_55.html'>55</a><a href='2_56.html'>56</a><a href='2_57.html'>57</a><a href='2_58.html'>58</a><a href='2_59.html'>59</a><a href='2_60.html'>60</a><a href='2_61.html'>61</a><a href='2_62.html'>62</a><a href='2_63.html'>63</a><a href='2_64.html'>64</a><a href='2_65.html'>65</a><a href='2_66.html'>66</a><a href='2_67.html'>67</a><a href='2_68.html'>68</a><a href='2_69.html'>69</a><a href='2_70.html'>70</a><a href='2_71.html'>71</a><a href='2_72.html'>72</a><a href='2_73.html'>73</a><a href='2_74.html'>74</a><a href='2_75.html'>75</a><a href='2_76.html'>76</a><a href='2_77.html'>77</a><a href='2_78.html'>78</a><a href='2_79.html'>79</a><a href='2_80.html'>80</a><a href='2_81.html'>81</a><a href='2_82.html'>82</a><a href='2_83.html'>83</a><a href='2_84.html'>84</a><a href='2_85.html'>85</a><a href='2_86.html'>86</a><a href='2_87.html'>87</a><a href='2_88.html'>88</a><a href='2_89.html'>89</a><a href='2_90.html'>90</a><a href='2_91.html'>91</a><a href='2_92.html'>92</a><a href='2_93.html'>93</a><a href='2_94.html'>94</a><a href='2_95.html'>95</a><a href='2_96.html'>96</a><a href='2_97.html'>97</a><a href='2_98.html'>98</a><a href='2_99.html'>99</a><a href='2_100.html'>100</a><a href='2_101.html'>101</a><a href='2_102.html'>102</a><a href='2_103.html'>103</a><a href='2_104.html'>104</a><a href='2_105.html'>105</a><a href='2_106.html'>106</a><a href='2_107.html'>107</a><a href='2_108.html'>108</a><a href='2_109.html'>109</a><a href='2_110.html'>110</a><a href='2_111.html'>111</a><a href='2_112.html'>112</a><a href='2_113.html'>113</a><a href='2_114.html'>114</a><a href='2_115.html'>115</a><a href='2_116.html'>116</a><a href='2_117.html'>117</a><a href='2_118.html'>118</a><a href='2_119.html'>119</a><a href='2_120.html'>120</a><a href='2_121.html'>121</a><a href='2_122.html'>122</a><a href='2_123.html'>123</a><a href='2_124.html'>124</a><a href='2_125.html'>125</a><a href='2_126.html'>126</a><a href='2_127.html'>127</a><a href='2_128.html'>128</a><a href='2_129.html'>129</a><a href='2_130.html'>130</a><a href='2_131.html'>131</a><a href='2_132.html'>132</a><a href='2_133.html'>133</a><a href='2_134.html'>134</a><a href='2_135.html'>135</a><a href='2_136.html'>136</a><a href='2_137.html'>137</a><a href='2_138.html'>138</a><a href='2_139.html'>139</a><a href='2_140.html'>140</a><a href='2_18.html'>Next&gt;&gt;</a>
    </div>
    <hr>
    <pre>commit 379cacc5e566f7197bdeb1ea3e99219d3e880c0a
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Fri Jun 8 16:59:37 2018 -0400

    USB: Report wakeup events on root-hub ports
    
    When a USB device attached to a root-hub port sends a wakeup request
    to a sleeping system, we do not report the wakeup event to the PM
    core.  This is because a system resume involves waking up all
    suspended USB ports as quickly as possible; without the normal
    USB_RESUME_TIMEOUT delay, the host controller driver doesn't set the
    USB_PORT_STAT_C_SUSPEND flag and so usb_port_resume() doesn't realize
    that a wakeup request was received.
    
    However, some environments (such as Chrome OS) want to have all wakeup
    events reported so they can be ascribed to the appropriate device.  To
    accommodate these environments, this patch adds a new routine to the
    hub driver and a corresponding new HCD method to be used when a root
    hub resumes.  The HCD method returns a bitmap of ports that have
    initiated a wakeup signal but not yet completed resuming.  The hub
    driver can then report to the PM core that the child devices attached
    to these ports initiated a wakeup event.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Suggested-by: Anshuman Gupta &lt;anshuman.gupta@intel.com&gt;
    Signed-off-by: Greg Kroah-Hartman &lt;gregkh@linuxfoundation.org&gt;

diff --git a/drivers/usb/core/hub.c b/drivers/usb/core/hub.c
index fcae521df29b..fef5af7aab92 100644
--- a/drivers/usb/core/hub.c
+++ b/drivers/usb/core/hub.c
@@ -3656,12 +3656,54 @@ static int hub_suspend(struct usb_interface *intf, pm_message_t msg)
 	return 0;
 }
 
+/* Report wakeup requests from the ports of a resuming root hub */
+static void report_wakeup_requests(struct usb_hub *hub)
+{
+	struct usb_device	*hdev = hub-&gt;hdev;
+	struct usb_device	*udev;
+	struct usb_hcd		*hcd;
+	unsigned long		resuming_ports;
+	int			i;
+
+	if (hdev-&gt;parent)
+		return;		/* Not a root hub */
+
+	hcd = bus_to_hcd(hdev-&gt;bus);
+	if (hcd-&gt;driver-&gt;get_resuming_ports) {
+
+		/*
+		 * The get_resuming_ports() method returns a bitmap (origin 0)
+		 * of ports which have started wakeup signaling but have not
+		 * yet finished resuming.  During system resume we will
+		 * resume all the enabled ports, regardless of any wakeup
+		 * signals, which means the wakeup requests would be lost.
+		 * To prevent this, report them to the PM core here.
+		 */
+		resuming_ports = hcd-&gt;driver-&gt;get_resuming_ports(hcd);
+		for (i = 0; i &lt; hdev-&gt;maxchild; ++i) {
+			if (test_bit(i, &amp;resuming_ports)) {
+				udev = hub-&gt;ports[i]-&gt;child;
+				if (udev)
+					pm_wakeup_event(&amp;udev-&gt;dev, 0);
+			}
+		}
+	}
+}
+
 static int hub_resume(struct usb_interface *intf)
 {
 	struct usb_hub *hub = usb_get_intfdata(intf);
 
 	dev_dbg(&amp;intf-&gt;dev, "%s\n", __func__);
 	hub_activate(hub, HUB_RESUME);
+
+	/*
+	 * This should be called only for system resume, not runtime resume.
+	 * We can't tell the difference here, so some wakeup requests will be
+	 * reported at the wrong time or more than once.  This shouldn't
+	 * matter much, so long as they do get reported.
+	 */
+	report_wakeup_requests(hub);
 	return 0;
 }
 
diff --git a/include/linux/usb/hcd.h b/include/linux/usb/hcd.h
index 34a6ded6f319..97e2ddec18b1 100644
--- a/include/linux/usb/hcd.h
+++ b/include/linux/usb/hcd.h
@@ -322,6 +322,7 @@ struct hc_driver {
 	int	(*bus_suspend)(struct usb_hcd *);
 	int	(*bus_resume)(struct usb_hcd *);
 	int	(*start_port_reset)(struct usb_hcd *, unsigned port_num);
+	unsigned long	(*get_resuming_ports)(struct usb_hcd *);
 
 		/* force handover of high-speed port to full-speed companion */
 	void	(*relinquish_port)(struct usb_hcd *, int);</pre><hr><pre>commit cee0321a404fe6b43d1f4364639c8ffe2f2b37d1
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Mon May 14 16:33:53 2018 -0700

    tools/memory-model: Remove out-of-date comments and code from lock.cat
    
    lock.cat contains old comments and code referring to the possibility
    of LKR events that are not part of an RMW pair.  This is a holdover
    from when I though we might end up using LKR events to implement
    spin_is_locked().  Reword the comments to remove this assumption and
    replace domain(lk-rmw) in the code with LKR.
    
    Tested-by: Andrea Parri &lt;andrea.parri@amarulasolutions.com&gt;
    [ paulmck: Pulled as lock-nest into previous line as discussed. ]
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Paul E. McKenney &lt;paulmck@linux.vnet.ibm.com&gt;
    Cc: Akira Yokosawa &lt;akiyks@gmail.com&gt;
    Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
    Cc: Boqun Feng &lt;boqun.feng@gmail.com&gt;
    Cc: David Howells &lt;dhowells@redhat.com&gt;
    Cc: Jade Alglave &lt;j.alglave@ucl.ac.uk&gt;
    Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
    Cc: Luc Maranget &lt;luc.maranget@inria.fr&gt;
    Cc: Nicholas Piggin &lt;npiggin@gmail.com&gt;
    Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;
    Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
    Cc: Will Deacon &lt;will.deacon@arm.com&gt;
    Cc: linux-arch@vger.kernel.org
    Cc: parri.andrea@gmail.com
    Link: http://lkml.kernel.org/r/1526340837-12222-15-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;

diff --git a/tools/memory-model/lock.cat b/tools/memory-model/lock.cat
index 7217cd4941a4..cd002a33ca8a 100644
--- a/tools/memory-model/lock.cat
+++ b/tools/memory-model/lock.cat
@@ -47,18 +47,15 @@ flag ~empty [M \ IW] ; loc ; [ALL-LOCKS] as mixed-lock-accesses
 let lk-rmw = ([LKR] ; po-loc ; [LKW]) \ (po ; po)
 let rmw = rmw | lk-rmw
 
+(* The litmus test is invalid if an LKR/LKW event is not part of an RMW pair *)
+flag ~empty LKW \ range(lk-rmw) as unpaired-LKW
+flag ~empty LKR \ domain(lk-rmw) as unpaired-LKR
+
 (*
- * A paired LKR must always see an unlocked value; spin_lock() calls nested
+ * An LKR must always see an unlocked value; spin_lock() calls nested
  * inside a critical section (for the same lock) always deadlock.
  *)
-empty ([LKW] ; po-loc ; [domain(lk-rmw)]) \ (po-loc ; [UL] ; po-loc)
-	as lock-nest
-
-(* The litmus test is invalid if an LKW event is not part of an RMW pair *)
-flag ~empty LKW \ range(lk-rmw) as unpaired-LKW
-
-(* This will be allowed if we implement spin_is_locked() *)
-flag ~empty LKR \ domain(lk-rmw) as unpaired-LKR
+empty ([LKW] ; po-loc ; [LKR]) \ (po-loc ; [UL] ; po-loc) as lock-nest
 
 (* The final value of a spinlock should not be tested *)
 flag ~empty [FW] ; loc ; [ALL-LOCKS] as lock-final</pre><hr><pre>commit 30b795df11a1a9dd7fc50c1ff4677343b67cb379
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Mon May 14 16:33:52 2018 -0700

    tools/memory-model: Improve mixed-access checking in lock.cat
    
    The code in lock.cat which checks for normal read/write accesses to
    spinlock variables doesn't take into account the newly added RL and RU
    events.  Add them into the test, and move the resulting code up near
    the start of the file, since a violation would indicate a pretty
    severe conceptual error in a litmus test.
    
    Tested-by: Andrea Parri &lt;andrea.parri@amarulasolutions.com&gt;
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Paul E. McKenney &lt;paulmck@linux.vnet.ibm.com&gt;
    Cc: Akira Yokosawa &lt;akiyks@gmail.com&gt;
    Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
    Cc: Boqun Feng &lt;boqun.feng@gmail.com&gt;
    Cc: David Howells &lt;dhowells@redhat.com&gt;
    Cc: Jade Alglave &lt;j.alglave@ucl.ac.uk&gt;
    Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
    Cc: Luc Maranget &lt;luc.maranget@inria.fr&gt;
    Cc: Nicholas Piggin &lt;npiggin@gmail.com&gt;
    Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;
    Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
    Cc: Will Deacon &lt;will.deacon@arm.com&gt;
    Cc: linux-arch@vger.kernel.org
    Cc: parri.andrea@gmail.com
    Link: http://lkml.kernel.org/r/1526340837-12222-14-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;

diff --git a/tools/memory-model/lock.cat b/tools/memory-model/lock.cat
index df74de2148f6..7217cd4941a4 100644
--- a/tools/memory-model/lock.cat
+++ b/tools/memory-model/lock.cat
@@ -32,6 +32,17 @@ include "cross.cat"
  * LKW, LF, RL, and RU have no ordering properties.
  *)
 
+(* Backward compatibility *)
+let RL = try RL with emptyset
+let RU = try RU with emptyset
+
+(* Treat RL as a kind of LF: a read with no ordering properties *)
+let LF = LF | RL
+
+(* There should be no ordinary R or W accesses to spinlocks *)
+let ALL-LOCKS = LKR | LKW | UL | LF | RU
+flag ~empty [M \ IW] ; loc ; [ALL-LOCKS] as mixed-lock-accesses
+
 (* Link Lock-Reads to their RMW-partner Lock-Writes *)
 let lk-rmw = ([LKR] ; po-loc ; [LKW]) \ (po ; po)
 let rmw = rmw | lk-rmw
@@ -49,20 +60,9 @@ flag ~empty LKW \ range(lk-rmw) as unpaired-LKW
 (* This will be allowed if we implement spin_is_locked() *)
 flag ~empty LKR \ domain(lk-rmw) as unpaired-LKR
 
-(* There should be no ordinary R or W accesses to spinlocks *)
-let ALL-LOCKS = LKR | LKW | UL | LF
-flag ~empty [M \ IW] ; loc ; [ALL-LOCKS] as mixed-lock-accesses
-
 (* The final value of a spinlock should not be tested *)
 flag ~empty [FW] ; loc ; [ALL-LOCKS] as lock-final
 
-(* Backward compatibility *)
-let RL = try RL with emptyset
-let RU = try RU with emptyset
-
-(* Treat RL as a kind of LF: a read with no ordering properties *)
-let LF = LF | RL
-
 (*
  * Put lock operations in their appropriate classes, but leave UL out of W
  * until after the co relation has been generated.</pre><hr><pre>commit fd0359dbac3df00d1c6c22769e7d647b16b920cc
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Mon May 14 16:33:51 2018 -0700

    tools/memory-model: Improve comments in lock.cat
    
    This patch improves the comments in tools/memory-model/lock.cat.  In
    addition to making the text more uniform and removing redundant
    comments, it adds a description of all the possible locking events
    that herd can generate.
    
    Tested-by: Andrea Parri &lt;andrea.parri@amarulasolutions.com&gt;
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Paul E. McKenney &lt;paulmck@linux.vnet.ibm.com&gt;
    Cc: Akira Yokosawa &lt;akiyks@gmail.com&gt;
    Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
    Cc: Boqun Feng &lt;boqun.feng@gmail.com&gt;
    Cc: David Howells &lt;dhowells@redhat.com&gt;
    Cc: Jade Alglave &lt;j.alglave@ucl.ac.uk&gt;
    Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
    Cc: Luc Maranget &lt;luc.maranget@inria.fr&gt;
    Cc: Nicholas Piggin &lt;npiggin@gmail.com&gt;
    Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;
    Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
    Cc: Will Deacon &lt;will.deacon@arm.com&gt;
    Cc: linux-arch@vger.kernel.org
    Cc: parri.andrea@gmail.com
    Link: http://lkml.kernel.org/r/1526340837-12222-13-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;

diff --git a/tools/memory-model/lock.cat b/tools/memory-model/lock.cat
index 1f6d67e79065..df74de2148f6 100644
--- a/tools/memory-model/lock.cat
+++ b/tools/memory-model/lock.cat
@@ -4,15 +4,35 @@
  * Copyright (C) 2017 Alan Stern &lt;stern@rowland.harvard.edu&gt;
  *)
 
-(* Generate coherence orders and handle lock operations *)
 (*
- * Warning, crashes with herd7 versions strictly before 7.48.
- * spin_islocked is functional from version 7.49.
+ * Generate coherence orders and handle lock operations
  *
+ * Warning: spin_is_locked() crashes herd7 versions strictly before 7.48.
+ * spin_is_locked() is functional from herd7 version 7.49.
  *)
+
 include "cross.cat"
 
-(* From lock reads to their partner lock writes *)
+(*
+ * The lock-related events generated by herd are as follows:
+ *
+ * LKR		Lock-Read: the read part of a spin_lock() or successful
+ *			spin_trylock() read-modify-write event pair
+ * LKW		Lock-Write: the write part of a spin_lock() or successful
+ *			spin_trylock() RMW event pair
+ * UL		Unlock: a spin_unlock() event
+ * LF		Lock-Fail: a failed spin_trylock() event
+ * RL		Read-Locked: a spin_is_locked() event which returns True
+ * RU		Read-Unlocked: a spin_is_locked() event which returns False
+ *
+ * LKR and LKW events always come paired, like all RMW event sequences.
+ *
+ * LKR, LF, RL, and RU are read events; LKR has Acquire ordering.
+ * LKW and UL are write events; UL has Release ordering.
+ * LKW, LF, RL, and RU have no ordering properties.
+ *)
+
+(* Link Lock-Reads to their RMW-partner Lock-Writes *)
 let lk-rmw = ([LKR] ; po-loc ; [LKW]) \ (po ; po)
 let rmw = rmw | lk-rmw
 
@@ -29,18 +49,16 @@ flag ~empty LKW \ range(lk-rmw) as unpaired-LKW
 (* This will be allowed if we implement spin_is_locked() *)
 flag ~empty LKR \ domain(lk-rmw) as unpaired-LKR
 
-(* There should be no R or W accesses to spinlocks *)
+(* There should be no ordinary R or W accesses to spinlocks *)
 let ALL-LOCKS = LKR | LKW | UL | LF
 flag ~empty [M \ IW] ; loc ; [ALL-LOCKS] as mixed-lock-accesses
 
 (* The final value of a spinlock should not be tested *)
 flag ~empty [FW] ; loc ; [ALL-LOCKS] as lock-final
 
-(*
- * Backward compatibility
- *)
-let RL = try RL with emptyset (* defined herd7 &gt;= 7.49 *)
-let RU = try RU with emptyset (* defined herd7 &gt;= 7.49 *)
+(* Backward compatibility *)
+let RL = try RL with emptyset
+let RU = try RU with emptyset
 
 (* Treat RL as a kind of LF: a read with no ordering properties *)
 let LF = LF | RL
@@ -55,7 +73,6 @@ let W = W | LKW
 let Release = Release | UL
 let Acquire = Acquire | LKR
 
-
 (* Match LKW events to their corresponding UL events *)
 let critical = ([LKW] ; po-loc ; [UL]) \ (po-loc ; [LKW | UL] ; po-loc)
 
@@ -65,7 +82,6 @@ flag ~empty UL \ range(critical) as unmatched-unlock
 let UNMATCHED-LKW = LKW \ domain(critical)
 empty ([UNMATCHED-LKW] ; loc ; [UNMATCHED-LKW]) \ id as unmatched-locks
 
-
 (* rfi for LF events: link each LKW to the LF events in its critical section *)
 let rfi-lf = ([LKW] ; po-loc ; [LF]) \ ([LKW] ; po-loc ; [UL] ; po-loc)
 
@@ -86,18 +102,23 @@ let all-possible-rfe-lf =
 with rfe-lf from cross(all-possible-rfe-lf)
 let rf-lf = rfe-lf | rfi-lf
 
-(* Read from unlock, ie islocked returning false, slightly different *)
+(*
+ * RU, i.e., spin_is_locked() returning False, is slightly different.
+ * We rely on the memory model to rule out cases where spin_is_locked()
+ * within one of the lock's critical sections returns False.
+ *)
 
-(* islocked returning false can read from the last po-previous unlock *)
+(* rfi for RU events: an RU may read from the last po-previous UL *)
 let rfi-ru = ([UL] ; po-loc ; [RU]) \ ([UL] ; po-loc ; [LKW] ; po-loc)
 
-(* any islocked returning false can read from any external unlock *)
+(* rfe for RU events: an RU may read from an external UL or the initial write *)
 let all-possible-rfe-ru =
    let possible-rfe-ru r =
      let pair-to-relation p = p ++ 0
      in map pair-to-relation (((UL|IW) * {r}) &amp; loc &amp; ext)
   in map possible-rfe-ru RU
 
+(* Generate all rf relations for RU events *)
 with rfe-ru from cross(all-possible-rfe-ru)
 let rf-ru = rfe-ru | rfi-ru
 </pre><hr><pre>commit 8559183ccaec97454b2515ac426f113967256cf9
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Mon May 14 16:33:50 2018 -0700

    tools/memory-model: Remove duplicated code from lock.cat
    
    This patch simplifies the implementation of spin_is_locked in the
    LKMM.  It capitalizes on the fact that a failed spin_trylock() and a
    spin_is_locked() which returns True have exactly the same semantics
    (those of READ_ONCE) and ordering properties (none).  Therefore the
    two kinds of events can be combined and handled by the same code,
    instead of treated separately as they are currently.
    
    Tested-by: Andrea Parri &lt;andrea.parri@amarulasolutions.com&gt;
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Paul E. McKenney &lt;paulmck@linux.vnet.ibm.com&gt;
    Cc: Akira Yokosawa &lt;akiyks@gmail.com&gt;
    Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
    Cc: Boqun Feng &lt;boqun.feng@gmail.com&gt;
    Cc: David Howells &lt;dhowells@redhat.com&gt;
    Cc: Jade Alglave &lt;j.alglave@ucl.ac.uk&gt;
    Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
    Cc: Luc Maranget &lt;luc.maranget@inria.fr&gt;
    Cc: Nicholas Piggin &lt;npiggin@gmail.com&gt;
    Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;
    Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
    Cc: Will Deacon &lt;will.deacon@arm.com&gt;
    Cc: linux-arch@vger.kernel.org
    Cc: parri.andrea@gmail.com
    Link: http://lkml.kernel.org/r/1526340837-12222-12-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;

diff --git a/tools/memory-model/lock.cat b/tools/memory-model/lock.cat
index 3b1439edc818..1f6d67e79065 100644
--- a/tools/memory-model/lock.cat
+++ b/tools/memory-model/lock.cat
@@ -41,11 +41,15 @@ flag ~empty [FW] ; loc ; [ALL-LOCKS] as lock-final
  *)
 let RL = try RL with emptyset (* defined herd7 &gt;= 7.49 *)
 let RU = try RU with emptyset (* defined herd7 &gt;= 7.49 *)
+
+(* Treat RL as a kind of LF: a read with no ordering properties *)
+let LF = LF | RL
+
 (*
  * Put lock operations in their appropriate classes, but leave UL out of W
  * until after the co relation has been generated.
  *)
-let R = R | LKR | LF | RL | RU
+let R = R | LKR | LF | RU
 let W = W | LKW
 
 let Release = Release | UL
@@ -80,28 +84,8 @@ let all-possible-rfe-lf =
 
 (* Generate all rf relations for LF events *)
 with rfe-lf from cross(all-possible-rfe-lf)
-
 let rf-lf = rfe-lf | rfi-lf
 
-(* rf for RL events, ie islocked returning true, similar to LF above *)
-
-(* islocked returning true inside a critical section
- * must read from the opening lock
- *)
-let rfi-rl = ([LKW] ; po-loc ; [RL]) \ ([LKW] ; po-loc ; [UL] ; po-loc)
-
-(* islocked returning true outside critical sections can match any
- * external lock.
- *)
-let all-possible-rfe-rl =
-  let possible-rfe-lf r =
-    let pair-to-relation p = p ++ 0
-    in map pair-to-relation ((LKW * {r}) &amp; loc &amp; ext)
-  in map possible-rfe-lf (RL \ range(rfi-rl))
-
-with rfe-rl from cross(all-possible-rfe-rl)
-let rf-rl = rfe-rl | rfi-rl
-
 (* Read from unlock, ie islocked returning false, slightly different *)
 
 (* islocked returning false can read from the last po-previous unlock *)
@@ -118,7 +102,7 @@ with rfe-ru from cross(all-possible-rfe-ru)
 let rf-ru = rfe-ru | rfi-ru
 
 (* Final rf relation *)
-let rf = rf | rf-lf | rf-rl | rf-ru
+let rf = rf | rf-lf | rf-ru
 
 (* Generate all co relations, including LKW events but not UL *)
 let co0 = co0 | ([IW] ; loc ; [LKW]) |</pre><hr><pre>commit 9d036883a17969caf8796d1fce813af0ab016986
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Mon May 14 16:33:40 2018 -0700

    tools/memory-model: Redefine rb in terms of rcu-fence
    
    This patch reorganizes the definition of rb in the Linux Kernel Memory
    Consistency Model.  The relation is now expressed in terms of
    rcu-fence, which consists of a sequence of gp and rscs links separated
    by rcu-link links, in which the number of occurrences of gp is &gt;= the
    number of occurrences of rscs.
    
    Arguments similar to those published in
    http://diy.inria.fr/linux/long.pdf show that rcu-fence behaves like an
    inter-CPU strong fence.  Furthermore, the definition of rb in terms of
    rcu-fence is highly analogous to the definition of pb in terms of
    strong-fence, which can help explain why rcu-path expresses a form of
    temporal ordering.
    
    This change should not affect the semantics of the memory model, just
    its internal organization.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Paul E. McKenney &lt;paulmck@linux.vnet.ibm.com&gt;
    Reviewed-by: Boqun Feng &lt;boqun.feng@gmail.com&gt;
    Reviewed-by: Andrea Parri &lt;parri.andrea@gmail.com&gt;
    Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
    Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
    Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;
    Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
    Cc: Will Deacon &lt;will.deacon@arm.com&gt;
    Cc: akiyks@gmail.com
    Cc: dhowells@redhat.com
    Cc: j.alglave@ucl.ac.uk
    Cc: linux-arch@vger.kernel.org
    Cc: luc.maranget@inria.fr
    Cc: npiggin@gmail.com
    Link: http://lkml.kernel.org/r/1526340837-12222-2-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;

diff --git a/tools/memory-model/Documentation/explanation.txt b/tools/memory-model/Documentation/explanation.txt
index 1a387d703212..1b09f3175a1f 100644
--- a/tools/memory-model/Documentation/explanation.txt
+++ b/tools/memory-model/Documentation/explanation.txt
@@ -27,7 +27,7 @@ Explanation of the Linux-Kernel Memory Consistency Model
   19. AND THEN THERE WAS ALPHA
   20. THE HAPPENS-BEFORE RELATION: hb
   21. THE PROPAGATES-BEFORE RELATION: pb
-  22. RCU RELATIONS: rcu-link, gp-link, rscs-link, and rb
+  22. RCU RELATIONS: rcu-link, gp, rscs, rcu-fence, and rb
   23. ODDS AND ENDS
 
 
@@ -1451,8 +1451,8 @@ they execute means that it cannot have cycles.  This requirement is
 the content of the LKMM's "propagation" axiom.
 
 
-RCU RELATIONS: rcu-link, gp-link, rscs-link, and rb
----------------------------------------------------
+RCU RELATIONS: rcu-link, gp, rscs, rcu-fence, and rb
+----------------------------------------------------
 
 RCU (Read-Copy-Update) is a powerful synchronization mechanism.  It
 rests on two concepts: grace periods and read-side critical sections.
@@ -1537,49 +1537,100 @@ relation, and the details don't matter unless you want to comb through
 a somewhat lengthy formal proof.  Pretty much all you need to know
 about rcu-link is the information in the preceding paragraph.
 
-The LKMM goes on to define the gp-link and rscs-link relations.  They
-bring grace periods and read-side critical sections into the picture,
-in the following way:
+The LKMM also defines the gp and rscs relations.  They bring grace
+periods and read-side critical sections into the picture, in the
+following way:
 
-	E -&gt;gp-link F means there is a synchronize_rcu() fence event S
-	and an event X such that E -&gt;po S, either S -&gt;po X or S = X,
-	and X -&gt;rcu-link F.  In other words, E and F are linked by a
-	grace period followed by an instance of rcu-link.
+	E -&gt;gp F means there is a synchronize_rcu() fence event S such
+	that E -&gt;po S and either S -&gt;po F or S = F.  In simple terms,
+	there is a grace period po-between E and F.
 
-	E -&gt;rscs-link F means there is a critical section delimited by
-	an rcu_read_lock() fence L and an rcu_read_unlock() fence U,
-	and an event X such that E -&gt;po U, either L -&gt;po X or L = X,
-	and X -&gt;rcu-link F.  Roughly speaking, this says that some
-	event in the same critical section as E is linked by rcu-link
-	to F.
+	E -&gt;rscs F means there is a critical section delimited by an
+	rcu_read_lock() fence L and an rcu_read_unlock() fence U, such
+	that E -&gt;po U and either L -&gt;po F or L = F.  You can think of
+	this as saying that E and F are in the same critical section
+	(in fact, it also allows E to be po-before the start of the
+	critical section and F to be po-after the end).
 
 If we think of the rcu-link relation as standing for an extended
-"before", then E -&gt;gp-link F says that E executes before a grace
-period which ends before F executes.  (In fact it covers more than
-this, because it also includes cases where E executes before a grace
-period and some store propagates to F's CPU before F executes and
-doesn't propagate to some other CPU until after the grace period
-ends.)  Similarly, E -&gt;rscs-link F says that E is part of (or before
-the start of) a critical section which starts before F executes.
+"before", then X -&gt;gp Y -&gt;rcu-link Z says that X executes before a
+grace period which ends before Z executes.  (In fact it covers more
+than this, because it also includes cases where X executes before a
+grace period and some store propagates to Z's CPU before Z executes
+but doesn't propagate to some other CPU until after the grace period
+ends.)  Similarly, X -&gt;rscs Y -&gt;rcu-link Z says that X is part of (or
+before the start of) a critical section which starts before Z
+executes.
+
+The LKMM goes on to define the rcu-fence relation as a sequence of gp
+and rscs links separated by rcu-link links, in which the number of gp
+links is &gt;= the number of rscs links.  For example:
+
+	X -&gt;gp Y -&gt;rcu-link Z -&gt;rscs T -&gt;rcu-link U -&gt;gp V
+
+would imply that X -&gt;rcu-fence V, because this sequence contains two
+gp links and only one rscs link.  (It also implies that X -&gt;rcu-fence T
+and Z -&gt;rcu-fence V.)  On the other hand:
+
+	X -&gt;rscs Y -&gt;rcu-link Z -&gt;rscs T -&gt;rcu-link U -&gt;gp V
+
+does not imply X -&gt;rcu-fence V, because the sequence contains only
+one gp link but two rscs links.
+
+The rcu-fence relation is important because the Grace Period Guarantee
+means that rcu-fence acts kind of like a strong fence.  In particular,
+if W is a write and we have W -&gt;rcu-fence Z, the Guarantee says that W
+will propagate to every CPU before Z executes.
+
+To prove this in full generality requires some intellectual effort.
+We'll consider just a very simple case:
+
+	W -&gt;gp X -&gt;rcu-link Y -&gt;rscs Z.
+
+This formula means that there is a grace period G and a critical
+section C such that:
+
+	1. W is po-before G;
+
+	2. X is equal to or po-after G;
+
+	3. X comes "before" Y in some sense;
+
+	4. Y is po-before the end of C;
+
+	5. Z is equal to or po-after the start of C.
+
+From 2 - 4 we deduce that the grace period G ends before the critical
+section C.  Then the second part of the Grace Period Guarantee says
+not only that G starts before C does, but also that W (which executes
+on G's CPU before G starts) must propagate to every CPU before C
+starts.  In particular, W propagates to every CPU before Z executes
+(or finishes executing, in the case where Z is equal to the
+rcu_read_lock() fence event which starts C.)  This sort of reasoning
+can be expanded to handle all the situations covered by rcu-fence.
+
+Finally, the LKMM defines the RCU-before (rb) relation in terms of
+rcu-fence.  This is done in essentially the same way as the pb
+relation was defined in terms of strong-fence.  We will omit the
+details; the end result is that E -&gt;rb F implies E must execute before
+F, just as E -&gt;pb F does (and for much the same reasons).
 
 Putting this all together, the LKMM expresses the Grace Period
-Guarantee by requiring that there are no cycles consisting of gp-link
-and rscs-link links in which the number of gp-link instances is &gt;= the
-number of rscs-link instances.  It does this by defining the rb
-relation to link events E and F whenever it is possible to pass from E
-to F by a sequence of gp-link and rscs-link links with at least as
-many of the former as the latter.  The LKMM's "rcu" axiom then says
-that there are no events E with E -&gt;rb E.
-
-Justifying this axiom takes some intellectual effort, but it is in
-fact a valid formalization of the Grace Period Guarantee.  We won't
-attempt to go through the detailed argument, but the following
-analysis gives a taste of what is involved.  Suppose we have a
-violation of the first part of the Guarantee: A critical section
-starts before a grace period, and some store propagates to the
-critical section's CPU before the end of the critical section but
-doesn't propagate to some other CPU until after the end of the grace
-period.
+Guarantee by requiring that the rb relation does not contain a cycle.
+Equivalently, this "rcu" axiom requires that there are no events E and
+F with E -&gt;rcu-link F -&gt;rcu-fence E.  Or to put it a third way, the
+axiom requires that there are no cycles consisting of gp and rscs
+alternating with rcu-link, where the number of gp links is &gt;= the
+number of rscs links.
+
+Justifying the axiom isn't easy, but it is in fact a valid
+formalization of the Grace Period Guarantee.  We won't attempt to go
+through the detailed argument, but the following analysis gives a
+taste of what is involved.  Suppose we have a violation of the first
+part of the Guarantee: A critical section starts before a grace
+period, and some store propagates to the critical section's CPU before
+the end of the critical section but doesn't propagate to some other
+CPU until after the end of the grace period.
 
 Putting symbols to these ideas, let L and U be the rcu_read_lock() and
 rcu_read_unlock() fence events delimiting the critical section in
@@ -1606,11 +1657,14 @@ by rcu-link, yielding:
 
 	S -&gt;po X -&gt;rcu-link Z -&gt;po U.
 
-The formulas say that S is po-between F and X, hence F -&gt;gp-link Z
-via X.  They also say that Z comes before the end of the critical
-section and E comes after its start, hence Z -&gt;rscs-link F via E.  But
-now we have a forbidden cycle: F -&gt;gp-link Z -&gt;rscs-link F.  Thus the
-"rcu" axiom rules out this violation of the Grace Period Guarantee.
+The formulas say that S is po-between F and X, hence F -&gt;gp X.  They
+also say that Z comes before the end of the critical section and E
+comes after its start, hence Z -&gt;rscs E.  From all this we obtain:
+
+	F -&gt;gp X -&gt;rcu-link Z -&gt;rscs E -&gt;rcu-link F,
+
+a forbidden cycle.  Thus the "rcu" axiom rules out this violation of
+the Grace Period Guarantee.
 
 For something a little more down-to-earth, let's see how the axiom
 works out in practice.  Consider the RCU code example from above, this
@@ -1639,15 +1693,15 @@ time with statement labels added to the memory access instructions:
 If r2 = 0 at the end then P0's store at X overwrites the value that
 P1's load at Z reads from, so we have Z -&gt;fre X and thus Z -&gt;rcu-link X.
 In addition, there is a synchronize_rcu() between Y and Z, so therefore
-we have Y -&gt;gp-link X.
+we have Y -&gt;gp Z.
 
 If r1 = 1 at the end then P1's load at Y reads from P0's store at W,
 so we have W -&gt;rcu-link Y.  In addition, W and X are in the same critical
-section, so therefore we have X -&gt;rscs-link Y.
+section, so therefore we have X -&gt;rscs W.
 
-This gives us a cycle, Y -&gt;gp-link X -&gt;rscs-link Y, with one gp-link
-and one rscs-link, violating the "rcu" axiom.  Hence the outcome is
-not allowed by the LKMM, as we would expect.
+Then X -&gt;rscs W -&gt;rcu-link Y -&gt;gp Z -&gt;rcu-link X is a forbidden cycle,
+violating the "rcu" axiom.  Hence the outcome is not allowed by the
+LKMM, as we would expect.
 
 For contrast, let's see what can happen in a more complicated example:
 
@@ -1683,15 +1737,11 @@ For contrast, let's see what can happen in a more complicated example:
 	}
 
 If r0 = r1 = r2 = 1 at the end, then similar reasoning to before shows
-that W -&gt;rscs-link Y via X, Y -&gt;gp-link U via Z, and U -&gt;rscs-link W
-via V.  And just as before, this gives a cycle:
-
-	W -&gt;rscs-link Y -&gt;gp-link U -&gt;rscs-link W.
-
-However, this cycle has fewer gp-link instances than rscs-link
-instances, and consequently the outcome is not forbidden by the LKMM.
-The following instruction timing diagram shows how it might actually
-occur:
+that W -&gt;rscs X -&gt;rcu-link Y -&gt;gp Z -&gt;rcu-link U -&gt;rscs V -&gt;rcu-link W.
+However this cycle is not forbidden, because the sequence of relations
+contains fewer instances of gp (one) than of rscs (two).  Consequently
+the outcome is allowed by the LKMM.  The following instruction timing
+diagram shows how it might actually occur:
 
 P0			P1			P2
 --------------------	--------------------	--------------------
diff --git a/tools/memory-model/linux-kernel.cat b/tools/memory-model/linux-kernel.cat
index cdf682859d4e..1e5c4653dd12 100644
--- a/tools/memory-model/linux-kernel.cat
+++ b/tools/memory-model/linux-kernel.cat
@@ -102,20 +102,27 @@ let rscs = po ; crit^-1 ; po?
  *)
 let rcu-link = hb* ; pb* ; prop
 
-(* Chains that affect the RCU grace-period guarantee *)
-let gp-link = gp ; rcu-link
-let rscs-link = rscs ; rcu-link
-
 (*
- * A cycle containing at least as many grace periods as RCU read-side
- * critical sections is forbidden.
+ * Any sequence containing at least as many grace periods as RCU read-side
+ * critical sections (joined by rcu-link) acts as a generalized strong fence.
  *)
-let rec rb =
-	gp-link |
-	(gp-link ; rscs-link) |
-	(rscs-link ; gp-link) |
-	(rb ; rb) |
-	(gp-link ; rb ; rscs-link) |
-	(rscs-link ; rb ; gp-link)
+let rec rcu-fence = gp |
+	(gp ; rcu-link ; rscs) |
+	(rscs ; rcu-link ; gp) |
+	(gp ; rcu-link ; rcu-fence ; rcu-link ; rscs) |
+	(rscs ; rcu-link ; rcu-fence ; rcu-link ; gp) |
+	(rcu-fence ; rcu-link ; rcu-fence)
+
+(* rb orders instructions just as pb does *)
+let rb = prop ; rcu-fence ; hb* ; pb*
 
 irreflexive rb as rcu
+
+(*
+ * The happens-before, propagation, and rcu constraints are all
+ * expressions of temporal ordering.  They could be replaced by
+ * a single constraint on an "executes-before" relation, xb:
+ *
+ * let xb = hb | pb | rb
+ * acyclic xb as executes-before
+ *)</pre><hr><pre>commit 1ee2da5f9b5a8e814b397b77a08d44fed5f96a4a
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Mon May 14 16:33:39 2018 -0700

    tools/memory-model: Rename link and rcu-path to rcu-link and rb
    
    This patch makes a simple non-functional change to the RCU portion of
    the Linux Kernel Memory Consistency Model by renaming the "link" and
    "rcu-path" relations to "rcu-link" and "rb", respectively.
    
    The name "link" was an unfortunate choice, because it was too generic
    and subject to confusion with other meanings of the same word, which
    occur quite often in LKMM documentation.  The name "rcu-path" is not
    very appropriate, because the relation is analogous to the
    happens-before (hb) and propagates-before (pb) relations -- although
    that fact won't become apparent until the second patch in this series.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Paul E. McKenney &lt;paulmck@linux.vnet.ibm.com&gt;
    Acked-by: Andrea Parri &lt;parri.andrea@gmail.com&gt;
    Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
    Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
    Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;
    Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
    Cc: Will Deacon &lt;will.deacon@arm.com&gt;
    Cc: akiyks@gmail.com
    Cc: boqun.feng@gmail.com
    Cc: dhowells@redhat.com
    Cc: j.alglave@ucl.ac.uk
    Cc: linux-arch@vger.kernel.org
    Cc: luc.maranget@inria.fr
    Cc: npiggin@gmail.com
    Link: http://lkml.kernel.org/r/1526340837-12222-1-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;

diff --git a/tools/memory-model/Documentation/explanation.txt b/tools/memory-model/Documentation/explanation.txt
index a727c82bd434..1a387d703212 100644
--- a/tools/memory-model/Documentation/explanation.txt
+++ b/tools/memory-model/Documentation/explanation.txt
@@ -27,7 +27,7 @@ Explanation of the Linux-Kernel Memory Consistency Model
   19. AND THEN THERE WAS ALPHA
   20. THE HAPPENS-BEFORE RELATION: hb
   21. THE PROPAGATES-BEFORE RELATION: pb
-  22. RCU RELATIONS: link, gp-link, rscs-link, and rcu-path
+  22. RCU RELATIONS: rcu-link, gp-link, rscs-link, and rb
   23. ODDS AND ENDS
 
 
@@ -1451,8 +1451,8 @@ they execute means that it cannot have cycles.  This requirement is
 the content of the LKMM's "propagation" axiom.
 
 
-RCU RELATIONS: link, gp-link, rscs-link, and rcu-path
------------------------------------------------------
+RCU RELATIONS: rcu-link, gp-link, rscs-link, and rb
+---------------------------------------------------
 
 RCU (Read-Copy-Update) is a powerful synchronization mechanism.  It
 rests on two concepts: grace periods and read-side critical sections.
@@ -1509,8 +1509,8 @@ y, which occurs before the end of the critical section, did not
 propagate to P1 before the end of the grace period, violating the
 Guarantee.
 
-In the kernel's implementations of RCU, the business about stores
-propagating to every CPU is realized by placing strong fences at
+In the kernel's implementations of RCU, the requirements for stores
+to propagate to every CPU are fulfilled by placing strong fences at
 suitable places in the RCU-related code.  Thus, if a critical section
 starts before a grace period does then the critical section's CPU will
 execute an smp_mb() fence after the end of the critical section and
@@ -1523,19 +1523,19 @@ executes.
 What exactly do we mean by saying that a critical section "starts
 before" or "ends after" a grace period?  Some aspects of the meaning
 are pretty obvious, as in the example above, but the details aren't
-entirely clear.  The LKMM formalizes this notion by means of a
-relation with the unfortunately generic name "link".  It is a very
-general relation; among other things, X -&gt;link Z includes cases where
-X happens-before or is equal to some event Y which is equal to or
-comes before Z in the coherence order.  Taking Y = Z, this says that
-X -&gt;rfe Z implies X -&gt;link Z, and taking Y = X, it says that X -&gt;fr Z
-and X -&gt;co Z each imply X -&gt;link Z.
-
-The formal definition of the link relation is more than a little
+entirely clear.  The LKMM formalizes this notion by means of the
+rcu-link relation.  rcu-link encompasses a very general notion of
+"before": Among other things, X -&gt;rcu-link Z includes cases where X
+happens-before or is equal to some event Y which is equal to or comes
+before Z in the coherence order.  When Y = Z this says that X -&gt;rfe Z
+implies X -&gt;rcu-link Z.  In addition, when Y = X it says that X -&gt;fr Z
+and X -&gt;co Z each imply X -&gt;rcu-link Z.
+
+The formal definition of the rcu-link relation is more than a little
 obscure, and we won't give it here.  It is closely related to the pb
 relation, and the details don't matter unless you want to comb through
 a somewhat lengthy formal proof.  Pretty much all you need to know
-about link is the information in the preceding paragraph.
+about rcu-link is the information in the preceding paragraph.
 
 The LKMM goes on to define the gp-link and rscs-link relations.  They
 bring grace periods and read-side critical sections into the picture,
@@ -1543,32 +1543,33 @@ in the following way:
 
 	E -&gt;gp-link F means there is a synchronize_rcu() fence event S
 	and an event X such that E -&gt;po S, either S -&gt;po X or S = X,
-	and X -&gt;link F.  In other words, E and F are connected by a
-	grace period followed by an instance of link.
+	and X -&gt;rcu-link F.  In other words, E and F are linked by a
+	grace period followed by an instance of rcu-link.
 
 	E -&gt;rscs-link F means there is a critical section delimited by
 	an rcu_read_lock() fence L and an rcu_read_unlock() fence U,
 	and an event X such that E -&gt;po U, either L -&gt;po X or L = X,
-	and X -&gt;link F.  Roughly speaking, this says that some event
-	in the same critical section as E is connected by link to F.
-
-If we think of the link relation as standing for an extended "before",
-then E -&gt;gp-link F says that E executes before a grace period which
-ends before F executes.  (In fact it says more than this, because it
-includes cases where E executes before a grace period and some store
-propagates to F's CPU before F executes and doesn't propagate to some
-other CPU until after the grace period ends.)  Similarly,
-E -&gt;rscs-link F says that E is part of (or before the start of) a
-critical section which starts before F executes.
+	and X -&gt;rcu-link F.  Roughly speaking, this says that some
+	event in the same critical section as E is linked by rcu-link
+	to F.
+
+If we think of the rcu-link relation as standing for an extended
+"before", then E -&gt;gp-link F says that E executes before a grace
+period which ends before F executes.  (In fact it covers more than
+this, because it also includes cases where E executes before a grace
+period and some store propagates to F's CPU before F executes and
+doesn't propagate to some other CPU until after the grace period
+ends.)  Similarly, E -&gt;rscs-link F says that E is part of (or before
+the start of) a critical section which starts before F executes.
 
 Putting this all together, the LKMM expresses the Grace Period
 Guarantee by requiring that there are no cycles consisting of gp-link
-and rscs-link connections in which the number of gp-link instances is
-&gt;= the number of rscs-link instances.  It does this by defining the
-rcu-path relation to link events E and F whenever it is possible to
-pass from E to F by a sequence of gp-link and rscs-link connections
-with at least as many of the former as the latter.  The LKMM's "rcu"
-axiom then says that there are no events E such that E -&gt;rcu-path E.
+and rscs-link links in which the number of gp-link instances is &gt;= the
+number of rscs-link instances.  It does this by defining the rb
+relation to link events E and F whenever it is possible to pass from E
+to F by a sequence of gp-link and rscs-link links with at least as
+many of the former as the latter.  The LKMM's "rcu" axiom then says
+that there are no events E with E -&gt;rb E.
 
 Justifying this axiom takes some intellectual effort, but it is in
 fact a valid formalization of the Grace Period Guarantee.  We won't
@@ -1585,10 +1586,10 @@ rcu_read_unlock() fence events delimiting the critical section in
 question, and let S be the synchronize_rcu() fence event for the grace
 period.  Saying that the critical section starts before S means there
 are events E and F where E is po-after L (which marks the start of the
-critical section), E is "before" F in the sense of the link relation,
-and F is po-before the grace period S:
+critical section), E is "before" F in the sense of the rcu-link
+relation, and F is po-before the grace period S:
 
-	L -&gt;po E -&gt;link F -&gt;po S.
+	L -&gt;po E -&gt;rcu-link F -&gt;po S.
 
 Let W be the store mentioned above, let Z come before the end of the
 critical section and witness that W propagates to the critical
@@ -1600,12 +1601,12 @@ some event X which is po-after S.  Symbolically, this amounts to:
 
 The fr link from Y to W indicates that W has not propagated to Y's CPU
 at the time that Y executes.  From this, it can be shown (see the
-discussion of the link relation earlier) that X and Z are connected by
-link, yielding:
+discussion of the rcu-link relation earlier) that X and Z are related
+by rcu-link, yielding:
 
-	S -&gt;po X -&gt;link Z -&gt;po U.
+	S -&gt;po X -&gt;rcu-link Z -&gt;po U.
 
-These formulas say that S is po-between F and X, hence F -&gt;gp-link Z
+The formulas say that S is po-between F and X, hence F -&gt;gp-link Z
 via X.  They also say that Z comes before the end of the critical
 section and E comes after its start, hence Z -&gt;rscs-link F via E.  But
 now we have a forbidden cycle: F -&gt;gp-link Z -&gt;rscs-link F.  Thus the
@@ -1635,13 +1636,13 @@ time with statement labels added to the memory access instructions:
 	}
 
 
-If r2 = 0 at the end then P0's store at X overwrites the value
-that P1's load at Z reads from, so we have Z -&gt;fre X and thus
-Z -&gt;link X.  In addition, there is a synchronize_rcu() between Y and
-Z, so therefore we have Y -&gt;gp-link X.
+If r2 = 0 at the end then P0's store at X overwrites the value that
+P1's load at Z reads from, so we have Z -&gt;fre X and thus Z -&gt;rcu-link X.
+In addition, there is a synchronize_rcu() between Y and Z, so therefore
+we have Y -&gt;gp-link X.
 
 If r1 = 1 at the end then P1's load at Y reads from P0's store at W,
-so we have W -&gt;link Y.  In addition, W and X are in the same critical
+so we have W -&gt;rcu-link Y.  In addition, W and X are in the same critical
 section, so therefore we have X -&gt;rscs-link Y.
 
 This gives us a cycle, Y -&gt;gp-link X -&gt;rscs-link Y, with one gp-link
diff --git a/tools/memory-model/linux-kernel.cat b/tools/memory-model/linux-kernel.cat
index df97db03b6c2..cdf682859d4e 100644
--- a/tools/memory-model/linux-kernel.cat
+++ b/tools/memory-model/linux-kernel.cat
@@ -100,22 +100,22 @@ let rscs = po ; crit^-1 ; po?
  * one but two non-rf relations, but only in conjunction with an RCU
  * read-side critical section.
  *)
-let link = hb* ; pb* ; prop
+let rcu-link = hb* ; pb* ; prop
 
 (* Chains that affect the RCU grace-period guarantee *)
-let gp-link = gp ; link
-let rscs-link = rscs ; link
+let gp-link = gp ; rcu-link
+let rscs-link = rscs ; rcu-link
 
 (*
  * A cycle containing at least as many grace periods as RCU read-side
  * critical sections is forbidden.
  *)
-let rec rcu-path =
+let rec rb =
 	gp-link |
 	(gp-link ; rscs-link) |
 	(rscs-link ; gp-link) |
-	(rcu-path ; rcu-path) |
-	(gp-link ; rcu-path ; rscs-link) |
-	(rscs-link ; rcu-path ; gp-link)
+	(rb ; rb) |
+	(gp-link ; rb ; rscs-link) |
+	(rscs-link ; rb ; gp-link)
 
-irreflexive rcu-path as rcu
+irreflexive rb as rcu</pre><hr><pre>commit fb5ee84ea72c5f1b6cabdd1c9d6e8648995ca7c6
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Thu May 3 11:04:48 2018 -0400

    USB: Accept bulk endpoints with 1024-byte maxpacket
    
    Some non-compliant high-speed USB devices have bulk endpoints with a
    1024-byte maxpacket size.  Although such endpoints don't work with
    xHCI host controllers, they do work with EHCI controllers.  We used to
    accept these invalid sizes (with a warning), but we no longer do
    because of an unintentional change introduced by commit aed9d65ac327
    ("USB: validate wMaxPacketValue entries in endpoint descriptors").
    
    This patch restores the old behavior, so that people with these
    peculiar devices can use them without patching their kernels by hand.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Suggested-by: Elvinas &lt;elvinas@veikia.lt&gt;
    Fixes: aed9d65ac327 ("USB: validate wMaxPacketValue entries in endpoint descriptors")
    CC: &lt;stable@vger.kernel.org&gt;
    Signed-off-by: Greg Kroah-Hartman &lt;gregkh@linuxfoundation.org&gt;

diff --git a/drivers/usb/core/config.c b/drivers/usb/core/config.c
index c821b4b9647e..7b5cb28ffb35 100644
--- a/drivers/usb/core/config.c
+++ b/drivers/usb/core/config.c
@@ -191,7 +191,9 @@ static const unsigned short full_speed_maxpacket_maxes[4] = {
 static const unsigned short high_speed_maxpacket_maxes[4] = {
 	[USB_ENDPOINT_XFER_CONTROL] = 64,
 	[USB_ENDPOINT_XFER_ISOC] = 1024,
-	[USB_ENDPOINT_XFER_BULK] = 512,
+
+	/* Bulk should be 512, but some devices use 1024: we will warn below */
+	[USB_ENDPOINT_XFER_BULK] = 1024,
 	[USB_ENDPOINT_XFER_INT] = 1024,
 };
 static const unsigned short super_speed_maxpacket_maxes[4] = {</pre><hr><pre>commit 5d1332a8eabd8bd5b8c322d45542968ee6f113be
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Tue Mar 27 10:27:06 2018 -0400

    usb: gadget: udc: core: Document the relation between usb_ep_queue() and completion callback
    
    Improve the kerneldoc for usb_ep_queue() to note explicitly that the
    request's completion routine will be called if and only if the return
    value is 0.  The corresponding fact about usb_submit_urb() for the
    host-side API has long been documented, and this has always been the
    intention for the gadget API.  But until now, documentation seems to
    have been lacking.
    
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    Signed-off-by: Felipe Balbi &lt;felipe.balbi@linux.intel.com&gt;

diff --git a/drivers/usb/gadget/udc/core.c b/drivers/usb/gadget/udc/core.c
index 842814bc0e4f..cab5e4f09924 100644
--- a/drivers/usb/gadget/udc/core.c
+++ b/drivers/usb/gadget/udc/core.c
@@ -244,6 +244,12 @@ EXPORT_SYMBOL_GPL(usb_ep_free_request);
  * Returns zero, or a negative error code.  Endpoints that are not enabled
  * report errors; errors will also be
  * reported when the usb peripheral is disconnected.
+ *
+ * If and only if @req is successfully queued (the return value is zero),
+ * @req-&gt;complete() will be called exactly once, when the Gadget core and
+ * UDC are finished with the request.  When the completion function is called,
+ * control of the request is returned to the device driver which submitted it.
+ * The completion handler may then immediately free or reuse @req.
  */
 int usb_ep_queue(struct usb_ep *ep,
 			       struct usb_request *req, gfp_t gfp_flags)</pre><hr><pre>commit bd5c0ba2cd78a4c116726ead84f8f37dc92d043e
Author: Alan Stern &lt;stern@rowland.harvard.edu&gt;
Date:   Wed Mar 7 09:27:40 2018 -0800

    tools/memory-model: Finish the removal of rb-dep, smp_read_barrier_depends(), and lockless_dereference()
    
    Commit:
    
      bf28ae562744 ("tools/memory-model: Remove rb-dep, smp_read_barrier_depends, and lockless_dereference")
    
    was merged too early, while it was still in RFC form.  This patch adds in
    the missing pieces.
    
    Akira pointed out some typos in the original patch, and he noted that
    cheatsheet.txt should indicate that READ_ONCE() now implies an address
    dependency.  Andrea suggested documenting the relationship betwwen
    unsuccessful RMW operations and address dependencies.
    
    Andrea pointed out that the macro for rcu_dereference() in linux.def
    should now use the "once" annotation instead of "deref".  He also
    suggested that the comments should mention commit:
    
      5a8897cc7631 ("locking/atomics/alpha: Add smp_read_barrier_depends() to _release()/_relaxed() atomics")
    
    ... as an important precursor, and he contributed commit:
    
      cb13b424e986 ("locking/xchg/alpha: Add unconditional memory barrier to cmpxchg()")
    
    which is another prerequisite.
    
    Suggested-by: Akira Yokosawa &lt;akiyks@gmail.com&gt;
    Suggested-by: Andrea Parri &lt;parri.andrea@gmail.com&gt;
    Signed-off-by: Alan Stern &lt;stern@rowland.harvard.edu&gt;
    [ Fixed read_read_lock() typo reported by Akira. ]
    Signed-off-by: Paul E. McKenney &lt;paulmck@linux.vnet.ibm.com&gt;
    Acked-by: Andrea Parri &lt;parri.andrea@gmail.com&gt;
    Acked-by: Akira Yokosawa &lt;akiyks@gmail.com&gt;
    Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
    Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;
    Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
    Cc: boqun.feng@gmail.com
    Cc: dhowells@redhat.com
    Cc: j.alglave@ucl.ac.uk
    Cc: linux-arch@vger.kernel.org
    Cc: luc.maranget@inria.fr
    Cc: npiggin@gmail.com
    Cc: will.deacon@arm.com
    Fixes: bf28ae562744 ("tools/memory-model: Remove rb-dep, smp_read_barrier_depends, and lockless_dereference")
    Link: http://lkml.kernel.org/r/1520443660-16858-4-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;

diff --git a/tools/memory-model/Documentation/cheatsheet.txt b/tools/memory-model/Documentation/cheatsheet.txt
index 04e458acd6d4..956b1ae4aafb 100644
--- a/tools/memory-model/Documentation/cheatsheet.txt
+++ b/tools/memory-model/Documentation/cheatsheet.txt
@@ -1,11 +1,11 @@
                                   Prior Operation     Subsequent Operation
                                   ---------------  ---------------------------
                                C  Self  R  W  RWM  Self  R  W  DR  DW  RMW  SV
-                              __  ----  -  -  ---  ----  -  -  --  --  ---  --
+                              --  ----  -  -  ---  ----  -  -  --  --  ---  --
 
 Store, e.g., WRITE_ONCE()            Y                                       Y
-Load, e.g., READ_ONCE()              Y                              Y        Y
-Unsuccessful RMW operation           Y                              Y        Y
+Load, e.g., READ_ONCE()              Y                          Y   Y        Y
+Unsuccessful RMW operation           Y                          Y   Y        Y
 rcu_dereference()                    Y                          Y   Y        Y
 Successful *_acquire()               R                   Y  Y   Y   Y    Y   Y
 Successful *_release()         C        Y  Y    Y     W                      Y
diff --git a/tools/memory-model/Documentation/explanation.txt b/tools/memory-model/Documentation/explanation.txt
index dae8b8cb2ad3..a727c82bd434 100644
--- a/tools/memory-model/Documentation/explanation.txt
+++ b/tools/memory-model/Documentation/explanation.txt
@@ -826,7 +826,7 @@ A-cumulative; they only affect the propagation of stores that are
 executed on C before the fence (i.e., those which precede the fence in
 program order).
 
-read_lock(), rcu_read_unlock(), and synchronize_rcu() fences have
+rcu_read_lock(), rcu_read_unlock(), and synchronize_rcu() fences have
 other properties which we discuss later.
 
 
@@ -1138,7 +1138,7 @@ final effect is that even though the two loads really are executed in
 program order, it appears that they aren't.
 
 This could not have happened if the local cache had processed the
-incoming stores in FIFO order.  In constrast, other architectures
+incoming stores in FIFO order.  By contrast, other architectures
 maintain at least the appearance of FIFO order.
 
 In practice, this difficulty is solved by inserting a special fence
diff --git a/tools/memory-model/linux-kernel.def b/tools/memory-model/linux-kernel.def
index 5dfb9c7f3462..397e4e67e8c8 100644
--- a/tools/memory-model/linux-kernel.def
+++ b/tools/memory-model/linux-kernel.def
@@ -13,7 +13,7 @@ WRITE_ONCE(X,V) { __store{once}(X,V); }
 smp_store_release(X,V) { __store{release}(*X,V); }
 smp_load_acquire(X) __load{acquire}(*X)
 rcu_assign_pointer(X,V) { __store{release}(X,V); }
-rcu_dereference(X) __load{deref}(X)
+rcu_dereference(X) __load{once}(X)
 
 // Fences
 smp_mb() { __fence{mb} ; }</pre>
    <div class="pagination">
        <a href='2_16.html'>&lt;&lt;Prev</a><a href='2.html'>1</a><a href='2_2.html'>2</a><a href='2_3.html'>3</a><a href='2_4.html'>4</a><a href='2_5.html'>5</a><a href='2_6.html'>6</a><a href='2_7.html'>7</a><a href='2_8.html'>8</a><a href='2_9.html'>9</a><a href='2_10.html'>10</a><a href='2_11.html'>11</a><a href='2_12.html'>12</a><a href='2_13.html'>13</a><a href='2_14.html'>14</a><a href='2_15.html'>15</a><a href='2_16.html'>16</a><span>[17]</span><a href='2_18.html'>18</a><a href='2_19.html'>19</a><a href='2_20.html'>20</a><a href='2_21.html'>21</a><a href='2_22.html'>22</a><a href='2_23.html'>23</a><a href='2_24.html'>24</a><a href='2_25.html'>25</a><a href='2_26.html'>26</a><a href='2_27.html'>27</a><a href='2_28.html'>28</a><a href='2_29.html'>29</a><a href='2_30.html'>30</a><a href='2_31.html'>31</a><a href='2_32.html'>32</a><a href='2_33.html'>33</a><a href='2_34.html'>34</a><a href='2_35.html'>35</a><a href='2_36.html'>36</a><a href='2_37.html'>37</a><a href='2_38.html'>38</a><a href='2_39.html'>39</a><a href='2_40.html'>40</a><a href='2_41.html'>41</a><a href='2_42.html'>42</a><a href='2_43.html'>43</a><a href='2_44.html'>44</a><a href='2_45.html'>45</a><a href='2_46.html'>46</a><a href='2_47.html'>47</a><a href='2_48.html'>48</a><a href='2_49.html'>49</a><a href='2_50.html'>50</a><a href='2_51.html'>51</a><a href='2_52.html'>52</a><a href='2_53.html'>53</a><a href='2_54.html'>54</a><a href='2_55.html'>55</a><a href='2_56.html'>56</a><a href='2_57.html'>57</a><a href='2_58.html'>58</a><a href='2_59.html'>59</a><a href='2_60.html'>60</a><a href='2_61.html'>61</a><a href='2_62.html'>62</a><a href='2_63.html'>63</a><a href='2_64.html'>64</a><a href='2_65.html'>65</a><a href='2_66.html'>66</a><a href='2_67.html'>67</a><a href='2_68.html'>68</a><a href='2_69.html'>69</a><a href='2_70.html'>70</a><a href='2_71.html'>71</a><a href='2_72.html'>72</a><a href='2_73.html'>73</a><a href='2_74.html'>74</a><a href='2_75.html'>75</a><a href='2_76.html'>76</a><a href='2_77.html'>77</a><a href='2_78.html'>78</a><a href='2_79.html'>79</a><a href='2_80.html'>80</a><a href='2_81.html'>81</a><a href='2_82.html'>82</a><a href='2_83.html'>83</a><a href='2_84.html'>84</a><a href='2_85.html'>85</a><a href='2_86.html'>86</a><a href='2_87.html'>87</a><a href='2_88.html'>88</a><a href='2_89.html'>89</a><a href='2_90.html'>90</a><a href='2_91.html'>91</a><a href='2_92.html'>92</a><a href='2_93.html'>93</a><a href='2_94.html'>94</a><a href='2_95.html'>95</a><a href='2_96.html'>96</a><a href='2_97.html'>97</a><a href='2_98.html'>98</a><a href='2_99.html'>99</a><a href='2_100.html'>100</a><a href='2_101.html'>101</a><a href='2_102.html'>102</a><a href='2_103.html'>103</a><a href='2_104.html'>104</a><a href='2_105.html'>105</a><a href='2_106.html'>106</a><a href='2_107.html'>107</a><a href='2_108.html'>108</a><a href='2_109.html'>109</a><a href='2_110.html'>110</a><a href='2_111.html'>111</a><a href='2_112.html'>112</a><a href='2_113.html'>113</a><a href='2_114.html'>114</a><a href='2_115.html'>115</a><a href='2_116.html'>116</a><a href='2_117.html'>117</a><a href='2_118.html'>118</a><a href='2_119.html'>119</a><a href='2_120.html'>120</a><a href='2_121.html'>121</a><a href='2_122.html'>122</a><a href='2_123.html'>123</a><a href='2_124.html'>124</a><a href='2_125.html'>125</a><a href='2_126.html'>126</a><a href='2_127.html'>127</a><a href='2_128.html'>128</a><a href='2_129.html'>129</a><a href='2_130.html'>130</a><a href='2_131.html'>131</a><a href='2_132.html'>132</a><a href='2_133.html'>133</a><a href='2_134.html'>134</a><a href='2_135.html'>135</a><a href='2_136.html'>136</a><a href='2_137.html'>137</a><a href='2_138.html'>138</a><a href='2_139.html'>139</a><a href='2_140.html'>140</a><a href='2_18.html'>Next&gt;&gt;</a>
    <div>
</body>
